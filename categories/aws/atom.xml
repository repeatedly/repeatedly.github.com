<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: AWS | Go ahead!]]></title>
  <link href="http://repeatedly.github.com/categories/aws/atom.xml" rel="self"/>
  <link href="http://repeatedly.github.com/"/>
  <updated>2016-12-05T19:06:24+09:00</updated>
  <id>http://repeatedly.github.com/</id>
  <author>
    <name><![CDATA[Masahiro Nakagawa]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[AWS Athena雑感]]></title>
    <link href="http://repeatedly.github.com/ja/2016/12/aws-athena-impression/"/>
    <updated>2016-12-05T19:00:00+09:00</updated>
    <id>http://repeatedly.github.com/ja/2016/12/aws-athena-impression</id>
    <content type="html"><![CDATA[<p><a href="https://aws.amazon.com/athena/">Amazon Athena — Serverless Interactive Query Service - AWS</a></p>

<p>Prestoのフォースを感じたので，知り合いが試した情報も含めて，今思っている所を書いてみる．</p>

<h2>実装</h2>

<p>Athenaのページにあるように，実行エンジンは独自実装ではなくて，Facebookが公開しているPrestoを使っている．FacebookのみならずTreasure Data，Airbnb，Netflixなどクエリがガンガン飛ぶ環境で元気に動いている実績もあるので，拡張性，パフォーマンス，安定性で選ばれたのだろうと思われる．あとAWS的にJavaの方が相性は良さそう．</p>

<h2>パフォーマンス</h2>

<p>いくつかの記事で言及されている．</p>

<ul>
<li><a href="https://aws.amazon.com/jp/blogs/big-data/analyzing-data-in-s3-using-amazon-athena/">Analyzing Data in S3 using Amazon Athena</a></li>
<li><a href="http://data.gunosy.io/entry/aws-athena-vs-bigquery">Amazon AthenaをBigQueryと比較してみた</a></li>
<li><a href="http://dev.classmethod.jp/cloud/aws/amazon-athena-using-parquet/">Amazon Athena: カラムナフォーマット『Parquet』でクエリを試してみた</a></li>
</ul>


<p>これらを見ると，Prestoをそんなに改造せずに動かしている感じ．例えばGunosyさんやclassmethodさんの記事ではとりあえずフルスキャンをするcsv.gzの方がParquetより速い．データ量が少ないのとクエリが単純なので誤差の範囲に収まってる可能性もあるが，ParquetのReaderをAthena向けに改造している感じはしない(TQA(TDのPresto)の場合，PlazmaDB向けに色々と最適化したReaderを実装してパフォーマンスを稼いでいる(<a href="https://twitter.com/taroleo/status/804152866881478658">参考</a>))．</p>

<p>AWSがGoogleのColossus相当を持っているという話は聞かないものの，それでもBigQueryに近いパフォーマンスが出たりもするようなので，1クエリで多めにワーカーを使っているんじゃないかと思っている．TQAがクエリによっては同じデータ量でBigQueryとかその他DWHより高速に動いたケースってのはいくつかあるので，Prestoを使っているAthenaでも同様になると思われる．</p>

<p>あと細かなところだけど知り合いの試した情報によると，TQAとかBigQueryはキューイングされてから実行が完了するまでの実行時間が表示されるが，Athenaはクエリが走り始めてから完了するまでの時間しか表示されてないようなので，キューイングまわりで時間が掛かっている場合，体感と表示時間にかなり差があくようだ．</p>

<h2>スケジューリング</h2>

<p>1クラスタに数千ワーカー(今のPrestoだと万は怪しい？)があって，そこにユーザが割り当てられ，そこの中でさらに適宜ワーカーを選んで処理をしている感じ．</p>

<p><a href="http://dev.classmethod.jp/cloud/athena-cloudfront-logs/">Amazon AthenaでCloudFrontログをSQLで解析する #reinvent #athena</a></p>

<p>例えばこの記事の最後に「同じSELECTでも数秒で終わるものが時間帯によって数百秒かかることがあったり」というのがあるので，リソースが空いてるワーカーやクラスタをちゃんと選んでいるのではなくて，おそらくランダムか割り当て回数が少ないワーカーを選んでいるっぽい．この辺はBigQueryと同じで，実際複数ユーザが投げ続ける環境だと空いてるワーカーをクエリ負荷含めて探すのはかなり難しいので，この手のアプローチがシンプルでそれなりによく動く．</p>

<p>ただ，知人の試した結果だと，1時間弱くらいResourceUnavailableで弾かれ続けた，みたいな状況もあるようなので，重めのクエリを投げ続けると制限されるのか，ユーザのクラスタ割り当てが一定時間は固定で，ビジーなクラスタに割り当てられるとクエリが失敗しやすくなるのかもしれない．</p>

<p>Athenaのページに同時実行数に関する記述がないので，この辺どれだけ絞っているのかよく分からないのが悩ましいところ……</p>

<h2>エラーハンドリング</h2>

<p>どうもPresto内部でいくつかエラーを握りつぶしているっぽい．これはBigQueryもそうなんだけど，多分そのエラーによってクラスタの状態とかバックエンドの詳細が分かってしまうので，「とりあえずエラー」みたいなのを返しているようだ．
エラーが起きたらとりあえずretryする感じになりそう．</p>

<h2>カスタマイズされている部分</h2>

<p>ユーザが目に見えるところだと，DDLとか禁止されているクエリ周り．例えば運用上発行されたら困るDDLとかはもちろん弾かれるし，生のPrestoとかTQAだと通るクエリがAthenaではエラーになったりすることもあるようなので，その辺は運用との兼ね合いで禁止しているようだ．</p>

<p>あと当たり前だけどHiveのmetastore周りはAWS向けに専用サーバを実装しているっぽい．</p>

<h2>料金</h2>

<p>ここは思いっきりBigQueryを参考にしているようだ，がBilling Tierみたいなのはない．いずれ入るかもしれないが，AthenaはBigQueryのようにバッチとか含めてDWH的に使わせる気はあまりないようなので，当分ないだろうと思っている．
ただ，AWSは既存のうまく行ってるサービスを自社サービスに取り込んで提供する傾向が強いので，今後BigQueryに寄せていく可能性はありそう．</p>

<p>Athenaは様々なフォーマットに投げられる一方，jsonやcsvみたいなオブジェクトを対象にすると強制的にフルスキャンになるので，その分課金がバーストしやすい．列指向にするにはEMRのSparkとか使って行うのが鉄板のようだ．</p>

<p>あと当たり前だけどS3に対する保存・APIリクエスト・データ転送分も別途課金されるので，1TB per 5$ + additionalというのは気をつけてないと，想像より課金されてた，みたいなのが起きやすそう．特にデータ転送量．</p>

<h2>感想</h2>

<p>結構TLとか見てると，「BigQueryの対抗だ！」みたいなtweetを見かけたりするけど，個人的にはあくまでManaged Prestoって感じでまだ対抗みたいな感じはしてない．今後，ヘビーユーザが増えた時にどこまでうまくworkするのかは気になっているところ．</p>

<p>出来れば，AWSからPrestoにガンガンパッチとかFeature Requestが飛んでくれると嬉しいなぁと思ってます．</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[AWSを使ったデータ解析PaaSの裏側]]></title>
    <link href="http://repeatedly.github.com/ja/2013/03/the-architecture-of-data-analytics-paas-on-aws-jaws-days-2013-day2/"/>
    <updated>2013-03-18T16:11:00+09:00</updated>
    <id>http://repeatedly.github.com/ja/2013/03/the-architecture-of-data-analytics-paas-on-aws-jaws-days-2013-day2</id>
    <content type="html"><![CDATA[<p><a href="http://jaws-ug.jp/jawsdays2013/">JAWS DAYS 2013</a>というイベントがあって，2日目に<a href="http://jaws-ug.jp/jawsdays2013/speaker.html#DEV-01">Treasure Dataとして発表</a>してきました．実は1日目には弊社CTOが<a href="http://jaws-ug.jp/jawsdays2013/speaker.html#PD-02">パネルディスカッションに登壇</a>したりしてました．</p>

<ul>
<li>Slideshare</li>
</ul>


<iframe src="http://www.slideshare.net/slideshow/embed_code/17252380?rel=0" width="427" height="356" frameborder="0" marginwidth="0" marginheight="0" scrolling="no" style="border:1px solid #CCC;border-width:1px 1px 0;margin-bottom:5px" allowfullscreen webkitallowfullscreen mozallowfullscreen> </iframe>


<p> <div style="margin-bottom:5px"> <strong> <a href="http://www.slideshare.net/treasure-data/the-architecture-ofdataanalyticspaasonaws" title="The architecture of data analytics PaaS on AWS" target="_blank">The architecture of data analytics PaaS on AWS</a> </strong> from <strong><a href="http://www.slideshare.net/treasure-data" target="_blank">Treasure Data, Inc.</a></strong> </div></p>

<ul>
<li>Ustream</li>
</ul>


<iframe width="480" height="302" src="http://www.ustream.tv/embed/recorded/30009634?v=3&amp;wmode=direct" scrolling="no" frameborder="0" style="border: 0px none transparent;">    </iframe>


<p><br /><a href="http://www.ustream.tv/" style="padding: 2px 0px 4px; width: 400px; background: #ffffff; display: block; color: #000000; font-weight: normal; font-size: 10px; text-decoration: underline; text-align: center;" target="_blank">Video streaming by Ustream</a></p>

<p>最初はfrsyukiが登壇予定に上がっていたんだけど，今彼はアメリカということで代打で役割が回ってきた，というのが発表の経緯．</p>

<p>なんかラベルが"Dev"と"Ops"という超大雑把なくくりで「AWSで"Dev"って何発表すれば…」という状態だったので，
AWS上で展開しているTreasure Dataサービスの仕組みについてつらつらと話しました．</p>

<p>AWSべったりな感じではなくて</p>

<ul>
<li>Treasure Dataのサービス内容と目的</li>
<li>どうAWSのプロダクトを使っているのか</li>
<li>なぜこのAWSのサービスを使わないのか</li>
</ul>


<p>というのを大まかに話しました．仕組みの部分はどちらかというと一般的な設計の話になったかなという感じです．<br />
会場だったトラックBの席はほぼ満席で，発表の後の質疑応答も時間いっぱい掛かったので，個人的にはかなり嬉しい結果でした．</p>

<p>発表の後の時間や懇親会などで，すでにTreasure Dataを使っている人や，Fluentdを導入している人達とも交流出来，楽しい時間を過ごせました．これから導入しようかな，と考えている人もおられたので，何か問題があれば是非相談して頂ければなぁという感じです．<br />
AWSのMilesにも「Fluentd is good!!」と言われ，向こうでも徐々にFluentdが広まってきていると感じている今日この頃．このままTreasure Dataも伸びていきたい所です．</p>

<p>各セッションの感想は他の人が書いてくれるはず．ということで，皆さんお疲れ様でした！またどこかでお会いしましょう :)</p>
]]></content>
  </entry>
  
</feed>
