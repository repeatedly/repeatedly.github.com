<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Go ahead!]]></title>
  <link href="http://repeatedly.github.com/atom.xml" rel="self"/>
  <link href="http://repeatedly.github.com/"/>
  <updated>2014-08-03T01:20:06+09:00</updated>
  <id>http://repeatedly.github.com/</id>
  <author>
    <name><![CDATA[Masahiro Nakagawa]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Fluentdとログ収集のパターン]]></title>
    <link href="http://repeatedly.github.com/ja/2014/07/fluentd-and-log-forwarding-patterns/"/>
    <updated>2014-07-31T18:35:00+09:00</updated>
    <id>http://repeatedly.github.com/ja/2014/07/fluentd-and-log-forwarding-patterns</id>
    <content type="html"><![CDATA[<p>「ログを集めて保存する」と言うのは簡単だけど，ログ収集の構成にはいくつか方法があり，勉強会などでちょくちょく聞かれるので，いくつかのパターンについて書く．<br />
「俺はもうバリバリログ収集やってるぜ！」という人は多分すでに知っていることが書かれているので，タブを閉じて良い．</p>

<p>ここではログコレクタにFluentdを想定しているが，他のログ収集プロダクトにも適用出来るはず．
ただ，Fluentdはタグベースのルーティングを持ち，単体でもキューのように動作させることが可能で，既存のものより複雑な問題を解決しようとしているので，少し工夫が必要かもしれない．<br />
Fluentdそのものについては<a href="http://docs.fluentd.org/articles/quickstart">公式ドキュメント</a>や，<a href="http://tagomoris.hatenablog.com/entry/2013/12/03/150656">Fluentdとはどのようなソフトウェアなのか</a>を参考に．</p>

<h2>クライアントから直接保存する</h2>

<p><img src="http://repeatedly.github.com/images/fluentd_only_client_pattern.png" title="&#34;Only client pattern&#34;" alt="&#34;Only client pattern&#34;"></p>

<p>いきなりFluentdを使わないパターン．JavaScript SDKを提供している解析サービスやモバイル端末などでよく使われている．ログがユーザサイドで発生する場合にはログコレクタを仕込むことは出来ないので，基本このアプローチになる．<br />
これらはクライアントの出来によって精度が左右されるが，モバイルであれば繋がらなかったら一定量バッファリングをし，ネットワークが繋がった段階で非同期に転送などがよくある実装．</p>

<p>ログコレクタを用意出来るサーバサイドでこのアプローチを取っているシステムは最近だとあまり聞かない．もしやるならエラーハンドリングとして</p>

<ul>
<li>バッファリング</li>
<li>リトライ</li>
<li>ロードバランシング</li>
</ul>


<p>などの問題を解決する必要がある．Fluentdであればこれらの機能が最初からついているので，今から構築するシステムでやる必要はほとんど無いと思われる．</p>

<h2>末端ノードのログコレクタから直接保存する</h2>

<p><img src="http://repeatedly.github.com/images/fluentd_only_leaf_node_pattern.png" title="&#34;Only leaf node pattern&#34;" alt="&#34;Only leaf node pattern&#34;"></p>

<p>アプリケーションやノードからログを集め，ログコレクタから直接保存する．「クライアントから直接保存する」の例で，ローカルにログコレクタを置き，そこ経由でデータを投げつけるモデル．<br />
ネットワーク周りのややこしい問題をログコレクタに任せられ，Fluentdであればプラグインで容易にストリームを操作できるのがメリット．また，ApacheやNginxから直接外部にデータを投げるのは難しいので，Fluentdでファイルにはき出されたログを収集するときにはこの構成となる．</p>

<p>この構成だと，収集対象のサーバが多くなるだけアクセスが増えて保存先への負荷があがるので</p>

<ul>
<li>データのストリームがそれほど大きくない</li>
<li>保存先が書き込みに対して耐性がある (クラウドサービスなど)</li>
</ul>


<p>などの場合に有効になる．次で書く集約ノードが必要ないので，その分管理は楽になる．<br />
Fluentdは転送役と集約役に違いはないので，この段階でフィルター系プラグインを使って，データを加工することもある．</p>

<p><a href="http://www.treasuredata.com/">Treasure Data</a>の場合には，<a href="https://metrics.librato.com/">Librato Metrics</a>に投げる所などは集約ノードを経由せず，各Fluentd(Treasure Agent)から直接投げている．この場合は各ノードのメトリックスが取りたいので，集約ノードでデータストリームをまとめる必要もない．</p>

<p>これとは違いMongoDBの場合だと，細かいのをちまちま送るより大きめのバッチでガンと書き込んだ方が効率が良いので，このモデルよりも集約ノードを置いた方が良い．</p>

<h2>集約ノードのログコレクタを経由して保存する</h2>

<p><img src="http://repeatedly.github.com/images/fluentd_aggregation_node_pattern.png" title="&#34;Using aggregation node pattern&#34;" alt="&#34;Using aggregation node pattern&#34;"></p>

<p>ログコレクタでの多段構成モデル．集約ノードを置く利点は，データストリームをまとめてデータに対する処理をしやすくする点が大きい．また，各ノードから集めることでストリームが太くなり，マイクロバッチの効率も良くなる．</p>

<p>Fluentdでもアグリゲーションをしたり，<a href="http://norikra.github.io/">Norikra</a>と連携するプラグインがあったりするので，その手の処理はこの集約ノードでやるのがベター．</p>

<p>大抵のログコレクタと同じく，Fluentdのデフォルトの転送プロトコルはPush型になっていて，多段構成時には流れるように保存先にデータが集まるようになっている．<br />
多段構成時の注意点は，ある場所のノードが落ちた時にストリームが途切れてしまう所．Fluentdの場合は障害に対応するために，転送先を複数指定可能で，その中で負荷分散とノードが落ちた時の処理を指定出来るようになっていて，よほど一気にノードが落ちない限りストリームが途切れることはない．もし落ちてもバッファリングが行われるので，ノードを再度立ち上げればデータはまた流れ出す．</p>

<h3>PaaS上でのアプリケーション</h3>

<p>アプリケーションをホストするような環境だとローカルにFluentdを置けなかったりするので(HerokuだとFluentdは起動できるが，ファイルバッファが使えなかったりする．ユースケース次第)，その場合はいきなり集約ノードやキューにデータを投げることになる．</p>

<h2>キューを置く</h2>

<p><img src="http://repeatedly.github.com/images/fluentd_queue_pattern.png" title="&#34;Using queue pattern&#34;" alt="&#34;Using queue pattern&#34;"></p>

<p>データストリームの中でキューを間に挟むことの主な理由は，ログのreliabilityの向上と，処理の間にワンクッション置くこと．</p>

<p>そもそもキューはPush型ではなくPull型であり，Producer・Queue・Consumerと登場人物も増えるので，キューを置くことでログ収集そのものが効率化されることはあまりない．異なる粒度のシステム間で連携をする時に，間にキューを置くことが多い．</p>

<p>実際Fluentdとキューを連携させている例はいくつかあり，たとえば複雑なシステムを構築している<a href="http://engineering.viki.com/blog/2014/data-warehouse-and-analytics-infrastructure-at-viki/">Vikiの例</a>ではKestrelでFluentdからのデータストリームを分岐させているし，AWSは本家が<a href="https://github.com/awslabs/aws-fluent-plugin-kinesis">fluent-plugin-kinesis</a>を書いているので，いずれこの事例も増えるはず.</p>

<p>KafkaやKinesisなど信頼性のあるキューを間に置けば，ログをそれなりの期間保持しつつ，Consumerを複数用意することでストリームを分岐できる．<br />
Push型での分岐とは違い，キューからログを取る側の都合でデータを処理出来るので，各データストリームで処理粒度が違う時に有効．
ただ，キューそのものに信頼性があってもProducer/Consumerが駄目だと効率が良くならずログが欠損/重複するので，自分たちのシステム要件に合わせてちゃんと構築する必要がある．</p>

<h3>Pull型のログ収集</h3>

<p>キューを置かずにPull型でログを転送する方法もある．Kafkaほどの信頼性を期待するのは難しいが，Pull型の利点を享受できる．まだ完成していないが，Fluentdだとモリス=タゴという人が，<a href="https://github.com/tagomoris/fluent-plugin-pullforward">pullforward</a>というのを開発中らしい．</p>

<h2>Fluentdを使わない方が良いパターン</h2>

<p>プロダクションで使われているパターンをいくつか書いた．大抵のシステムは上のどれかの構成に当てはまる．FluentdはWebや広告のみならずIoTやPOS含め色々なところで使われていて，データのアーカイブ，簡単なストリーム処理，ノードやアプリケーションのモニタリング，などなど様々なユースケースの基盤になれる柔軟性がある．</p>

<p>また，LINE社で2年間問題なく動いているし，最近勉強会とかで話を聞くと「安定していて自分の仕事がない」と言われる位，よほど変なことしない限り安定性もある．ある会社で100億events/dayをFluentdクラスタで転送した実績もあるので，パフォーマンスもそれなりにある(フィルタ的な処理を重ねまくると，もちろん遅くなる)．</p>

<p>が，Fluentdを使わない方が良いケースもある．以下主に二つ．</p>

<h3>Exactly Onceが必要なケース</h3>

<p>一切ログの欠損も重複も許せない，しかも確実に書き込む必要がある，というケース．<br />
ストリーム処理でExactly Onceを保証するのはかなり難しく，俺が知っている限りOSSでは存在していない．商用でもほとんど知らない．</p>

<p>Exactly Onceを実現しようとすると，ログ発生時点から書き込むまでを完全に同期的にやるか，様々な箇所でトランザクションが必要になり，スケールアウトが難しくコストもものすごく掛かる．そして保存先にもそれなりの機能が求められる．</p>

<p>かつてOSSでマスターノードを使い到達保証を目指したプロダクトがあったが，結局パフォーマンスがボトルネックになり，そこまでしてもログの欠損が防げなかったため，新しいバージョンでは諦めることになった．</p>

<h4>Fluentdのモデル</h4>

<p>FluentdはAt Most Onceであり，<a href="http://docs.fluentd.org/articles/high-availability">ドキュメントにもモデルの説明と対策が書いてある</a>，<br />
これはログが欠損/重複しまくるということではなく，At Most OnceもAt Least Onceも通常は問題は起きない．トポロジーに問題がある場合に，システム的に欠損/重複が起きうるという話．そして大抵のユーザはExactly Onceでなくても上手く行く．</p>

<p>Fluentdでも欠損/重複を防ぐための対策はいくつかあり</p>

<ul>
<li>ログにユニークIDを足して，HadoopなどのETLで重複を削除する</li>
<li>直近の生ログは保持しておき，保存先とのレコード数を比較する．おかしい所は再送</li>
<li>データストリームを複数作って冗長性を持たせる</li>
</ul>


<p>などなど．システム的にExactly Onceではなくても，それに低コストで近づけることは可能．</p>

<h3>データストリームが一本で密結合したサービスがある</h3>

<p>たとえばAWSのCloudWatch Logsがそう．Agentのセットアップが必要だったりして楽かと言われるとまだ微妙だが，今後最初からインストールされる可能性もある．<br />
そのような状況で，Agentから取れるログをCloudWatch Logsで直接見るので十分であれば，Fluentdを入れるメリットは少ない(<a href="https://github.com/ryotarai/fluent-plugin-cloudwatch-logs">CloudWatch Logs</a>用のプラグインがあるので，Fluentdから利用することは可能)．</p>

<p>Fluentdの利点は簡単にロバストで柔軟性のあるログ収集基盤が作れて，一度構築してしまえば，環境非依存でそのログ収集基盤を再利用出来るところなので，そのような必要性がないのであれば，環境と密結合したサービスを使う方が運用コストそのものは直近は削減できるはず．</p>

<h2>まとめ</h2>

<p>Fluentdが向いているケースと向いてないケース，そのPros/Consみたいなのを書いた．細かく書けばもっと色々と書けるのだけど，記事でそんなに長々と書いても疲れるだけなので大まかに．
何か質問があればTwitterで<a href="https://twitter.com/repeatedly">@repeatedly</a>にmentionするなり，この記事にコメントするなりしてください :)</p>

<p>もうすぐFluentd + Elasticsearch + Kibanaという有名な構成のムック本が出るようなので，この本とか読むと，解析のノウハウ含め色々とここには書いていない情報が手に入るのではないかと思います．<br />
<a href="http://www.amazon.co.jp/exec/obidos/ASIN/4774169838/repeatedly-22/ref=nosim/"><img src="http://ecx.images-amazon.com/images/I/61vwvFp6EEL._SL160_.jpg" /></a></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[MPP on Hadoop, Redshift, BigQuery]]></title>
    <link href="http://repeatedly.github.com/ja/2014/07/mpp-on-hadoop-redshift-bigquery/"/>
    <updated>2014-07-23T22:33:00+09:00</updated>
    <id>http://repeatedly.github.com/ja/2014/07/mpp-on-hadoop-redshift-bigquery</id>
    <content type="html"><![CDATA[<p>Twitterで「早く今流行のMPPの大まかな使い方の違い書けよ！」というプレッシャーが半端ないのでてきとうに書きます．この記事は俺の経験と勉強会などでユーザから聞いた話をもとに書いているので，すべてが俺の経験ではありません(特にBigQuery)．各社のSAの人とかに聞けば，もっと良いアプローチとか詳細を教えてくれるかもしれません．<br />
オンプレミスの商用MPPは使ったことないのでノーコメントです．</p>

<p>MPP on HadoopでPrestoがメインなのは今一番使っているからで，Impalaなど他のMPP on Hadoop的なものも似たような感じかなと思っています．
もちろん実装の違いなどがあるので，その辺は適宜自分で補間してください．</p>

<h2>前提</h2>

<p>アプリケーションを開発していて，そのための解析基盤を一から作る．</p>

<h2>簡単なまとめ</h2>

<ul>
<li>データを貯める所が作れるのであれば，そこに直接クエリを投げられるPrestoなどのMPPクエリエンジンを立てるのが楽

<ul>
<li>特にHadoopとかすでにある場合には，まずこれ</li>
</ul>
</li>
<li>データマートが必要であれば，RedshiftやBigQueryの方が向いている</li>
<li>ストレージもスキーマも運用も何も考えずにやりたいのであれば，BigQueryにFluentdとかでとりあえずJSONでぶち込むのが，多分この候補の中では一番初期コストが掛からない

<ul>
<li>もちろん要求によるので気をつける</li>
</ul>
</li>
<li>Presto + Redshiftというケースも有り(アドホックなクエリはPresto，BIからガリガリつなぐのにRedshiftなど)</li>
</ul>


<p>以下つらつらとリスト形式で書いてます．</p>

<h2>Presto/Impala/Drill</h2>

<p>PrestoやImpalaやApache Drillは，Redshift/BigQueryと違ってMPPデータベースではなくてMPPクエリエンジンなので，そこに違いがある．
Prestoそのものについては，@frsyuki が<a href="http://treasure-data.hateblo.jp/entry/2014/07/10/150250">HCJ 2014で発表したスライド</a>があるので，そっちも参考に．</p>

<ul>
<li>PrestoやImpalaはそもそもサービスじゃないので，自分ですべて運用する必要がある．

<ul>
<li>死活監視とか，もう少しワーカーが欲しかったら追加でデプロイみたいなのをする人が必要</li>
</ul>
</li>
<li>外部にストレージが必要

<ul>
<li>すでにある場合には，RedshiftやBigQueryじゃなくて，まずこれで十分かどうか試すという流れになりつつある</li>
<li>PrestoならS3とかにもクエリが投げられるので，FluentdでS3にJSONで貯めて，とかで構築コストはかなり軽減出来る</li>
</ul>
</li>
<li>ストレージ側にスキーマを要求せず，直接クエリが投げられる</li>
<li>MapReduceとかとデータソースを共有出来る

<ul>
<li>データ量が増えてくると，ストレージからMPPデータベースにimportするだけでコストになるので，アドホックにクエリが投げにくくなる</li>
<li>PrestoやApache Drillは一つのクエリで複数のデータソースにアクセス出来るので．マスターテーブルとのjoinとかが楽に出来る</li>
</ul>
</li>
<li>速さに関しては，やはりスキーマありでチューニングされたMPPにはまだ基本勝てない．状況によっては勝てる時もある

<ul>
<li>それでも数秒 - 数十秒で返ってきたりするので，どこまでパフォーマンスを求めるかによる</li>
</ul>
</li>
<li>クエリ同時実行制御に関しては，まだ商用のものに迫っているのはない印象

<ul>
<li>ここの改善に取り組んでいる人たちがいるので，いずれデータマート的にも使えるようになる可能性は高い</li>
</ul>
</li>
<li>オープンソースなので，問題があったら自分で修正可能，処理傾向も把握しやすい</li>
</ul>


<h2>Redshift</h2>

<ul>
<li>スキーマが必須なので，アドホックに解析するためのデータベースとしては少し不向き

<ul>
<li>やるならデータをJSON文字列で保存，クエリ時に分解する．効率は落ちる</li>
</ul>
</li>
<li>MPPデータベース(ParAccel)がAWSカスタマイズされて載っているので，その辺の知識がないと嵌まりやすい

<ul>
<li>AWS Casualで青木さんが話した<a href="http://www.slideshare.net/mineroaoki/20140419-aws-casualredshiftpublic">ふつうのRedshiftパフォーマンスチューニング</a>が参考になる</li>
<li>データ量がすくないとそれでもパワーでなんとかなる</li>
</ul>
</li>
<li>マネージドサービスとはいえ，リーダーノードの挙動がおかしい時など，面倒を見ないと行けないケースはある</li>
<li>カラムを弄る場合は基本テーブルを作り直すのがベター．クラスタ再配置中はREAD ONLYになるので，その辺含めて運用を考える必要がある

<ul>
<li>数時間READ ONLYの場合，貯めようとしていたログはどうするか，など</li>
<li>今時はMPPデータベース単体で運用している所は少ない．RedshiftでもEMRなどからデータを整形して一気にガツンと入れるのが多い</li>
</ul>
</li>
<li>クエリの同時実行制御周りは他のに比べて優秀

<ul>
<li>データマートして使いやすい．<a href="https://twitter.com/mineroaoki/status/491995296671363073">バッチを投げると厳しい</a>とのこと．</li>
</ul>
</li>
<li>ストレージと演算パワーが分離してないので，ユースケースによってはコストが割に合わない

<ul>
<li>特に周りだとSSDインスタンスを使っている人は<del>いない</del>ほとんどいない(<a href="https://twitter.com/repeatedly/status/489635755979837441">この辺の話</a>)．</li>
<li>某ふっふはっほ社が「たべみる」でSSDをつかってました(<a href="http://www.slideshare.net/mineroaoki/at-aws-summit-tokyo-2014/9">AWS Summitでのスライド</a>)．が，これはかなり<a href="https://twitter.com/mirakui/status/491947294019690497">特殊な</a><a href="https://twitter.com/mirakui/status/491948100571758592">ケース</a>な気も．<a href="https://twitter.com/mineroaoki/status/49">横に並べることによるメリット</a>が大きいようです．</li>
</ul>
</li>
</ul>


<h2>BigQuery</h2>

<ul>
<li>Redshiftと同じく，アドホックに色々とデータをぶち込んで解析するには，JSON文字列(record型？)で保存する必要がある</li>
<li>既存のMPPデータベースとかで考えないと行けない問題(distkeyとか)を，Googleパワーで強引に解決</li>
<li>運用は完全Google任せ</li>
<li>Googleの制約を受ける

<ul>
<li>負荷が極端に上がるようなクエリとかは望み薄(FULL OUTER JOIN, 数億同士のjoin，count(distinct))</li>
<li>Redshift同様，でかいバッチ向けにHDFSとかオブジェクトストレージに生のデータを置いておくのがベター</li>
</ul>
</li>
<li>BigQueryもスキーマがあり，alter column的なものがないので，変更する時は適宜テーブルを作り直すのがベター</li>
<li>Redshiftと違いクエリ単位の課金なので，どれだけ掛かるか把握するのが難しい

<ul>
<li>小さい会社だとかなりマネージしやすい(<a href="https://twitter.com/repeatedly/status/491889139579506688">この辺の話</a>)．大きい会社や，マーケや営業の人がガンガン使う場合には，かなりバーストする可能性がある．Reservedがあるが，<a href="https://developers.google.com/bigquery/pricing?hl=ja#reserved_cap">月200万から</a>なので，判断が難しい</li>
</ul>
</li>
<li>Streaming Importが結構パフォーマンスが出るので，importして即クエリがやりやすい(<a href="http://qiita.com/kazunori279/items/10ac0066ac9b0b5aaaf3">参考記事</a>)</li>
<li>同時実行制御周り誰か教えてください</li>
</ul>


<h2>まとめ</h2>

<p>基本的にこれらの裏にはHadoopなどの基盤が前提になりつつある(オブジェクトストレージ + 演算リソースでも可)．上のリストを眺めれば，なんとなく使い分けが分かるんじゃないでしょうか！
MPPと一纏めにするにはユースケースや得意なものが違うので，ちゃんと使い分けましょう．基本的にどれもBIツールと接続する方法があり，苦労はそんなにしないはず．</p>

<p>各プロダクトは常に改善されているので，ここに書いてある制約などは，いずれ緩和される可能性があります．常に最新情報をチェックしましょう．</p>

<p>今回はMPPクエリエンジンプロダクトの話なので上のリストでは省きましたが，Treasure Dataが提供しているTQAというMPPサービスは「Prestoで運用とかストレージを考えなくていい版」に近い感じになります．TDはさまざまな<a href="http://docs.treasuredata.com/categories/result">外部ストレージと連携出来る</a>ので，<a href="http://treasure-data.hateblo.jp/entry/2014/05/14/104632">Treasure Dataを中心に使い分ける感じになります</a>．<br />
最後に宣伝！</p>

<h2>P.S</h2>

<p>Twitterに流したさらに要約したtweet.</p>

<blockquote class="twitter-tweet" lang="en"><p>Presto on Storage/BigQuery/Redshiftはユースケースがバラバラなので，適宜使い分ければ良いという単純な話．ただ，HDFSやオブジェクトストレージみたいなのにデータが永続化されている前提なので，Prestoは入りには楽だよね，というのはあります．</p>&mdash; Mr. Fiber (@repeatedly) <a href="https://twitter.com/repeatedly/statuses/491883277829951488">July 23, 2014</a></blockquote>


<script async src="http://repeatedly.github.com//platform.twitter.com/widgets.js" charset="utf-8"></script>




<blockquote class="twitter-tweet" lang="en"><p>Redshiftは同時実行制御頑張っているし，distkeyとかをちゃんと設計してあげればかなりパフォーマンスが出るので，データマートとして優秀．特に8XLとかであれば，RDSとかでは頑張れない領域になる．ただ，スキーマの変更に弱いので，適宜ロードしてあげないと行けないのがネック</p>&mdash; Mr. Fiber (@repeatedly) <a href="https://twitter.com/repeatedly/statuses/491884516605038592">July 23, 2014</a></blockquote>


<script async src="http://repeatedly.github.com//platform.twitter.com/widgets.js" charset="utf-8"></script>




<blockquote class="twitter-tweet" lang="en"><p>BigQueryは逆に，その辺のMPPの知識ないけど楽に処理したい，という時には便利．ストレージと密結合しているRedshiftと違ってストレージとしては安価なので，ガンガンデータを入れられる．スキーマの変更に弱いのと，G社の都合でクエリに制限が掛かったり不安定になるのがネック</p>&mdash; Mr. Fiber (@repeatedly) <a href="https://twitter.com/repeatedly/statuses/491884911515533312">July 23, 2014</a></blockquote>


<script async src="http://repeatedly.github.com//platform.twitter.com/widgets.js" charset="utf-8"></script>




<blockquote class="twitter-tweet" lang="en"><p>Prestoは単体だとストレージがないので，裏側に何を使うかによってかなり左右される．ちゃんとしたHadoopクラスタやオブジェクトストレージがあれば，同時実行制御の部分に難はあるが，低レイテンシクエリーとしては十分優秀．データのインポートの手間がないのが大きい．</p>&mdash; Mr. Fiber (@repeatedly) <a href="https://twitter.com/repeatedly/statuses/491885404665049089">July 23, 2014</a></blockquote>


<script async src="http://repeatedly.github.com//platform.twitter.com/widgets.js" charset="utf-8"></script>




<blockquote class="twitter-tweet" lang="en"><p>まぁHadoopとかあるならとりあえずPresto入れとくか，という流れにはなりつつある気がする．それでも同時にたくさんのクエリが飛んでくるとか，ある程度スキーマ固まったのでガッツリ使いたい，になるとRedshiftとかBigQueryにバッチでinsert，がよくあるパターン</p>&mdash; Mr. Fiber (@repeatedly) <a href="https://twitter.com/repeatedly/statuses/491886467266789376">July 23, 2014</a></blockquote>


<script async src="http://repeatedly.github.com//platform.twitter.com/widgets.js" charset="utf-8"></script>




<blockquote class="twitter-tweet" lang="en"><p>やっぱり他のMPPデータベースにデータ入れるの面倒だからPrestoでがんばりたい，というユーザ結構いてその人たちが色々とPrestoをデータマート的に使えるようにと頑張っているようなので，いずれHadoop上ですべて完結する世界は来るかもしれない</p>&mdash; Mr. Fiber (@repeatedly) <a href="https://twitter.com/repeatedly/statuses/491887539267960833">July 23, 2014</a></blockquote>


<script async src="http://repeatedly.github.com//platform.twitter.com/widgets.js" charset="utf-8"></script>




<blockquote class="twitter-tweet" lang="en"><p>トレジャーデータというサービス，自分でインフラ管理する必要ないですし，Fluentd/JS/iOS/Androidなどからデータを入れるだけで，即バッチや低レイテンシクエリを投げられる，便利なサービスらしいですよ &gt; <a href="http://t.co/gSg9ZTNjKt">http://t.co/gSg9ZTNjKt</a></p>&mdash; Mr. Fiber (@repeatedly) <a href="https://twitter.com/repeatedly/statuses/491889631437144064">July 23, 2014</a></blockquote>


<script async src="http://repeatedly.github.com//platform.twitter.com/widgets.js" charset="utf-8"></script>




<blockquote class="twitter-tweet" lang="en"><p>社会人の勤めを果たした</p>&mdash; Mr. Fiber (@repeatedly) <a href="https://twitter.com/repeatedly/statuses/491889663787819008">July 23, 2014</a></blockquote>


<script async src="http://repeatedly.github.com//platform.twitter.com/widgets.js" charset="utf-8"></script>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Release fluent-plugin-http-puma]]></title>
    <link href="http://repeatedly.github.com/ja/2014/07/release-fluent-plugin-http-puma/"/>
    <updated>2014-07-20T18:42:00+09:00</updated>
    <id>http://repeatedly.github.com/ja/2014/07/release-fluent-plugin-http-puma</id>
    <content type="html"><![CDATA[<p><a href="https://github.com/repeatedly/fluent-plugin-http-puma">fluent-plugin-http-puma</a></p>

<p>標準で入っているin_httpとは違って，Pumaと呼ばれるWebサーバベースのHTTP(S)でのリクエストを受け付けるInputプラグイン書きました．</p>

<h2>使い方</h2>

<p>fluent-gemでインストール．</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>$ fluent-gem install fluent-plugin-http-puma</span></code></pre></td></tr></table></div></figure>


<p>in_httpとほぼ同じように動きますが，独自でHTTPリクエストをパースしてないので，keepaliveやボディサイズチェック用のオプションはありません．その代わりPuma関係のオプションが増えてます(<a href="https://github.com/repeatedly/fluent-plugin-http-puma#configuration">README参照</a>)．<br />
一番の違いは，HTTPSをサポートしている所です．<code>use_ssl</code>と<code>ssl_keys</code>を使うことで，HTTPSとして立ち上がります．</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
</pre></td><td class='code'><pre><code class='aconf'><span class='line'><span class="nt">&lt;source&gt;</span>
</span><span class='line'>  <span class="nb">type</span> http_puma
</span><span class='line'>
</span><span class='line'>  <span class="err">use_</span><span class="nb">ssl</span>
</span><span class='line'>  ssl_keys [<span class="s2">&quot;/path/to/key&quot;</span>, <span class="s2">&quot;/path/to/cert&quot;</span>]
</span><span class='line'><span class="nt">&lt;/source&gt;</span>
</span></code></pre></td></tr></table></div></figure>


<h2>パフォーマンス</h2>

<p>手元のMBPで試して見たら，HTTPはin_httpより少し速かった．HTTPSは当たり前ですがｶﾞｸｯと落ちます．</p>

<p>クライアントはRubyの<code>net/http</code>を使って，小さめのjsonを<code>application/json</code>で送ってます．</p>

<ul>
<li>in_http</li>
</ul>


<p>平均2400 events/secくらい．</p>

<pre><code>2014-07-20 19:02:30 +0900 [info]: plugin:out_flowcounter_simple count:2318      indicator:num   unit:second
2014-07-20 19:02:31 +0900 [info]: plugin:out_flowcounter_simple count:2420      indicator:num   unit:second
2014-07-20 19:02:32 +0900 [info]: plugin:out_flowcounter_simple count:2383      indicator:num   unit:second
2014-07-20 19:02:33 +0900 [info]: plugin:out_flowcounter_simple count:2399      indicator:num   unit:second
2014-07-20 19:02:34 +0900 [info]: plugin:out_flowcounter_simple count:2382      indicator:num   unit:second
</code></pre>

<ul>
<li>in_http_puma</li>
</ul>


<p>平均2500 events/secくらい．Ojを使ったらもっと速くなるかと思ったけど，ほぼ誤差の範囲だった．</p>

<pre><code>2014-07-20 19:01:12 +0900 [info]: plugin:out_flowcounter_simple count:2472      indicator:num   unit:second
2014-07-20 19:01:13 +0900 [info]: plugin:out_flowcounter_simple count:2550      indicator:num   unit:second
2014-07-20 19:01:14 +0900 [info]: plugin:out_flowcounter_simple count:2294      indicator:num   unit:second
2014-07-20 19:01:15 +0900 [info]: plugin:out_flowcounter_simple count:2537      indicator:num   unit:second
2014-07-20 19:01:16 +0900 [info]: plugin:out_flowcounter_simple count:2538      indicator:num   unit:second
</code></pre>

<ul>
<li>in_http_puma with VERIFY_NONE client</li>
</ul>


<p>平均400 events/secくらい．けどVERIFY_NONEはほとんど本番では使われないので参考程度．</p>

<pre><code>2014-07-20 19:04:06 +0900 [info]: plugin:out_flowcounter_simple count:406       indicator:num   unit:second
2014-07-20 19:04:07 +0900 [info]: plugin:out_flowcounter_simple count:365       indicator:num   unit:second
2014-07-20 19:04:08 +0900 [info]: plugin:out_flowcounter_simple count:400       indicator:num   unit:second
2014-07-20 19:04:09 +0900 [info]: plugin:out_flowcounter_simple count:399       indicator:num   unit:second
2014-07-20 19:04:10 +0900 [info]: plugin:out_flowcounter_simple count:400       indicator:num   unit:second
</code></pre>

<ul>
<li>in_http_puma with VERIFY_PEER client</li>
</ul>


<p>平均320 events/secくらい．高負荷環境で無ければ大丈夫かな…？</p>

<pre><code>2014-07-20 19:05:18 +0900 [info]: plugin:out_flowcounter_simple count:329       indicator:num   unit:second
2014-07-20 19:05:19 +0900 [info]: plugin:out_flowcounter_simple count:327       indicator:num   unit:second
2014-07-20 19:05:20 +0900 [info]: plugin:out_flowcounter_simple count:327       indicator:num   unit:second
2014-07-20 19:05:21 +0900 [info]: plugin:out_flowcounter_simple count:325       indicator:num   unit:second
2014-07-20 19:05:22 +0900 [info]: plugin:out_flowcounter_simple count:326       indicator:num   unit:second
</code></pre>

<h2>まとめ</h2>

<p>モダンと言われるPumaってどんなもんなんだろう？と調べてたら，HTTPSを標準でサポートしてるし，ライブラリとしても簡単に使えそうだったので試して見たら，それなりにパフォーマンスが出たので公開してみたという感じです．<br />
Pumaなので，今後FluentdがJRubyとかサポートしても普通にそのまま使えると思います．</p>

<p>実際HTTPSを処理するならFluentdの前にNginxとかを置いた方が良いのだけど，バックエンドでも通信はHTTPSでやってるとかなんか縛りがあるような環境では，手軽に使えるのではないかと思います．</p>

<p>何かあれば<a href="https://github.com/repeatedly/fluent-plugin-http-puma">issue/pull request</a>に投げてもらえれば対応します．</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Prestoソースコードリーディング #4]]></title>
    <link href="http://repeatedly.github.com/ja/2014/07/presto-scr-4/"/>
    <updated>2014-07-17T17:53:00+09:00</updated>
    <id>http://repeatedly.github.com/ja/2014/07/presto-scr-4</id>
    <content type="html"><![CDATA[<p><a href="http://atnd.org/events/53545">Presto ソースコードリーディング #4</a></p>

<p>いつものようにLINEでやりました！</p>

<p>@frsyukiが帰国する前に，という流れで開催決定・募集が1週間前というタイトなスケジュールでしたが，
無茶ぶりにつきあってくれた@ueshinさんに感謝．</p>

<h2>当日の内容</h2>

<p><a href="http://togetter.com/li/694128">togetterのまとめ</a>を見れば，なんとなく大まかな流れは把握できるはず…！</p>

<p>ueshinさんが第二回のashigeruさんの論理計画実行の後を継いで，
物理計画実行周りの話をしてくれました(<a href="https://gist.github.com/ueshin/5e38cfe915ce15f756b1">資料のgist</a>)．
バイトコード生成しての高速化の話とか，Presto以外でも有用な話が出てました．</p>

<p>frsyukiが現在のPrestoの開発体制の話，Treasure Dataでハックしている所の紹介，
CREATE VIEWなどの実装がなぜこうなっているのか(これはfrsyuki案が通ったらしい)，
今後Prestoチームがやろうとしていることなど含め，その場で色々と議論する感じになりました．</p>

<h2>まとめ</h2>

<p>少人数でソースコードレベルで興味のある人が集まっているのもあり，いつも通り濃い感じでした！
partitionedの話とか，現在の実行モデルにおけるオペレータの実装の話とか，
この辺を話すイベントはあんまりないんじゃないかなと思います．</p>

<p>次第5回をいつやるかは決まってませんが，いずれやる予定です．</p>

<p>またソースコードリーディングとは別に，Prestoのユースケースや，
プロダクションで動かしている人の運用の話などを共有する，
Presto meetupみたいなもう少し緩めのイベントもやる予定です．</p>

<p>お楽しみに :)</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Release fluent-plugin-multi-format-parser]]></title>
    <link href="http://repeatedly.github.com/ja/2014/07/release-fluent-plugin-multi-format-parser/"/>
    <updated>2014-07-13T21:00:00+09:00</updated>
    <id>http://repeatedly.github.com/ja/2014/07/release-fluent-plugin-multi-format-parser</id>
    <content type="html"><![CDATA[<p><a href="https://github.com/repeatedly/fluent-plugin-multi-format-parser">fluent-plugin-multi-format-parser</a></p>

<p>一つのログファイルの中に複数のフォーマットがある時に利用可能なパーサプラグイン書きました．</p>

<h2>使い方</h2>

<p>fluent-gemでインストール．</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>$ fluent-gem install fluent-plugin-multi-format-parser</span></code></pre></td></tr></table></div></figure>


<p>インストールすると，TextParserを利用している<code>in_tail</code>や<code>in_udp</code>などで<code>multi_format</code>が使えるようになります．
そこで<code>&lt;pattern&gt;</code>を複数並べてください．<code>&lt;pattern&gt;</code>内の各設定は，利用するパーサにそのまま渡されます．</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
</pre></td><td class='code'><pre><code class='aconf'><span class='line'><span class="nt">&lt;source&gt;</span>
</span><span class='line'>  <span class="nb">type</span> udp
</span><span class='line'>  <span class="nb">tag</span> logs.multi
</span><span class='line'>
</span><span class='line'>  <span class="nb">format</span> multi_format
</span><span class='line'>  <span class="nt">&lt;pattern&gt;</span>
</span><span class='line'>    <span class="nb">format</span> apache
</span><span class='line'>  <span class="nt">&lt;/pattern&gt;</span>
</span><span class='line'>  <span class="nt">&lt;pattern&gt;</span>
</span><span class='line'>    <span class="nb">format</span> json
</span><span class='line'>  <span class="nt">&lt;/pattern&gt;</span>
</span><span class='line'>  <span class="nt">&lt;pattern&gt;</span>
</span><span class='line'>    <span class="nb">format</span> <span class="k">none</span>
</span><span class='line'>  <span class="nt">&lt;/pattern&gt;</span>
</span><span class='line'><span class="nt">&lt;/match&gt;</span>
</span></code></pre></td></tr></table></div></figure>


<p><code>&lt;pattern&gt;</code>を上から順番に試し，パース出来たらその結果を返します．上の設定例だと，最初に<code>apache</code>，次に<code>json</code>，最後に<code>none</code>になります．
たとえば，以下のようなログ群を<code>in_udp</code>に流すと</p>

<pre><code>192.168.0.1 - - [28/Feb/2013:12:00:00 +0900] "GET / HTTP/1.1" 200 777
{"k1":"v", "k2":123456}
foobar
</code></pre>

<p>以下のように処理されます．</p>

<pre><code>2013-02-28 12:00:00 +0900 test.**: {"host":"192.168.0.1","user":"-","method":"GET","path":"/","code":"200","size":"777"}
2014-07-13 20:56:55 +0900 test.**: {"k":"v","k1":123456}
2014-07-13 20:56:55 +0900 test.**: {"message":"foobar"}
</code></pre>

<h2>まとめ</h2>

<p>ログファイルの中に複数のフォーマットが混じるのは望ましいことではないのですが，どうしてもそういう状況が起きるときには，使ってみてください．</p>

<p>あと，実装はかなり単純なので，パーサプラグインのサンプルにでもしてもらえればと思います．</p>

<p>何か要望があれば<a href="https://github.com/repeatedly/fluent-plugin-multi-format-parser">issue/pull request</a>に投げてもらえれば対応します．</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Release fluent-plugin-netflow]]></title>
    <link href="http://repeatedly.github.com/ja/2014/07/release-fluent-plugin-netflow/"/>
    <updated>2014-07-11T21:35:00+09:00</updated>
    <id>http://repeatedly.github.com/ja/2014/07/release-fluent-plugin-netflow</id>
    <content type="html"><![CDATA[<p><a href="https://github.com/repeatedly/fluent-plugin-netflow">fluent-plugin-netflow</a></p>

<p>CiscoのNetflowプロトコルを受け取るFluentdプラグインを書きました．
公開してみたら結構反応が良くて，地味にユーザが多そうですね…</p>

<h2>経緯</h2>

<p>Fluentdを調べていたユーザから「ログ収集基盤をFluentdベースにしたいんだけど，Netflowをパースするプラグインないの？」と言われたので，
さくっと作ってみました．<br />
「さくっと」と言ってもコアのパーサー部分はそのユーザが使っていたLogstashからポーティングしたやつなので，それなりにパース出来るはずです．
Pull Requestのおかげもあり，対応templateも少し増えてます．</p>

<h2>使い方</h2>

<p>fluent-gemでインストールするだけです．</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>$ fluent-gem install fluent-plugin-netflow</span></code></pre></td></tr></table></div></figure>


<p>その後，以下のように設定します．typeとtagは必須です．他のやつは適宜環境に合わせて設定してください．</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
</pre></td><td class='code'><pre><code class='aconf'><span class='line'><span class="nt">&lt;source&gt;</span>
</span><span class='line'>  <span class="nb">type</span> netflow
</span><span class='line'>  <span class="nb">tag</span> netflow.event
</span><span class='line'>
</span><span class='line'>  <span class="c"># optional parameters</span>
</span><span class='line'>  <span class="nb">bind</span> <span class="m">127.0.0.1</span>
</span><span class='line'>  <span class="nb">port</span> <span class="m">9555</span>
</span><span class='line'>
</span><span class='line'>  <span class="c"># optional parser parameters</span>
</span><span class='line'>  <span class="err">cache_</span><span class="nb">ttl</span> <span class="m">6000</span>
</span><span class='line'>  <span class="nb">versions</span> [5, <span class="m">9</span>]
</span><span class='line'>  <span class="nb">definitions</span> <span class="sx">/path/to/your_definitions.yml</span>
</span><span class='line'><span class="nt">&lt;/match&gt;</span>
</span></code></pre></td></tr></table></div></figure>


<p>今現在はin_syslogの影響もあってデフォルトポートが5140のままなのですが，0.1.0を出す時に変更する予定です．</p>

<h2>TODO</h2>

<ul>
<li>俺自身がNetflow関係のやつを持っていないので，使っている人，誰かメンテナになってください！実環境でのテストが出来ませんｗ</li>
<li>Fluentd v0.10.52が出たら，FluentdのSocketUtilベースで書き直して，0.1.0を出す</li>
</ul>


<p>他，何か要望があれば<a href="https://github.com/repeatedly/fluent-plugin-netflow">issue/pull request</a>をしてもらえれば対応します．</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Fluentd v1 and Roadmapというプレゼンをしてきた]]></title>
    <link href="http://repeatedly.github.com/ja/2014/05/fluentd-v1-and-roadmap/"/>
    <updated>2014-05-15T18:55:00+09:00</updated>
    <id>http://repeatedly.github.com/ja/2014/05/fluentd-v1-and-roadmap</id>
    <content type="html"><![CDATA[<p><a href="http://eventdots.jp/event/49560">Fluentd Meetup 新しい応用事例とv1に関する発表</a></p>

<p>フリークアウトさんのオフィスでFluentd Meetupがあり，Fluentdのv1について話してきました．</p>

<iframe src="http://www.slideshare.net/slideshow/embed_code/34652297?rel=0" width="427" height="356" frameborder="0" marginwidth="0" marginheight="0" scrolling="no" style="border:1px solid #CCC; border-width:1px 1px 0; margin-bottom:5px; max-width: 100%;" allowfullscreen> </iframe>


<p> <div style="margin-bottom:5px"> <strong> <a href="https://www.slideshare.net/treasure-data/fluentd-v1-and-roadmap" title="Fluentd v1 and Roadmap" target="_blank">Fluentd v1 and Roadmap</a> </strong> from <strong><a href="http://www.slideshare.net/treasure-data" target="_blank">Treasure Data, Inc.</a></strong> </div></p>

<p>今回の発表は，今までのv11やv1に関してのまとめ的な発表になっています．<br />
以下のリンク集を見れば，発表内容の大抵はカバー出来ると思います．
また，他の方もまとめ記事とかを書かれているので，そちらも参照してください．</p>

<ul>
<li><a href="http://repeatedly.github.io/ja/2014/03/about-fluentd-v11/">そろそろFluentd v11についてひとこと言っておくか</a></li>
<li><a href="https://github.com/fluent/fluentd/issues/251">Plan for v1 release #251</a></li>
<li><a href="https://github.com/fluent/fluentd/issues/317">Support JRuby #317</a></li>
<li><a href="https://github.com/fluent/fluentd/tree/windows">FluentdのWindowsブランチ</a></li>
<li><a href="https://github.com/fluent/fluentd/pull/293">Add &#8211;use-v1-config option to enable new configuration format #293</a></li>
<li><a href="https://github.com/repeatedly/omnibus-td-agent">td-agent2のパッケージリポジトリ</a></li>
</ul>


<p>俺の方から言えることは，Fluentd v0.10.46以降を使っている方は，
積極的に<code>--use-v1-config</code>オプションを使ってくださいということです．<br />
既存のフォーマットとの違いは<a href="http://docs.fluentd.org/articles/config-file#v1-format">ドキュメントを参照</a>してください．</p>

<p>td-agent2は今ビルド中で，今週末あたりにリリースしたいと思ってます(パッケージングツールをアップデートしたら色々と壊れて無駄に時間が…)．
それ以降はv1にリソースを割けるはずなので，フィルタやラベルなどを実装していく予定です．ご期待ください！</p>

<p>また，Treasure DataはFluentdの開発者含め<a href="http://www.treasuredata.com/jp/about/careers.php">人材を募集している</a>ので，
興味のある方はぜひぜひコンタクトをしてもらえればと思います！</p>

<p>P.S.</p>

<p>フリークアウトさんのオフィスにある，バスケのゴールにダンク出来なかったのが悔しいので，足腰鍛え直す．</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[MultiOS testing for Fluentd repository on Travis CI]]></title>
    <link href="http://repeatedly.github.com/2014/05/multios-testing-for-fluentd-repository-on-travis-ci/"/>
    <updated>2014-05-15T14:22:00+09:00</updated>
    <id>http://repeatedly.github.com/2014/05/multios-testing-for-fluentd-repository-on-travis-ci</id>
    <content type="html"><![CDATA[<p>Recently, Travis CI announces &#8220;Multi-OS feature&#8221; on their blog.</p>

<p><a href="http://blog.travis-ci.com/2014-05-13-multi-os-feature-available/">Multi-OS Feature Available</a></p>

<p>If this feature is enabled, our project can be tested on both Linux and Mac OS X. <br />
Multi OS feature has been enabled for <a href="https://github.com/fluent/fluentd/commit/e4bb4f61e91c70a95690d19b07414b485e7a3542">Fluentd repository</a>. See following build:</p>

<p><a href="https://travis-ci.org/fluent/fluentd/builds/25147077">fluent/fluentd on Travis CI</a></p>

<p>This is very useful for checking commit and PR. Thanks Travis CI and Facebook team!</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[The status of Cool.io]]></title>
    <link href="http://repeatedly.github.com/2014/05/the-status-of-coolio/"/>
    <updated>2014-05-06T02:55:00+09:00</updated>
    <id>http://repeatedly.github.com/2014/05/the-status-of-coolio</id>
    <content type="html"><![CDATA[<p><a href="https://github.com/tarcieri/cool.io">Cool.io</a> was revived after I became a maintainer. This article describes the current stauts and future work of Cool.io.</p>

<p>Cool.io is a core of <a href="http://fluentd.org/">Fluentd</a> so I am focusing Fluentd related features.</p>

<h2>Windows support</h2>

<p>Cool.io is the one of blocker for Fluentd Windows support. Since version 1.2, Cool.io works on Windows and I release mingw based cross-compiling gem for Windows environment.</p>

<p>You can now use Cool.io via <code>gem install cool.io</code> on Windows and we started to implement <a href="https://github.com/fluent/fluentd/tree/windows">Windows support of Fluentd</a>.</p>

<h3>The limitation on Windows</h3>

<p>Cool.io uses <code>select</code> on Windows, not IOCP. In this result, the performance isn&#8217;t better than other environments.
This limitation is of little concern in Fluentd forward use-case.</p>

<h2>JRuby support</h2>

<p>Fluentd works on CRuby and Rubinius. If support JRuby, Fluentd will work on almost popular Ruby environemnts.</p>

<p>Since May 2014, <a href="https://github.com/taichi">@taichi</a> started to implement <a href="https://github.com/tarcieri/cool.io/issues/32">JRuby support</a>. @taichi has experience with Java and evented IO frameworks so he is a good person for this task ;)</p>

<h2>Remove Ruby 1.8 support</h2>

<p>Ruby 1.8 is dead language so Cool.io removes 1.8 support since version 1.2.</p>

<h2>Remove HttpClient</h2>

<p>AFAIK, there is no HttpClient users including Fluentd. This class depends on Ragel to parse HTTP. It increases the maintenance cost and hard to support on cross platform.</p>

<p>So HttpClient will not be maintained in the future.</p>

<h2>Conclusion</h2>

<p>Cool.io isn&#8217;t dead and Cool.io is still improved. We are now working on more better environment support and fixing the bugs.</p>

<p>If you have a bug of Cool.io, then please file it on github :)</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[札幌 2014 冬]]></title>
    <link href="http://repeatedly.github.com/ja/2014/03/sapporo-2014-winter/"/>
    <updated>2014-03-22T15:41:00+09:00</updated>
    <id>http://repeatedly.github.com/ja/2014/03/sapporo-2014-winter</id>
    <content type="html"><![CDATA[<p>二つのイベントに参加するため，札幌に行ってました．</p>

<h2><a href="http://www.hicta.or.jp/index_oshirase_detail.php?id=624">技術セミナー２０１４～ビッグデータ時代のＩＴシーズ～</a></h2>

<p>北海道IT推進協会さまのイベントで，ビッグデータとかデータ解析周りについてクラウド要素も含めて，ビジネス的な話をしてきました．
参加者に経営者の方も多い感じだったので，なるべく技術的な用語は使わないよう心がけて講演．</p>

<p>いつもとは違う雰囲気の中での講演で，こういうのも勉強になって良いかなと．</p>

<h2><a href="http://connpass.com/event/5222/">AWS勉強会 in 北海道札幌！</a></h2>

<p>メインは上のイベントだったのだけど，それだけで北海道を去るのも勿体ないなぁと他のイベントを探していたら</p>

<blockquote class="twitter-tweet" data-conversation="none" lang="en"><p>話す側でお願いしますw <a href="https://twitter.com/repeatedly">@repeatedly</a> あれ，よく見たらクラスメソッドさんの勉強会が次の日にある．これに参加しようかな？ &gt; &quot;AWS勉強会 in 北海道札幌！（懇親会有）&quot; <a href="http://t.co/doSVv4FPb8">http://t.co/doSVv4FPb8</a></p>&mdash; よこたさとし (@sato_shi) <a href="https://twitter.com/sato_shi/statuses/441211073375371264">March 5, 2014</a></blockquote>


<script async src="http://repeatedly.github.com//platform.twitter.com/widgets.js" charset="utf-8"></script>


<p>とのreplyをもらったので，飛び入りでFluentdについて発表してきました．</p>

<iframe src="http://www.slideshare.net/slideshow/embed_code/32700881?rel=0" width="427" height="356" frameborder="0" marginwidth="0" marginheight="0" scrolling="no" style="border:1px solid #CCC; border-width:1px 1px 0; margin-bottom:5px; max-width: 100%;" allowfullscreen> </iframe>


<p> <div style="margin-bottom:5px"> <strong> <a href="https://www.slideshare.net/treasure-data/fluentd-and-aws-at-classmethod" title="Fluentd and AWS at classmethod" target="_blank">Fluentd and AWS at classmethod</a> </strong> from <strong><a href="http://www.slideshare.net/treasure-data" target="_blank">Treasure Data, Inc.</a></strong> </div></p>

<p>Fluentd利用者も少なかったので，基本的な動作原理や，Fluentdが有用なユースケース，
AWSなイベントなのでAWS関係のプラグインの紹介などなど，一通りやった．</p>

<p>懇親会で色々と話を聞いたけど，まだ地方？だとそもそもデータを集めてなかったり，
データ解析に関しての需要が出てきておらず，Fluentdなどを使う段階になってないとのこと．
そもそもIT化出来てない会社とかもあるのでまずはそこから，とも<br />
東京とかだとこの辺の動きが活発だけど，中央以外ではまた違った形で活動しないと，
「便利なソフトウェアがある！」とかで広めることは出来ないなぁと実感．<br /></p>

<p>色々と考えないと行けないことが増えた感じで，この辺の話を聞けたのは良かった．</p>

<h2>まとめ</h2>

<p><img src="http://repeatedly.github.com/images/kinki_sushi.jpg" title="&#34;Kinki no Sushi&#34;" alt="&#34;Kinki no Sushi&#34;"></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[そろそろFluentd v11についてひとこと言っておくか]]></title>
    <link href="http://repeatedly.github.com/ja/2014/03/about-fluentd-v11/"/>
    <updated>2014-03-05T19:40:00+09:00</updated>
    <id>http://repeatedly.github.com/ja/2014/03/about-fluentd-v11</id>
    <content type="html"><![CDATA[<p>リリースは永遠にされません！</p>

<p>日本では色々なところでv11の噂がまことしやかに囁かれていますが，
俺がメインメンテナである限りv11がリリースされることはないので，諦めてv0.10.xを使ってください！</p>

<p>以下まじめな話になります．</p>

<h2>v11が生まれた背景と現状</h2>

<p>v11が生まれたのは1年以上前です．背景には，v10と呼ばれる今のバージョンがプロトタイプを兼ねたリリースであり，
「利用者のフィードバックを取り込んで，ダメな所をガッツリ書き換えて互換性を壊してメジャーバージョンアップや！」という流れがありました．</p>

<p>しかし，v10は十分に柔軟でかつパフォーマンスも発揮しており，コミッタ陣はそれほどモチベーションがあったわけではありません．
また，プラグインによって解決出来た問題も多く，v11が生まれた時ほどユーザから「v11が欲しい！」という要望は聞かれなくなりました．</p>

<p>当たり前ですが，ユーザからの声がなければ「あれ，じゃあこの機能あんまり必要ないんじゃね？」ということになって削られるのはよくあることで，
v11もそんな感じで開発リソースはあまり割かれなくなって行きました．<br />
もともと空いた時間に@frsyuki，@tagomoris，@sonotsの人達がたまにコミットしていたくらいなので，直近では機能追加のコミットはほぼありません．</p>

<h2>Fluentdのユーザ拡大</h2>

<p>v11で互換性を壊しても大丈夫だろう，とコミッタ陣が思っていたものの一つに，当時Fluentdのプラグインの大半をコミッタの関係者が書いていた，
というのがあります．<br />
そのため，互換性を壊しても必要そうなプラグインの書き換えはすぐに終わるし，
「えいや！」と同時にバージョン上げれば被害は少ないだろうという感じです．</p>

<p>しかし，v10は思っていたよりも早くユーザが増え，今ではさきがけとなったWeb/アドテク業界のみならず，大小問わず様々な企業，
IoTな分野など，世界的にも使われるようになってきました．<br />
また，それにともないプラグイン数も200を越え，当初の目論見が難しくなっているのが現状です．</p>

<h2>開発方針の変更とv1案</h2>

<p>俺がFluentdのメインメンテナとなったのも関わってるんですが，「v11のリリースをどうするか？」という問題もハンドリングするようになりました．</br />
個人的には「v11の機能群は有用だけど，互換性を壊してリリースするほどのものではないなぁ」というのがv11を見た結論であり，
その辺やりとりしたのが以下のtogetter．</p>

<p><a href="http://togetter.com/li/620329">Fluentd v11 なんてなかったんだ</a></p>

<p>上のまとめにあるように，色々と話した結果，v11が持っているいくつかの機能をv10にマージし，
それらが終わったらv1としてリリースしようというのが，現在の開発の方向性です．<br />
段階的な変化になりますが，基本的には互換性が保たれるようにAPIを変えていくので，
既存ユーザはそのまま使えますし，バージョンアップにともなって徐々に有用な機能が使えるようになります．<br /></p>

<p>以下のissueで必要そうな機能リストと，進捗を管理してます．</p>

<p><a href="https://github.com/fluent/fluentd/issues/251">Plan for v1 release</a></p>

<p>v1というバージョンに関しては，今のFluentdのgemのバージョンがv0.10.xで，v0.11.xのことをv11と呼んでいて非常に紛らわしく，
新しく入ってくるユーザとかを考えるとそろそろまじめにバージョニングした方が良いだろうという考えです．<br />
v1だと安定版のイメージが強いですし，実際の所v0.10.xはv1でもおかしくない機能セットはすでに持っています．</p>

<h2>まとめ</h2>

<p>ということで，色々と今までの流れを書きましたが，皆さんFluentdを今後とも宜しくお願いします :)</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Sensu雑感]]></title>
    <link href="http://repeatedly.github.com/ja/2014/02/the-thoughts-of-sensu/"/>
    <updated>2014-02-25T02:15:00+09:00</updated>
    <id>http://repeatedly.github.com/ja/2014/02/the-thoughts-of-sensu</id>
    <content type="html"><![CDATA[<p><a href="http://sensuapp.org/">Sensu</a></p>

<p>最近人気が出てきているようなので試して見た．
仕組みに関しては本家のドキュメントとかスライドとか見ると大体分かる．</p>

<p>雑感:</p>

<ul>
<li>server, client, api, dashboardに分かれているのは良い

<ul>
<li>実装はRubyでシンプルに書かれているように見える．多分弄るのは簡単</li>
</ul>
</li>
<li>RabbitMQとRedisが必要なのが試すのに結構つらい．chefとかpuppetを使うと良いらしい？

<ul>
<li>なんかテストモードがあるなら知りたい</li>
<li>ドキュメントは最低限はある．Advancedなことしようとするとgithubとか先人を頼ることになる</li>
</ul>
</li>
<li>設定がJSONなのはいいけど，ログすらJSONなのは徹底している</li>
<li>RabbitMQにはクライアントから登録しにいくようで，勝手に監視対象が増えるのは楽

<ul>
<li>マスターからのpullは限界があるので，この仕組みはモニタリングでは筋が良さそう</li>
</ul>
</li>
<li>プラグインは簡単に書けるが，現状失敗したら諦める前提らしい

<ul>
<li>まじめにハンドリングするなら，他のと連携する必要がある</li>
</ul>
</li>
<li>apiが気がつけば落ちてる時があって，原因がよく分からない</li>
<li>Fluentdのハンドラがコミュニティプラグインになかったので<a href="https://github.com/sensu/sensu-community-plugins/blob/master/handlers/notification/fluentd.rb">書いた</a></li>
</ul>


<p>「FluentdかSensuかどっちかに寄せたい」みたいな記事を誰かが書いてた記憶があるけど，何となく分かる．
Fluentdのプラグイン機構でSensuのクライアント周りの機構はよりロバストに実装出来る．<br />
コアの機能は結構シンプルなので，visualizationまで考えるとどうしたもんかという感じ．</p>

<p>Sensuはモニタリングのためのフレームワークなのでその辺の機能が中心に開発されてるけど，
そこの尖った部分が必要でなければ，RabbitMQとかと相まって結構大がかりにも見える．<br />
Nagiosとかは使ったことはないので，その辺と違ってどこまでメリットがあるのかはよく分かってないけど，
新しく作るシステムで一からモニタリングシステムを構築するなら十分有り．</p>

<p>仕組み的には柔軟でAPIとかで管理も楽に出来るようになってるので，今後ユーザは増えそうな気もしている．
しかしRabbitMQとRedisの二つ必要なのどうにかならないものか…</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Developer Summit 2014]]></title>
    <link href="http://repeatedly.github.com/ja/2014/02/developer-summit-2014/"/>
    <updated>2014-02-16T19:53:00+09:00</updated>
    <id>http://repeatedly.github.com/ja/2014/02/developer-summit-2014</id>
    <content type="html"><![CDATA[<p><a href="http://event.shoeisha.jp/devsumi/20140213/">Developers Summit 2014：開発者のためのITカンファレンス</a></p>

<p>セッション登壇も兼ねて，初めてデブサミに参加してきました．</p>

<h2>1日目</h2>

<p><a href="http://event.shoeisha.jp/devsumi/20140213/session/394/">OSSコミッタ大集合</a></p>

<p>これに登壇してました．登壇といっても，それぞれのプロジェクトの人がわいわいと自分の関わってるプロジェクトについて
交互に話すというもので，FluentdとD言語の時に壇上にあがってあれやこれや話しました．<br />
まぁFluentdに関しては登壇して何も喋らずに降りましたが…prz</p>

<p>セッションに関係ないですが登壇者控え室，和室でネットワークも電源もありで環境良すぎて超快適だった．雅叙園良いですね．</p>

<h2>2日目</h2>

<p>「Webの現在過去未来」のセッションなど気になるのがあったのですが，雪が降りすぎていたので参加しませんでした！</p>

<p>それとは別に，渋谷でRubyコミッタ3人との飲み会があり，鍋をつつきつつ色々と話をした．
その結果，Focuslightのメンテナが正式に決まり，FluentdにはLinux kernel &amp; Rubyコミッタであるkosakiさんがjoin．良い鍋でした．</p>

<blockquote class = "twitter-tweet" lang = "en"><p><a href = "https://twitter.com/sora_h">@sora_h</a> and <a href = "https://twitter.com/sonots">@sonots</a> are now focuslight committer! This is great step for growing <a href = "https://twitter.com/search?q = %23Fluentd&amp;src = hash">#Fluentd</a> visualization environment :)</p>&mdash; Mr. Fiber (@repeatedly) <a href = "https://twitter.com/repeatedly/statuses/434379434435436545">February 14, 2014</a></blockquote>


<script async src = "http://repeatedly.github.com//platform.twitter.com/widgets.js" charset = "utf-8"></script>




<blockquote class = "twitter-tweet" lang = "en"><p><a href = "https://twitter.com/kosaki55tea">@kosaki55tea</a> is now Fluentd committer! We can improve Fluentd more quickly :) <a href = "https://twitter.com/search?q = %23fluentd&amp;src = hash">#fluentd</a></p>&mdash; Mr. Fiber (@repeatedly) <a href = "https://twitter.com/repeatedly/statuses/434395924224167936">February 14, 2014</a></blockquote>


<script async src = "http://repeatedly.github.com//platform.twitter.com/widgets.js" charset = "utf-8"></script>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Analyze event logs using Fluentd and Elasticsearch]]></title>
    <link href="http://repeatedly.github.com/2014/02/analyze-event-logs-using-fluentd-and-elasticsearch/"/>
    <updated>2014-02-12T17:25:00+09:00</updated>
    <id>http://repeatedly.github.com/2014/02/analyze-event-logs-using-fluentd-and-elasticsearch</id>
    <content type="html"><![CDATA[<p><a href="http://fluentd.org/">Fluentd</a> is a flexible and robust event log collector, but Fluentd doesn&#8217;t have own data-store and Web UI.
If you want to analyze the event logs collected by Fluentd, then you can use <a href="http://www.elasticsearch.org/">Elasticsearch</a> and <a href="http://www.elasticsearch.org/overview/kibana/">Kibana</a> :)</p>

<p>Elasticsearch is an easy to use Distributed Search Engine and Kibana is an awesome Web front-end for Elasticsearch.</p>

<h2>Setup</h2>

<p>I tested on Mac OS X.</p>

<h3>Pre requirements</h3>

<ul>
<li>Java for Elasticsearch</li>
</ul>


<p>Use Mac OS X&#8217;s Java.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class='sh'><span class='line'>% java -version
</span><span class='line'>java version <span class="s2">&quot;1.6.0_51&quot;</span>
</span><span class='line'>Java<span class="o">(</span>TM<span class="o">)</span> SE Runtime Environment <span class="o">(</span>build 1.6.0_51-b11-457-11M4509<span class="o">)</span>
</span><span class='line'>Java HotSpot<span class="o">(</span>TM<span class="o">)</span> 64-Bit Server VM <span class="o">(</span>build 20.51-b01-457, mixed mode<span class="o">)</span>
</span></code></pre></td></tr></table></div></figure>


<ul>
<li>Ruby for Fluentd</li>
</ul>


<p>In this article, I use my rbenv&#8217;s Ruby and Fluentd gem directly.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class='sh'><span class='line'>% ruby --version
</span><span class='line'>ruby 1.9.3p484 <span class="o">(</span>2013-11-22 revision 43786<span class="o">)</span> <span class="o">[</span>x86_64-darwin12.4.0<span class="o">]</span>
</span></code></pre></td></tr></table></div></figure>


<p>Note that Fluentd doesn&#8217;t work on Ruby 1.8.</p>

<h4>Treasure Agent (td-agent)</h4>

<p>Treasure Agent, as known as <code>td-agent</code>, is a stable distribution which consists of Fluentd, popular plugins and own Ruby processor.
Many users use <code>td-agent</code> instead of Fluentd gem. See <a href="http://docs.fluentd.org/articles/faq#treasure-agenttd-agnt">this FAQ</a>.</p>

<h3>Elasticsearch</h3>

<p>Downlod and extract the latest package.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class='sh'><span class='line'>% curl -O https://download.elasticsearch.org/elasticsearch/elasticsearch/elasticsearch-0.90.11.tar.gz
</span><span class='line'>% tar zxvf elasticsearch-0.90.11.tar.gz
</span><span class='line'>% <span class="nb">cd </span>elasticsearch-0.90.11/
</span></code></pre></td></tr></table></div></figure>


<p>I use version v0.90.11 but <a href="http://www.elasticsearch.org/blog/0-90-11-1-0-0-rc2-released/">v1.0 will be released</a> soon!</p>

<p>Start Elasticsearch:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
</pre></td><td class='code'><pre><code class='sh'><span class='line'>% ./bin/elasticsearch -f
</span><span class='line'><span class="o">[</span>2014-02-12 17:51:32,645<span class="o">][</span>INFO <span class="o">][</span>node                     <span class="o">]</span> <span class="o">[</span>Powerhouse<span class="o">]</span> version<span class="o">[</span>0.90.11<span class="o">]</span>, pid<span class="o">[</span>79737<span class="o">]</span>, build<span class="o">[</span>11da1ba/2014-02-03T15:27:39Z<span class="o">]</span>
</span><span class='line'><span class="o">[</span>2014-02-12 17:51:32,646<span class="o">][</span>INFO <span class="o">][</span>node                     <span class="o">]</span> <span class="o">[</span>Powerhouse<span class="o">]</span> initializing ...
</span><span class='line'><span class="o">[</span>2014-02-12 17:51:32,651<span class="o">][</span>INFO <span class="o">][</span>plugins                  <span class="o">]</span> <span class="o">[</span>Powerhouse<span class="o">]</span> loaded <span class="o">[]</span>, sites <span class="o">[]</span>
</span><span class='line'><span class="o">[</span>2014-02-12 17:51:34,319<span class="o">][</span>INFO <span class="o">][</span>node                     <span class="o">]</span> <span class="o">[</span>Powerhouse<span class="o">]</span> initialized
</span><span class='line'><span class="o">[</span>2014-02-12 17:51:34,320<span class="o">][</span>INFO <span class="o">][</span>node                     <span class="o">]</span> <span class="o">[</span>Powerhouse<span class="o">]</span> starting ...
</span><span class='line'><span class="o">[</span>2014-02-12 17:51:34,395<span class="o">][</span>INFO <span class="o">][</span>transport                <span class="o">]</span> <span class="o">[</span>Powerhouse<span class="o">]</span> bound_address <span class="o">{</span> inet<span class="o">[</span>/0:0:0:0:0:0:0:0%0:9300<span class="o">]}</span>, publish_address <span class="o">{</span> inet<span class="o">[</span>/192.168.1.112:9300<span class="o">]}</span>
</span><span class='line'><span class="o">[</span>2014-02-12 17:51:37,448<span class="o">][</span>INFO <span class="o">][</span>cluster.service          <span class="o">]</span> <span class="o">[</span>Powerhouse<span class="o">]</span> new_master <span class="o">[</span>Powerhouse<span class="o">][</span>tL1IC8xHSCudeVsFt4JFsQ<span class="o">][</span>inet<span class="o">[</span>/192.168.1.112:9300<span class="o">]]</span>, reason: zen-disco-join <span class="o">(</span>elected_as_master<span class="o">)</span>
</span><span class='line'><span class="o">[</span>2014-02-12 17:51:37,481<span class="o">][</span>INFO <span class="o">][</span>discovery                <span class="o">]</span> <span class="o">[</span>Powerhouse<span class="o">]</span> elasticsearch/tL1IC8xHSCudeVsFt4JFsQ
</span><span class='line'><span class="o">[</span>2014-02-12 17:51:37,492<span class="o">][</span>INFO <span class="o">][</span>http                     <span class="o">]</span> <span class="o">[</span>Powerhouse<span class="o">]</span> bound_address <span class="o">{</span> inet<span class="o">[</span>/0:0:0:0:0:0:0:0%0:9200<span class="o">]}</span>, publish_address <span class="o">{</span> inet<span class="o">[</span>/192.168.1.112:9200<span class="o">]}</span>
</span><span class='line'><span class="o">[</span>2014-02-12 17:51:37,493<span class="o">][</span>INFO <span class="o">][</span>node                     <span class="o">]</span> <span class="o">[</span>Powerhouse<span class="o">]</span> started
</span><span class='line'><span class="o">[</span>2014-02-12 17:51:37,505<span class="o">][</span>INFO <span class="o">][</span>gateway                  <span class="o">]</span> <span class="o">[</span>Powerhouse<span class="o">]</span> recovered <span class="o">[</span>0<span class="o">]</span> indices into cluster_state
</span></code></pre></td></tr></table></div></figure>


<h3>Kibana</h3>

<p>Latest Kibana, called Kibana 3, consists of only HTML and JavaScript,
so setup is very easy:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class='sh'><span class='line'>% curl -O https://download.elasticsearch.org/kibana/kibana/kibana-3.0.0milestone5.tar.gz
</span><span class='line'>% tar zxvf kibana-3.0.0milestone5.tar.gz
</span><span class='line'>% <span class="nb">cd </span>kibana-3.0.0milestone5/
</span></code></pre></td></tr></table></div></figure>


<p>Open index.html in the kibana directory:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='sh'><span class='line'>% open index.html
</span></code></pre></td></tr></table></div></figure>


<p>If you want to change Kibana configuration, please edit <code>config.js</code>, e.g. change elasticsearch URL.</p>

<h3>Fluentd</h3>

<p>Install Fluentd gem and <a href="https://github.com/uken/fluent-plugin-elasticsearch">Elasticsearch plugin</a>:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='sh'><span class='line'>% gem install fluentd fluent-plugin-elasticsearch
</span></code></pre></td></tr></table></div></figure>


<p>Fluentd configuration is below:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
</pre></td><td class='code'><pre><code class='apache'><span class='line'><span class="c"># es.conf</span>
</span><span class='line'><span class="nt">&lt;source&gt;</span>
</span><span class='line'>  <span class="nb">type</span> forward
</span><span class='line'><span class="nt">&lt;/source&gt;</span>
</span><span class='line'>
</span><span class='line'><span class="nt">&lt;match</span> <span class="s">es.**</span><span class="nt">&gt;</span>
</span><span class='line'>  <span class="nb">type</span> elasticsearch
</span><span class='line'>  <span class="err">logstash_</span><span class="nb">format</span> true
</span><span class='line'>  <span class="err">flush_</span><span class="nb">interval</span> <span class="m">5</span>s # <span class="m">5</span>s for testing. <span class="k">On</span> production environment, <span class="m">60</span>s or higher is better
</span><span class='line'><span class="nt">&lt;/match&gt;</span>
</span></code></pre></td></tr></table></div></figure>


<p>fluent-plugin-elasticsearch provides <code>logstash_format</code> option.
It enables Kibana to analyze the event logs with day based indexes.</p>

<p>Start Fluentd:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
</pre></td><td class='code'><pre><code class='sh'><span class='line'>% fluentd -c es.conf
</span><span class='line'>2014-02-12 18:43:31 +0900 <span class="o">[</span>info<span class="o">]</span>: starting fluentd-0.10.43
</span><span class='line'>2014-02-12 18:43:31 +0900 <span class="o">[</span>info<span class="o">]</span>: reading config file <span class="nv">path</span> <span class="o">=</span> <span class="s2">&quot;es.conf&quot;</span>
</span><span class='line'>2014-02-12 18:43:32 +0900 <span class="o">[</span>info<span class="o">]</span>: gem <span class="s1">&#39;fluent-plugin-elasticsearch&#39;</span> version <span class="s1">&#39;0.2.0&#39;</span>
</span><span class='line'>2014-02-12 18:43:32 +0900 <span class="o">[</span>info<span class="o">]</span>: gem <span class="s1">&#39;fluentd&#39;</span> version <span class="s1">&#39;0.10.43&#39;</span>
</span><span class='line'>2014-02-12 18:43:32 +0900 <span class="o">[</span>info<span class="o">]</span>: using configuration file: &lt;ROOT&gt;
</span><span class='line'>  &lt;<span class="nb">source</span>&gt;
</span><span class='line'>    <span class="nb">type </span>forward
</span><span class='line'>  &lt;/source&gt;
</span><span class='line'>  &lt;match es.**&gt;
</span><span class='line'>    <span class="nb">type </span>elasticsearch
</span><span class='line'>    logstash_format <span class="nb">true</span>
</span><span class='line'><span class="nb">    </span>flush_interval 5s
</span><span class='line'>  &lt;/match&gt;
</span><span class='line'>&lt;/ROOT&gt;
</span><span class='line'>2014-02-12 18:43:32 +0900 <span class="o">[</span>info<span class="o">]</span>: adding <span class="nb">source type</span> <span class="o">=</span> <span class="s2">&quot;forward&quot;</span>
</span><span class='line'>2014-02-12 18:43:32 +0900 <span class="o">[</span>info<span class="o">]</span>: adding match <span class="nv">pattern</span> <span class="o">=</span> <span class="s2">&quot;es.**&quot;</span> <span class="nb">type</span> <span class="o">=</span> <span class="s2">&quot;elasticsearch&quot;</span>
</span><span class='line'>2014-02-12 18:43:32 +0900 <span class="o">[</span>info<span class="o">]</span>: listening fluent socket on 0.0.0.0:24224
</span></code></pre></td></tr></table></div></figure>


<h2>Analyze event logs</h2>

<p>Send some events to Fluentd. <code>fluent-cat</code> is an utility command to send json text to Fluentd&#8217;s <code>in_forward</code> plugin.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class='sh'><span class='line'>% <span class="nb">echo</span> <span class="s1">&#39;{&quot;message&quot;:&quot;D&quot;}&#39;</span> | fluent-cat es.event <span class="c"># es.event is a tag. es.event matches es.** of &lt;match&gt;</span>
</span><span class='line'>% <span class="nb">echo</span> <span class="s1">&#39;{&quot;message&quot;:&quot;Ruby&quot;}&#39;</span> | fluent-cat es.event
</span><span class='line'>% <span class="nb">echo</span> <span class="s1">&#39;{&quot;message&quot;:&quot;Elasticsearch&quot;}&#39;</span> | fluent-cat es.event
</span><span class='line'>% <span class="nb">echo</span> <span class="s1">&#39;{&quot;message&quot;:&quot;msgpack&quot;}&#39;</span> | fluent-cat es.event
</span><span class='line'>% ...
</span></code></pre></td></tr></table></div></figure>


<p>After Fluentd flushed received events to Elasticsearch, you can analyze the event logs via Kibana!
Following image is one panel example:</p>

<p><img src="http://repeatedly.github.com/images/fluentd_kibana_elasticsearch.png" title="&#34;Fluentd, Elasticsearch and Kibana&#34;" alt="&#34;Fluentd, Elasticsearch and Kibana&#34;"></p>

<p>Kibana has some built-in panels, so you can create own dashboard easily. See <a href="http://demo.kibana.org/#/dashboard">Kibana demo</a></p>

<h2>Advanced tips</h2>

<p>If your service has a high traffic, then fluent-plugin-elasticsearch sometimes get stucked.
In this case, built-in <a href="http://docs.fluentd.org/articles/out_roundrobin">out_roundrobin plugin</a> is useful.
You can distribute a write request to elasticsearch nodes for load balancing.</p>

<p>Of course, putting Queue with multiple fluentd nodes is an another approach.</p>

<h2>Conclusion</h2>

<p>This article introduced Fluentd, Elasticsearch and Kibana combination to analyze the event logs.
These components are easy to setup and work fine, so you can try this framework soon!
I heard many companies have already tried / deployed this setup on production :)</p>

<p>Enjoy Fluentd and Elasticsearch!</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[高トラフィックでのFluentdからElasticsearchへの書き込み問題への対策]]></title>
    <link href="http://repeatedly.github.com/ja/2014/02/measures-for-fluentd-with-elasticsearch-issue-on-high-traffic/"/>
    <updated>2014-02-11T18:39:00+09:00</updated>
    <id>http://repeatedly.github.com/ja/2014/02/measures-for-fluentd-with-elasticsearch-issue-on-high-traffic</id>
    <content type="html"><![CDATA[<p><a href="http://blog.kakipo.com/trouble-with-fluentd-and-elasticsearch/">Fluentd -> Elasticsearch 大量データ転送でトラブル</a></p>

<p>上の記事にあるように，Elasticsearchに大量のデータを一気に流し込むと色々と問題が起きます．
元々検索エンジンはスケールさせるのが難しく，よく当たる問題だと思います．</p>

<p>また，Fluentdとかだとガンガンログを流し込むことも多く，この辺で詰まる云々はたまに聞きます．</p>

<p><a href="http://elasticsearch.doorkeeper.jp/events/7491">第3回elasticsearch勉強会</a></p>

<p>で，Elasticsearch勉強会にFlorianという本家のエンジニアが来ていたので，
懇親会でこの辺どうすればいいのか聞いてみました．
実際Elasticsearchユーザの中でもちょくちょく問題になるらしく，
大きくわけて二つの方法(またはこの組み合わせ)で回避しているようです．</p>

<h2>書き込み先のノードを増やす</h2>

<p>1ノードへの書き込みで詰まるなら，もっとノードを増やせば良いというアプローチ．
今のfluent-plugin-elasticsearchにはラウンドロビンの機能はないんですが，
out_roundrobinとかと組み合わせてやれば，書き込みを複数台に散らせることは出来そうです．</p>

<h2>前段にキューを置く</h2>

<p>書き込みをするノードの前にキューを置いて，そこでバッファリングしておくという方法．
Fluentdの場合はバッファがキューになっているので，そこのフラッシュ間隔を長めに調整するとか，
キュー系のプラグインがいくつかあるので，それを間に挟むという感じになるのかなと．<br />
ただ，キューから値をポップする間隔が短いと結局詰まるので，この辺は少し工夫が必要そうです．</p>

<h2>まとめ</h2>

<p>Elasticsearchを真面目に運用したことがないので，どっちが現実的なのかよく分からないのが正直な所．
この辺は高トラフィック環境で使っている人の話を聞きたい所です．</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Prestoソースコードリーディング #1]]></title>
    <link href="http://repeatedly.github.com/ja/2014/02/presto-scr-1/"/>
    <updated>2014-02-11T02:39:00+09:00</updated>
    <id>http://repeatedly.github.com/ja/2014/02/presto-scr-1</id>
    <content type="html"><![CDATA[<p><a href="http://atnd.org/events/47149">Presto ソースコードリーディング #1のATND</a></p>

<p>@tagomorisさんに場所を確保してもらって，LINEで第一回をやりました．</p>

<h2>開催の流れ</h2>

<p>CROSS辺りでPrestoのソースコードリーディングしたいね，という話が出て，
じゃあ俺が立てるので場所はLINE辺りで〜というその場のノリで決まった．</p>

<p>どうせ10人前後だろうということでかなり適当な感じで募集とかやってたんだけど，
応募人数が40人越え，当日参加が25人前後くらいだったので，予想より多かったかなという感じ．</p>

<h2>やったこと</h2>

<h3>全体の概要</h3>

<p>俺が軽めにやりました．Prestoの生まれた背景とか，依存している主要なライブラリ，
@frsyukiのスライドを拝借しての主要なクラス群の紹介，現在サポートしている型，
Slice使ってのデータの持ち方とか．後，最近の変更周りも少し紹介した</p>

<h3>HTTPレイヤー</h3>

<p>@tagomorisさんが担当で，クライアントが最初に到達するHTTP APIの <code>/v1/execution</code> や <code>/v1/statement</code> 周りの
処理の話．ソースコード的にはpresto-server．この辺もairliftにがっつり依存しているので，
パフォーマンスが気になるなど真面目に読みたい人はairliftも読みましょう．</p>

<h3>Execution</h3>

<p><a href="https://gist.github.com/oza/8912147">当日のgist</a></p>

<p>@oza_x86が担当．Coordinator内部でPlanやStageが出来るまでの流れ，
Workerで処理がどう進むかとかその辺の話．SplitsやそれぞれのRunnerの処理，
時間が掛かっているタスクの優先度下げるとか，工夫がいくつか見て取れた感じ．</p>

<h2>感想</h2>

<p>適当にやったわりにはそれなりに上手く進んで良かった．</p>

<p>第二回は，shot6さん，ashigeruさん，feeblefakieさん辺りが担当になってくれるかも？
という感じです．またソース読みつつあーだこーだ言い合いましょう．</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[New log_level parameter]]></title>
    <link href="http://repeatedly.github.com/2014/02/new-log-level-parameter/"/>
    <updated>2014-02-05T05:22:00+09:00</updated>
    <id>http://repeatedly.github.com/2014/02/new-log-level-parameter</id>
    <content type="html"><![CDATA[<p>In this week, <a href="https://groups.google.com/forum/#!topic/fluentd/ukJ999bDwxY">Fluentd v0.10.43 has been released</a>.
Since this version, Fluentd introduced <code>log_level</code> parameter in Input / Output plugin.
It enables you can set different log level separated from global log level, e.g. <code>-v</code>, <code>-q</code> command line option.</p>

<p>This article shows &#8220;How to support <code>log_level</code> option in your plugin.&#8221;</p>

<h2>log_level option use cases</h2>

<h3>Disable in_tail warning</h3>

<p><code>in_tail</code> prints &#8220;pattern no match&#8221; warning when receives invalid log. It is useful information for almost users, but some users want to ignore this log for other important plugin warning.</p>

<p>In this case, you can set &#8220;log_level error&#8221; in <code>in_tail</code> configuration to disable &#8220;pattern no match&#8221;.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class='aconf'><span class='line'><span class="nt">&lt;source&gt;</span>
</span><span class='line'>  <span class="nb">type</span> tail
</span><span class='line'>  ...
</span><span class='line'>  <span class="err">log_</span><span class="nb">level</span> <span class="k">error</span>
</span><span class='line'><span class="nt">&lt;/source&gt;</span>
</span></code></pre></td></tr></table></div></figure>


<h3>Debugging</h3>

<p>Without <code>log_level</code>, we get many verbose logs using <code>-vv</code> command line option for one plugin. With <code>log_level</code>, you can set verbose configuration in only one plugin.</p>

<p>It is useful for debugging a plugin on acutual environment.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class='aconf'><span class='line'><span class="nt">&lt;match</span> <span class="s">foo.**</span><span class="nt">&gt;</span>
</span><span class='line'>  <span class="nb">type</span> unstable_plugin
</span><span class='line'>  ...
</span><span class='line'>  <span class="err">log_</span><span class="nb">level</span> trace
</span><span class='line'><span class="nt">&lt;/match&gt;</span>
</span></code></pre></td></tr></table></div></figure>


<h2>Support log_level option in your plugin</h2>

<p>This section is for plugin developers.</p>

<p>First of all, Fluentd provides <code>$log</code> object as heretofore. So all plugin should work without changing on Fluentd v0.10.43 or later.</p>

<p>To suppot <code>log_level</code> is very easy. Replace <code>$log</code> with <code>log</code>. Following example is fluent-plugin-td&#8217;s diff:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class='diff'><span class='line'><span class="gd">-        $log.debug &quot;checking whether table &#39;#{key}&#39; exists on Treasure Data&quot;</span>
</span><span class='line'><span class="gi">+        log.debug &quot;checking whether table &#39;#{key}&#39; exists on Treasure Data&quot;</span>
</span></code></pre></td></tr></table></div></figure>


<h3>Support older Fluentd versions</h3>

<p>After replaced <code>$log</code> with <code>log</code>, your plugin only works on Fluentd v0.10.43 or later. If you want to support older Fluentd versions, you can use following code in your plugin.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
</pre></td><td class='code'><pre><code class='ruby'><span class='line'><span class="k">module</span> <span class="nn">Fluent</span>
</span><span class='line'>  <span class="k">module</span> <span class="nn">FooPluginOutput</span> <span class="o">&lt;</span> <span class="no">Output</span>
</span><span class='line'>    <span class="c1"># Define `log` method for v0.10.42 or earlier</span>
</span><span class='line'>    <span class="k">unless</span> <span class="nb">method_defined?</span><span class="p">(</span><span class="ss">:log</span><span class="p">)</span>
</span><span class='line'>      <span class="n">define_method</span><span class="p">(</span><span class="ss">:log</span><span class="p">)</span> <span class="p">{</span> <span class="vg">$log</span> <span class="p">}</span>
</span><span class='line'>    <span class="k">end</span>
</span><span class='line'>    <span class="o">.</span><span class="n">.</span><span class="o">.</span>
</span><span class='line'>  <span class="k">end</span>
</span><span class='line'><span class="k">end</span>
</span></code></pre></td></tr></table></div></figure>


<p>This code defines <code>log</code> method using <code>$log</code> when <code>log</code> method is not defined, so <code>log.error</code> is same as <code>$log.error</code> on older Fluentd.</p>

<p>fluent-plugin-td uses <a href="https://github.com/treasure-data/fluent-plugin-td/blob/1ae62326802ff998a38bbf040ddf0f4b236430ee/lib/fluent/plugin/out_tdlog.rb#L63">same approach</a>.</p>

<h2>Conculusion</h2>

<p><code>log_level</code> feature is very useful for Fluentd users. So if you have a time, please apply above changes and release new version plugin ;)</p>

<p>I will release new version of several plugins soon, S3, TD, Mongo and etc.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Fluentd v11 at Tokuben]]></title>
    <link href="http://repeatedly.github.com/ja/2014/01/fluentd-v11-at-tokuben/"/>
    <updated>2014-01-26T02:39:00+09:00</updated>
    <id>http://repeatedly.github.com/ja/2014/01/fluentd-v11-at-tokuben</id>
    <content type="html"><![CDATA[<p><a href="http://atnd.org/events/46924">@特勉</a>というイベントに呼ばれたので，Fluentd v11について発表してきました．</p>

<iframe src="http://www.slideshare.net/slideshow/embed_code/30427877?rel=0" width="427" height="356" frameborder="0" marginwidth="0" marginheight="0" scrolling="no" style="border:1px solid #CCC; border-width:1px 1px 0; margin-bottom:5px; max-width: 100%;" allowfullscreen> </iframe>


<p> <div style="margin-bottom:5px"> <strong> <a href="https://www.slideshare.net/treasure-data/fluentd-v11-at-tokuben" title="Fluentd v11 at tokuben" target="_blank">Fluentd v11 at tokuben</a> </strong> from <strong><a href="http://www.slideshare.net/treasure-data" target="_blank">Treasure Data, Inc.</a></strong> </div></p>

<p>今現在見えている機能群について一通りその背景とか，v10ではどうだったのかを絡めて話したので，上のスライドだけ見ても少しわかりにくいかもしれません．新しい機能の確認みたいな感じで眺めて貰えると．</p>

<p>特勉は今回はログ・データ解析がテーマでしたが，色々とテーマを変えて定期的にやるようなので，随時チェックしておくと良いと思います．</p>

<h2>その後…</h2>

<p><a href="http://togetter.com/li/620329">Fluentd v11 なんてなかったんだ</a></p>

<p>で，実はこの発表の次の日にTwitterで色々とやりとりがあり，上記のスライドに書かれているいくつかの機能は，v10に取り込まれる可能性が高いです．というか，v11そのものが消える可能性は普通にあります．</p>

<p>Fluentdそのものの改善では色々と考えていることはあるので，定期的にチェックして頂けると！後「v10でこういうところが使いにくい」とかあると，開発陣にフィードバックして貰えると助かります．</p>

<p>それでは！</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[CROSS 2014]]></title>
    <link href="http://repeatedly.github.com/ja/2014/01/cross-2014/"/>
    <updated>2014-01-18T23:57:00+09:00</updated>
    <id>http://repeatedly.github.com/ja/2014/01/cross-2014</id>
    <content type="html"><![CDATA[<p><a href="http://www.cross-party.com/">CROSS 2014</a>というイベントがあり，
<a href="http://www.cross-party.com/programs/distributed/">分散処理システムCROSS</a>というセッションのオーナーをやってきた．</p>

<h2>分散処理システムCROSS</h2>

<p>元々はログ収集で1セッションどうか，という話だった．が，
もうFluentdとかの話は色々な所でやってるし，ここで1時間やってもあんま成果はないだろうということでやめた．
そもそも日本でFluentd以外のログ収集プロジェクトで深い話を出来る人は希で，探すのがつらい．<br /></p>

<p>その変わり分散処理でも話が来ていたので，そっち側でどうにかやることにした．
分散処理だとなんかアルゴリズムとかそっち系の色が強くなりそうなので，とりあえずシステムをつけた．</p>

<h3>メンバ</h3>

<p>@oza_x86，@kuenishi，@shot6の三人にお願いした．時間を作って頂いてありがとうございました！
人選に関しては，少し前にTwitterでつぶやいたけど，以下のような感じで選んだ．</p>

<ul>
<li>分散処理システムを研究・開発している人</li>
<li>分散処理システムを開発・販売している人</li>
<li>分散処理システムを運用・サービスとして展開している人</li>
<li>分散処理システムの基盤を運用・提供している人</li>
</ul>


<p>事前打ち合わせの飲み会をやったけど，自己紹介して結局はなんか適当に喋りましょうということに．</p>

<h3>当日</h3>

<p>セッションが始まる前に，Hadoopやデータベースとかの入門的な話には多分ならないし，
他に面白そうなセッションがあるので〜，と誘導したにも関わらず，なんか結構人が入ってて驚いた！</p>

<p>色々と予防線は張ったものの，個人的には1時間それなりに話題は出せたんじゃないかと思ってます．
RaftやPaxosのような合意周り，Jepsenなどの分散処理システムの検証ツール，
Hadoopやその他のシステムの運用的な話，などなど．<br />
分散処理システムにおけるモデルの検証とかはやはり鬼門なので，今後色々と勉強したい所．</p>

<p>しかしモデレータというのは色々と疲れますね…</p>

<h2>その他のセッション</h2>

<h3>エンジニアの恋・愛・セックスのDevOps、ホントのところどうしたらいいの</h3>

<p>間に合わなくて参加出来なかったが，かなり反響があったセッションっぽい．
後で録画を見る．</p>

<h3>ぶつかり稽古</h3>

<p>セッションオーナーが登壇しないという酷いセッションだったｗ
けど内容そのものは，他社のレビュースタイルとか色々と知れて面白かった．</p>

<h3>アンカンファレンス</h3>

<p>Fluentd v11の話で登録したけど，雨の予報でも出社しないと噂の某モリスさんが一人でセッションの時間全部使い切り，
何も話せなかった．</p>

<h2>まとめ</h2>

<p>去年と違ってRed Bullガールがいないのが残念だった！来年は期待したい．</p>

<p>全体としては，Tシャツや雑誌の新刊も貰えたし，何人かリアルで合えたしで，色々とドタバタしたけど楽しかったので良し．皆さんお疲れ様でした！</p>

<p><img src="http://repeatedly.github.com/images/cross_2014.jpg" title="&#34;CROSS 2014 photo&#34;" alt="&#34;CROSS 2014 photo&#34;"></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[2013年の振り返り]]></title>
    <link href="http://repeatedly.github.com/ja/2014/01/2013-report/"/>
    <updated>2014-01-01T00:00:00+09:00</updated>
    <id>http://repeatedly.github.com/ja/2014/01/2013-report</id>
    <content type="html"><![CDATA[<p>転職したのもあり，色々と取り組むものが増えた年だった．</p>

<h2>D言語</h2>

<p>ちょっと割ける時間が減ったのもあり，全体的にD言語のコードを書く量は減ったかなと．
自分が欲しかった小さなライブラリはいくつか書いたりしたけど，
他にも書きたいのがあるので，2014年はガッツリ時間を取りたい．</p>

<ul>
<li><a href="http://repeatedly.github.io/2013/05/d-conference-2013/">D Conference 2013</a></li>
<li><a href="http://repeatedly.github.io/ja/2013/05/tdpl-japanese-edition/">プログラミング言語D</a></li>
</ul>


<p>その変わり，D言語の日本語書籍の出版に携わったりと，その他の活動はちょくちょくやった．</p>

<h2>Fluentd</h2>

<p>会社の関係もあってメインメンテナ的な立場になった．
Fluentdそのものの機能開発・メンテナンス含め，MLでの対応，イベントでの発表など色々やった．
2014年は，Windows対応にv11，それにtd-agentのRubyのバージョンアップなど，色々と課題は見えてたり．</p>

<p>MLに関しては，今かなり俺とkiyoto-sanの二人の独壇場な感じになっているので，
もう少し他の方の協力も欲しいと思ってたりします(その方が盛り上がっているように見えて良い)．<br />
特に日本は早期にヘビーユーザがついて色々と記事が増えたのもあり，他の国の人達より使いこなしているユーザが多いです．
なので英語の練習も兼ねて，簡単な質問にでも答えてくれる人が増えるといいな，と思ってます．<br />
日本の人はTwitterで質問し，海外の人はMLで質問する，というのがOSSやってて思う傾向ですね．</p>

<p>あと，Treasure Dataでは<a href="http://www.treasuredata.com/en/careers/careers-posting-004.php">Fluentdの開発者を募集している</a>ので，興味のある人は応募してみるといいかもしれません！</p>

<p>さらに，<a href="http://www.slideshare.net/treasure-data/treasure-agent-monitoring-service">年末発表したモニタリングシステム</a>のβユーザも随時募集しているので，
興味のある人は <a href="https://twitter.com/repeatedly">@repeatedly</a> にでも連絡して貰えればと思います．</p>

<h2>発表</h2>

<ul>
<li><a href="http://atnd.org/events/36713">Fluentd Casual Talks #2</a></li>
<li><a href="http://www.zusaar.com/event/501053">Fluentd meetup in Fukuoka</a></li>
<li><a href="http://repeatedly.github.io/ja/2013/03/the-architecture-of-data-analytics-paas-on-aws-jaws-days-2013-day2/">AWSを使ったデータ解析PaaSの裏側</a></li>
<li><a href="http://herokujp.doorkeeper.jp/events/3405">Heroku Meetup #8 TreasureData + Waza Report!!</a></li>
<li><a href="http://www.zusaar.com/event/873003">Monitoring Casual Talks #4</a></li>
<li><a href="http://repeatedly.github.io/ja/2013/07/july-tech-festa-2013/">July Tech Festa 2013</a></li>
<li><a href="http://atnd.org/events/44556">DevOps向けFluentd勉強会 at IPROS</a></li>
<li><a href="http://elasticsearch.doorkeeper.jp/events/6532">第2回elasticsearch勉強会</a></li>
<li><a href="http://www.ipsj.or.jp/event/s-seminar/2013/Exciting_Coding/">Exciting Coding! 2013</a></li>
</ul>


<p>とりあえず覚えている分だけリンクを貼ってみた．会社に関しての大きめな発表が増えたなと．</p>

<p>発表以外でも色々なイベントに参加して，FluentdやTDに関しての要望とかを聞いたりしていた．
これらで得たフィードバックは，ちゃんと吟味して取り込んでいきたい．</p>

<h2>まとめ</h2>

<p>ざっと振り返ってみた．
Fluentdに関しては，v10はもうコアでほぼやることがないので，次はv11が中心．
中心とは言っても，安定版として正式にリリースするのは当分先になる．多分．</p>

<p>2014年もOSS含め対外的な活動は積極的にしていきたいし，色々な人達と交流を増やして行きたい所．</p>

<p>今後も宜しくお願いします :)</p>
]]></content>
  </entry>
  
</feed>
