<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Go ahead!]]></title>
  <link href="http://repeatedly.github.com/atom.xml" rel="self"/>
  <link href="http://repeatedly.github.com/"/>
  <updated>2015-04-14T16:07:42+09:00</updated>
  <id>http://repeatedly.github.com/</id>
  <author>
    <name><![CDATA[Masahiro Nakagawa]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Fluentdの現実装のPros/Cons]]></title>
    <link href="http://repeatedly.github.com/ja/2015/04/fluentd-architecture-pros-and-cons/"/>
    <updated>2015-04-13T23:22:00+09:00</updated>
    <id>http://repeatedly.github.com/ja/2015/04/fluentd-architecture-pros-and-cons</id>
    <content type="html"><![CDATA[<p>TODO:</p>

<ul>
<li>必要なら図を足す</li>
<li>他に書いた方が良いPros/Consのリクエストがあったら追記</li>
</ul>


<h2>内部のイベントストリームの扱い</h2>

<ul>
<li>Pros: Inputがスケーラブルに実装しやすく，データストリームを正常時/エラー時で切り替えやすい</li>
<li>Cons: エラーハンドリングがブロッキングモデルよりも複雑になりやすい</li>
</ul>


<p>以下長々と理由書きます．</p>

<p>Fluentdはイベントストリームを効率良く，またロバストに扱うことを目的に設計されています．そのため，独自の転送プロトコル(forwardプラグイン)を実装していますし，内部のイベントのハンドリングもそれに沿うようになっています．ただ，それによって相性の悪い操作とかもあります．</p>

<p>Fluentdはバッファ機能を提供しており，これによって転送の効率化とエラー時のデータロスを防ぐ設計になっています．が，あまりにも書き込み先が遅いなどの問題があると，バッファの制限を超えてしまうことがあります．<br />
この時，FluentdはInputプラグインにエラーを返します．これによりInputプラグインはさらにエラーを外部にも伝搬させることが出来，forwardプラグインなら再送や，エラーが続くようならセカンダリに流すなどが出来るようになっています．これはデータストリームを流し続けるため，またInputプラグインがブロックせずに大量の入力を扱えるようにするため，こうなっています．</p>

<p>このモデルは，データがストリームではない過去ログの一括転送などと少し相性が悪いです．例えばtailを使って過去ログをElasticsearchに一気に流す時によく問題に当たるのですが，Elasticsearchは1台だと受け付けられるデータ量はそれほど多くなく(ここはチューニングに左右されます)，大量の過去ログを一気に送ろうとするとOutputプラグインのフラッシュ処理が追いつかなくなり，結果バッファが溜まりリミットを越え，Input側にエラーが返り続けることになります(tailの場合はひたすらリトライ)．</p>

<p>一方，Elasticsearchと一緒によく使われるLogstashはFluentdとは違うアプローチをとっています．内部には長さ固定のブロッキングキュー(Outputのバッファではない)がInputとOutputの間に存在しており，Inputはそのキューがあくまで処理がブロックします．<br />
そのため，上記のような過去ログの転送などでは，キューが空くまで処理は行われないので，Output側が詰まってもエラーなどにはなりません．その変わりブロックしているため，外部からデータが送られてくるようなケースにおいては，このブロックがどんどん伝搬していくので，大量・多数の入力を捌くのが難しくなります．</p>

<p>この辺に関しては最近のイベントでも言及されてました(ここで言われているログが抜ける云々はInput側の問題ではなくて，ESが高負荷になりすぎてES側でrejectされてるんだと思います．<a href="https://www.elastic.co/blog/performance-considerations-elasticsearch-indexing">この記事</a>参照)．</p>

<blockquote class="twitter-tweet" lang="en"><p>fluentdは日本では流行ってるけど、キューがあふれるとキューに入りきらなかったログが抜けることがある、logstashなら大丈夫なので、大量の過去ログ投入するといはlogstashがおすすめ。 <a href="https://twitter.com/hashtag/jdt54?src=hash">#jdt54</a> <a href="https://twitter.com/hashtag/JavaDayTokyo?src=hash">#JavaDayTokyo</a></p>&mdash; mogami (@smogami) <a href="https://twitter.com/smogami/status/585713225800495105">April 8, 2015</a></blockquote>


<script async src="http://repeatedly.github.com//platform.twitter.com/widgets.js" charset="utf-8"></script>


<p>これらのモデルの差は</p>

<ul>
<li>Fluentdはロバストなログ転送をするために</li>
<li>Logstashはログの管理をするために(昔はそれほどES/Kibanaと密結合していなかったはず)</li>
</ul>


<p>という出生の違いによって生まれているのかなぁと思っています．</p>

<p>実のところFluentdで過去ログを転送している人はいて大きな問題にはなってないのですが，どうしてもキャパシティが足りないところに無理にやろうとすると，上記のElasticsearchのような問題が起きたりするので気をつけましょうという感じです．(一括転送専用にバッファをチューニングするのは面倒だったりしますし…)．<br />
実際1レコードずつSQL発行してinsertを行うmysqlプラグインでも，最近同じ問題が起きてました．これはバルクロード版で解決しました．</p>

<p>今だと<a href="http://www.embulk.org/docs/">Embulk</a>があるので，大量データの一括転送はそちらを使ってくださいという流れになりますが，ブロックする挙動があっても損はないとは思うので，うまくバッファのAPIが整備出来れば，back-pressureっぽい機能は入れようかとは思ったりはしてます(<a href="https://github.com/fluent/fluentd/issues/567">fluent/fluentd #569</a>)．</p>

<p>今回はFluentdとLogstashしか言及してませんが，他にもいくつかログ収集のプロダクトは存在しているので，上記のイベントのライフサイクルや，転送プロトコルでどういうセマンティクスがあるのかなどは，使う場合には一通りチェックした方が良いと思います．</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Developers.IO 2015]]></title>
    <link href="http://repeatedly.github.com/ja/2015/04/developers-io-2015/"/>
    <updated>2015-04-09T17:31:00+09:00</updated>
    <id>http://repeatedly.github.com/ja/2015/04/developers-io-2015</id>
    <content type="html"><![CDATA[<p><a href="http://devio2015.classmethod.jp/">Developers.IO 2015 | IoT, BigData, BI. in 3/27(金),29(日)</a></p>

<p>書くの遅れましたが，先月の末に行われたDevelopers.IO 2015で，登壇してました．</p>

<h2>Treasure DataのAWS活用法</h2>

<p>発表スライドは以下です．</p>

<iframe src="http://repeatedly.github.com//www.slideshare.net/slideshow/embed_code/46410399" width="425" height="355" frameborder="0" marginwidth="0" marginheight="0" scrolling="no" style="border:1px solid #CCC; border-width:1px; margin-bottom:5px; max-width: 100%;" allowfullscreen> </iframe>


<p> <div style="margin-bottom:5px"> <strong> <a href="http://repeatedly.github.com//www.slideshare.net/repeatedly/treasure-data-and-aws-developersio-2015" title="Treasure Data and AWS - Developers.io 2015" target="_blank">Treasure Data and AWS - Developers.io 2015</a> </strong> from <strong><a href="http://repeatedly.github.com//www.slideshare.net/repeatedly" target="_blank">N Masahiro</a></strong> </div></p>

<p>Developers Dayの日で「なるべくニッチな話をしてください」と言われたのと，
TD Techtalkに参加出来なかった人も見に来るというのもあったので，Treasure Dataのデータインポートとかクエリ処理周りの
内部処理的な話をしました．</p>

<p>Treasure Dataみたいなサービスを自力で作る人は少ないとは思いますが，
昨今データ解析周りの需要は増えているので，もし社内でそういう案がある人の参考にでもなればという感じです．
といっても，クラスメソッドさんのイベントでもあり，AWS要素多めの内容になっています．</p>

<p>一番最後に決まったセッションだったんですが，部屋的には埋まっていた感じなので良かったです．クラスメソッドさんのまとめやtogetterのまとめは以下にあるので，参考にしてみてください．</p>

<ul>
<li><a href="http://dev.classmethod.jp/business/bigdata/developers-io-2015-treasure-data-cmdevio2015b/">【セッションレポート】Developers.IO 2015 Treasure DataのAWS活用法 #cmdevio2015B</a></li>
<li><a href="http://togetter.com/li/794727">2015/03/29 Developers.IO 2015 Developer Day サポーター様トラックB #cmdevio2015B</a></li>
</ul>


<h2>イベントの感想</h2>

<p>SAPさんの会場で，複数のトラックで行われており，盛況でした．興味があったものの参加出来なかったセッションがいくつかあったのが心残りといえば心残り．最後の抽選では色々と欲しいものがあったものの，残念ながら手に入れることは出来ませんでした．また似たようなイベントがあったときにはリベンジしたい…</p>

<p>クラスメソッドさん勢いあるなぁと感じたイベントでした．まだまだこれからも色々とやるようなので，盛り上げるのに今後も協力出来ればという感じです．</p>

<p>皆さんお疲れ様でした！</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[第一回 Vertica勉強会]]></title>
    <link href="http://repeatedly.github.com/ja/2015/03/vertica-meetup-1/"/>
    <updated>2015-03-26T18:54:00+09:00</updated>
    <id>http://repeatedly.github.com/ja/2015/03/vertica-meetup-1</id>
    <content type="html"><![CDATA[<p><a href="https://atnd.org/events/62925">第１回 Vertica 勉強会</a></p>

<p>DeNAでVerticaの勉強会が開かれるということで行ってきた．皆さんお疲れ様 &amp; ありがとうございました．</p>

<p>VerticaはMPPデータベースと呼ばれるプロダクトの一つ．まとめみたいなのはすでに他の人が用意してくれているので，そちらを参照してください．</p>

<ul>
<li><a href="http://togetter.com/li/799648">第1回 Vertica 勉強会 - Togetterまとめ</a></li>
<li><a href="http://estrellita.hatenablog.com/entry/2015/03/25/233003">第1回Vertica勉強会に参加してきた - INPUTしたらOUTPUT!</a></li>
<li><a href="http://d.hatena.ne.jp/wyukawa/20150326/1427360270">第１回 Vertica 勉強会に行ってきた - wyukawa’s blog</a></li>
</ul>


<h2>はじめてのVertica！（はじめのて方にも、20分で分かりやすく解説）</h2>

<p>Verticaの基本的な話．<a href="http://db.lcs.mit.edu/projects/cstore/">C-Store</a>が元になっていて，
やはりC-Storeの論文に書かれている機能がベースになってた．</p>

<p>ここで出てきた</p>

<ul>
<li>列指向フォーマット

<ul>
<li>そして列毎の圧縮</li>
</ul>
</li>
<li>Shared Nothing</li>
<li>ANSI SQL準拠</li>
</ul>


<p>とかはMPPでは基本的な特徴で，それらを一通り持っている感じ．</p>

<p>少し珍しいものとしては，マルチマスタみたいにすべてのノードがクエリを受け付ける所．
複数クエリが飛んでいる時にどういう負荷分散をするか分かってないけど，クエリを投げた時にあるノードが自動でリーダーになるっぽい．<br />
Impalaも似たような仕組みだけど，Statestoreみたいな外部サービスすら存在してないようなので，
クラスタがどういう風に状態を共有しているのかが，個人的には気になっている．</p>

<p>あとで言及するけど，DB Designerというツールが一番の肝.</p>

<h2>DeNAでのverticaを活用したアナリスト業務のご紹介</h2>

<p>DeNAでどうやってVerticaを利用しているかの話．まだPrestoやImpalaが広まる前から利用しているようで，
やはりHiveやPigをAd-hocクエリの代わりに使うのはつらかったという．</p>

<p>もちろんすべてをVerticaでやっているわけではなくて，データはHadoopクラスタにも入れていて，
でかいサービスなどの場合はHadoopで中間データをつくってVerticaに入れているという，よくある構成.<br />
ストレージと密結合しているMPPデータベースはこまめなロードが大抵苦手なので，
データ量が大きいところでは皆この構成を取っている．</p>

<p><code>lead</code>とか<code>lag</code>とかのWindow関数はHiveやPrestoでも使えるんだけど，<code>timeseriese</code>というgap-fillingな関数は少し面白いなと思った．</p>

<h2>DeNAでのVertica運用について</h2>

<p>FluentdとKafkaを使ってデータを収集している話があって，ここでもFluentdが！</p>

<p>ここでHadoopを機械学習にも使っているという話をしていた．何のプロジェクトを使っているんだろうか？懇親会で聞くの忘れてた．</p>

<p>運用に関して色々とTipsを話されていて，参考になる発表だった．
データインポート時に型が一致してないレコードをデフォルトで捨てるのが，なかなか豪快だなぁという感じ．</p>

<p>あとクエリは基本Resource Poolで細かく制御するのが複数ユーザで使う時の前提．
これはどこのMPPデータベースでも同じで，何もしないと一人がでかいクエリ投げると他の処理が止まってしまう．</p>

<h2>CTC、Vertica はじめました！－テスト結果を共有！</h2>

<p>「Verticaがすごい」という話だったんだけど，テスト内容の詳細がなくて，
どういうスキーマで，どれくらいのデータがあって，どういうクエリかが分からずかなりふわっとしていた．
あとグラフに目盛りとかもなかったので，さらにすごさがよく分からなかった…</p>

<p>お客さんのテスト結果ということらしいので詳細を話せないのは分かるのだけど，
こういうオープンなイベントだと<a href="http://www.tpc.org/information/benchmarks.asp">TPC</a>とか使って分かるデータで見せないと，
ちょっと厳しいかなぁという感じ(特にパフォーマンスとかを気にするエンジニアには)．</p>

<h2>Verticaの速さの秘密、プロジェクションに関して20分で！</h2>

<p>Verticaでのテーブルは単にどういうカラムがあるかというスキーマを持っているだけで，
実際にデータを保持するのはプロジェクションという単位．誰かがtweetしていたけど，Materialized Viewみたいなもの．</p>

<p>ここでDB Desingerというのが使えて，データやクエリを登録すると，それに最適なプロジェクションを構築してくれるらしい．
プロジェクションは一つのテーブルに何個も構築出来るので，それぞれ必要なプロジェクションを作っておけば，
後でクエリエンジンが勝手に最適なプロジェクションを選んで実行してくれる．</p>

<p>Vertica，てきとうにやっても速い，みたいなの前聞いたことあったけど，実際はDB Designerにお任せという感じのようだ．
DB Designer便利だけど，当たり前だけどプロジェクション作るとそれだけ容量食うので，作りすぎに注意．</p>

<p>データロード時に集計してしまうLive Aggregate Projectionという仕組みがあるのだけど，
ロードの負荷が結構無視できないVerticaだと，大規模だと使いにくい印象を受けた．</p>

<h2>懇親会</h2>

<p>色々と生の声が聞けた．</p>

<p>懇親会でユーザに聞いた話だと，OOMみたいなので落ちることはないらしく，20-30人とかで投げてもキューに貯めて順次処理する．
ただメモリ使用量が大きすぎたり，キューが貯まりすぎると，落ちるより先にクエリがRejectされる．</p>

<p>K-safetyといういわゆるレプリケーションの仕組みがあるのだけど，DeNAさんや他のユーザも1とのこと．
2にするとデータロードの負荷が高くなり，色々と大変になるらしい．<br />
個人的には，K-safetyの数を増やせばデータの分散具合が増してクエリの処理効率がよくなると思っていたんだけど，
Verticaは基本マスターデータしか見に行かないので，増やしても意味ないらしい．</p>

<blockquote class="twitter-tweet" lang="en"><p>K-safe 2ってレプリケーションすることでデータを分散させるわけだから，その分各ノードでのデータのローカリティがあがってクエリが高速になる気もするし，安易に減らすのはアンチパターンな気もする <a href="https://twitter.com/hashtag/vertica_meetup?src=hash">#vertica_meetup</a></p>&mdash; Mr. Fiber (@repeatedly) <a href="https://twitter.com/repeatedly/status/580690665283059712">March 25, 2015</a></blockquote>


<script async src="http://repeatedly.github.com//platform.twitter.com/widgets.js" charset="utf-8"></script>


<blockquote class="twitter-tweet" data-conversation="none" lang="en"><p><a href="https://twitter.com/repeatedly">@repeatedly</a> Verticaの場合K-safe1でも2でも基本的にはマスターデータのノードにしかアクセスはいかなくて、レプリの方にはアクセスいかないです！<a href="https://twitter.com/hashtag/vertica_meetup?src=hash">#vertica_meetup</a></p>&mdash; Civitaspo (@Civitaspo) <a href="https://twitter.com/Civitaspo/status/580721464376045568">March 25, 2015</a></blockquote>


<script async src="http://repeatedly.github.com//platform.twitter.com/widgets.js" charset="utf-8"></script>


<blockquote class="twitter-tweet" data-conversation="none" lang="en"><p><a href="https://twitter.com/Civitaspo">@Civitaspo</a> <a href="https://twitter.com/repeatedly">@repeatedly</a> 　レプリカはノード障害あった際に使われます。基本的には、レプリカは同じソートパターンを採用し、クエリーの高速性には寄与しません。K-safe=1のパターンが多いです。　<a href="https://twitter.com/hashtag/vertica_meetup?src=hash">#vertica_meetup</a></p>&mdash; Projection_man (@Projection_man) <a href="https://twitter.com/Projection_man/status/580771087895527424">March 25, 2015</a></blockquote>


<script async src="http://repeatedly.github.com//platform.twitter.com/widgets.js" charset="utf-8"></script>


<p>PrestoとかのようなMPPクエリエンジンと違ってストレージと結合しているし，
この辺うまく使ってデータの読み込み効率化出来そうだなぁと思っているんだけど，ソースが見られないので何とも言えない…</p>

<p>あとクラスタの再配置やデータのリバランスは結構時間が掛かるらしく，数日かかることもあるとのこと．
パフォーマンスはそんなに落ちないらしいけど，別クラスタを立てて一気に入れ替えるのが楽なのかなぁーという．</p>

<p>まー，やはり銀の弾丸はないので，皆それぞれ苦労するポイントはあるなという感じだった．
話を聞かせてくれた人達に感謝 (-人-)</p>

<h2>まとめ</h2>

<p>第一回ということもあり，基本的な話が多かった印象でした．
ただ実際に使っている人の話とかはやはり参考になる．</p>

<p>第二回もあるかもとのことなので，またその時は参加するかもしれません．
オープンソースではないので，気になる所の実装がチェック出来ないのがやっぱりつらい所…</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[データ転送ミドルウェア勉強会]]></title>
    <link href="http://repeatedly.github.com/ja/2015/02/data-transfer-middleware-meetup/"/>
    <updated>2015-02-02T17:00:00+09:00</updated>
    <id>http://repeatedly.github.com/ja/2015/02/data-transfer-middleware-meetup</id>
    <content type="html"><![CDATA[<ul>
<li><a href="http://eventdots.jp/event/312015">データ転送ミドルウェア勉強会</a></li>
<li><a href="http://dev.classmethod.jp/tool/dtm_meetup/">「データ転送ミドルウェア勉強会」レポート #dtm_meetup</a></li>
</ul>


<p>「古橋君がアメリカに帰る前にEmbulkのリリースイベントしちゃうか〜」というノリで1日で立ち上げたイベントでしたが，めちゃくちゃ人が集まって正直驚きでした．</p>

<p>Embulk以外にも，ファイル転送のドンであるHULFTの機能や20年以上つづく開発のアレコレ，Fluentdのv1までのバージョニングと実装予定の機能の説明，そしてHTTP2対応ウェブサーバであるh2oの話，などなど結構バラエティに富んだイベントになったんじゃないかと思っています．</p>

<p>質疑応答や懇親会でEmbulkに色々とフィードバックがあったり，その後触ってもらってバグ報告などもらったりして，イベントをやった甲斐があったなと実感してます．要望の多かったresume機能などもさっそく実装が始まっているので，随時チェックしてもらえればと思います．<br />
また，FluentdとEmbulkの関係みたいなものも，別途記事にする予定です．</p>

<p>データ転送ミドルウェア勉強会みたいなイベント，結構需要があるようなので，また色々と開いて行きたいと思っています．</p>

<p>会場をかしてくれたSAP Japan，会場手配などをしてくれたdots，懇親会をスポンサーしてくれたTreasure Data，発表者の方々，また参加者の方々，皆さんお疲れ様でした！</p>

<p>スライドは上記に貼ってある&#8221;「データ転送ミドルウェア勉強会」レポート #dtm_meetup&#8221;でまとめられているので，気になる方は参照してみてください！</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Presto meetup #1]]></title>
    <link href="http://repeatedly.github.com/ja/2015/02/presto-meetup-1/"/>
    <updated>2015-02-02T02:00:00+09:00</updated>
    <id>http://repeatedly.github.com/ja/2015/02/presto-meetup-1</id>
    <content type="html"><![CDATA[<p><a href="http://eventdots.jp/event/276987">Presto meetup</a></p>

<p>1月20日に第一回をやりました！キャンセルも少なめで，イベント参加100人強，懇親会が80人くらいでした．予想の倍以上集まった感じで，Prestoも注目されてるんだなと実感したイベントでした．</p>

<p>今回は基本から始まり，それぞれ今使っている人達に，運用の話，BIツールとの連携の話，どういう組み合わせで使っているかなど発表してもらいました．「PrestoのDynamoDBコネクタを作る！」みたいな話もあったりして，リリースが待ち遠しい所です．</p>

<p>懇親会でもたくさんの人と話をしましたが，やはり安定した運用のしやすさとか，コネクタによる複数ソースへのアクセスなど，色々と使っている理由含め情報交換出来たのが良かったです．発表してくれそうな人を二人くらい見つけたので，日程は決まってませんが，また第二回でもやろうと思っています．</p>

<p>このイベントの後，発表に関しての議論が他で行われたりもして，良いイベントになったんじゃないかと思います．</p>

<p>会場をかしてくれたFreakOut，会場準備や手配などをしてくれたdots，懇親会をスポンサーしてくれたTreasure Data，発表者の方々，また参加者の方々，皆さんお疲れ様でした！
第二回でお会いしましょう :)</p>

<p>スライドは以下です．</p>

<h3>いまさら聞けないPrestoのアーキテクチャ 〜 設計の違いから知るPrestoのメリットとデメリット</h3>

<iframe src="http://repeatedly.github.com//www.slideshare.net/slideshow/embed_code/43692990" width="425" height="355" frameborder="0" marginwidth="0" marginheight="0" scrolling="no" style="border:1px solid #CCC; border-width:1px; margin-bottom:5px; max-width: 100%;" allowfullscreen> </iframe>


<p> <div style="margin-bottom:5px"> <strong> <a href="http://repeatedly.github.com//www.slideshare.net/frsyuki/understanding-presto-presto-meetup-tokyo-1" title="Understanding Presto - Presto meetup @ Tokyo #1" target="_blank">Understanding Presto - Presto meetup @ Tokyo #1</a> </strong> from <strong><a href="http://repeatedly.github.com//www.slideshare.net/frsyuki" target="_blank">Sadayuki Furuhashi</a></strong> </div></p>

<h3>Presto as a Service 〜 運用とモニタリングのコツ</h3>

<iframe src="http://repeatedly.github.com//www.slideshare.net/slideshow/embed_code/43693529" width="425" height="355" frameborder="0" marginwidth="0" marginheight="0" scrolling="no" style="border:1px solid #CCC; border-width:1px; margin-bottom:5px; max-width: 100%;" allowfullscreen> </iframe>


<p> <div style="margin-bottom:5px"> <strong> <a href="http://repeatedly.github.com//www.slideshare.net/taroleo/presto-as-a-service-at-treasure-data" title="Presto as a Service - Tips for operation and monitoring" target="_blank">Presto as a Service - Tips for operation and monitoring</a> </strong> from <strong><a href="http://repeatedly.github.com//www.slideshare.net/taroleo" target="_blank">Taro L. Saito</a></strong> </div></p>

<h3>Presto in my use case</h3>

<iframe src="http://repeatedly.github.com//www.slideshare.net/slideshow/embed_code/43701223" width="425" height="355" frameborder="0" marginwidth="0" marginheight="0" scrolling="no" style="border:1px solid #CCC; border-width:1px; margin-bottom:5px; max-width: 100%;" allowfullscreen> </iframe>


<p> <div style="margin-bottom:5px"> <strong> <a href="http://repeatedly.github.com//www.slideshare.net/wyukawa/presto-in-myusecase" title="Presto in my_use_case" target="_blank">Presto in my_use_case</a> </strong> from <strong><a href="http://repeatedly.github.com//www.slideshare.net/wyukawa" target="_blank">Wataru Yukawa</a></strong> </div></p>

<h3>シロクでの利用方法と、Sparkとの比較</h3>

<script async class="speakerdeck-embed" data-id="65ca751085cb0132de3a7a1c3ec56d64" data-ratio="1.33333333333333" src="http://repeatedly.github.com//speakerdeck.com/assets/embed.js"></script>


<h3>社内の利用例の紹介と、自社でのHIVE、TEZとの比較</h3>

<iframe src="http://repeatedly.github.com//www.slideshare.net/slideshow/embed_code/43774471" width="425" height="355" frameborder="0" marginwidth="0" marginheight="0" scrolling="no" style="border:1px solid #CCC; border-width:1px; margin-bottom:5px; max-width: 100%;" allowfullscreen> </iframe>


<p> <div style="margin-bottom:5px"> <strong> <a href="http://repeatedly.github.com//www.slideshare.net/Ogibayashi/20140120-presto-meetupen" title="20140120 presto meetup_en" target="_blank">20140120 presto meetup_en</a> </strong> from <strong><a href="http://repeatedly.github.com//www.slideshare.net/Ogibayashi" target="_blank">Ogibayashi</a></strong> </div></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Serverspec本]]></title>
    <link href="http://repeatedly.github.com/ja/2015/01/serverspec-book/"/>
    <updated>2015-01-12T20:09:00+09:00</updated>
    <id>http://repeatedly.github.com/ja/2015/01/serverspec-book</id>
    <content type="html"><![CDATA[<p>著者のmizzyさんから頂きました．ありがとうございます！</p>

<p><img src="http://repeatedly.github.com/images/serverspec_cover.jpg" title="&#34;Serverspec book cover&#34;" alt="&#34;Serverspec book cover&#34;"></p>

<p>Serverspecそのものの説明はいらないとは思いますが，公式サイトと書籍へのリンクを張っておきます．</p>

<ul>
<li><a href="http://serverspec.org/">Serverspec - Home</a></li>
<li><a href="http://www.oreilly.co.jp/books/9784873117096/">O&#8217;Reilly Japan - Serverspec</a></li>
</ul>


<h2>本の感想</h2>

<p>ソフトウェアの書籍でよくあるような「Serverspecはこう使う」といよりも「Serverspecはなぜこうなっているのか？」という所に重みを置いている書籍です．D言語のTDPLもそうですが，メイン開発者だからこそ書ける書籍になっています．
もちろん，Serverspecの説明のために使い方や機能の説明もありますが，個人的には1章と4章がこの本の肝だろうと勝手に思っています．</p>

<h3>1章</h3>

<p>Serverspecの誕生から，どういう時に使うのか，また今どういう哲学でmizzyさんがServerspecを開発しているかについて書かれています．この章は，Serverspecというよりも，ソフトウェア開発に関する考えとして読むのも面白いと思います．</p>

<h3>4章</h3>

<p>Serverspec・Specinfraの内部的な構造から設計指針まで広く深く書かれている章です．もし今後Serverspecをがっつり使いたい・またパッチを投げたい，と思っている人は読むべきでしょう．この章のいくつかは，英語でどこかで公開した方がいいんじゃないかと思うくらいです(PRのレビューの負荷が下がりそう)．</p>

<p>実装寄りの章ですが，ソースコードもふんだんに出てくるので，理解はしやすいと思います．</p>

<h2>Serverspecを使っている所</h2>

<p>個人的に，Treasure Agent(td-agent)のインストール後の状態テストにServerspecを使っています．ミドルウェアのパッケージは構成が変わると，運用している人のスクリプトが動かなくなったりするので，そこを動くコードでチェック出来るようにServerspecで書きました．</p>

<p>この時には汎用的なパッケージの構成テストにServerspecを使っている例がなかったのか，OSなどの判定をする機能がありませんでした．その影響でテスト出来ない箇所がありましたが，「ohaiみたいなのがあるとこうやってテスト書ける〜」みたいな要望を出したら，次の日にはServerspec(実際はSpecinfra)に入ってました！
この機能に関しては，3章の3.8のセクションに書かれてます．</p>

<h2>まとめ</h2>

<p>Serverspecの作者が著者ということもあり，付録含めて200ページの中に様々な情報がちりばめられています．Serverspec使ってみようかな，と思っている方は買って損はないと思いますし，各リソースタイプも付録に列挙されているので，簡単なリファレンスとしても使える感じです．</p>

<p>mizzyさん，執筆お疲れ様でした and ありがとうございました！</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[2014年振り返り]]></title>
    <link href="http://repeatedly.github.com/ja/2014/12/inventory-2014/"/>
    <updated>2014-12-31T11:59:00+09:00</updated>
    <id>http://repeatedly.github.com/ja/2014/12/inventory-2014</id>
    <content type="html"><![CDATA[<p>乗るしかない，このビッグウェーブに！</p>

<h2>イベント・勉強会</h2>

<p>覚えている限りメインで参加したのは以下．</p>

<ul>
<li><a href="http://repeatedly.github.io/ja/2014/01/cross-2014/">CROSS 2014の分散処理システムセッション</a>のモデレータ</li>
<li><a href="http://repeatedly.github.io/ja/2014/01/fluentd-v11-at-tokuben/">@特勉</a></li>
<li>筑波大学の情報システム特別講義D(<a href="https://gist.github.com/rkmathi/8700805">聴講者のgist</a>)</li>
<li><a href="http://repeatedly.github.io/ja/2014/02/developer-summit-2014/">Developer Summit 2014</a></li>
<li><a href="http://www.hicta.or.jp/index_oshirase_detail.php?id=624">北海道IT推進協会のセミナー</a></li>
<li><a href="http://repeatedly.github.io/ja/2014/03/sapporo-2014-winter/">AWS勉強会 in 北海道札幌！</a></li>
<li><a href="http://repeatedly.github.io/ja/2014/05/fluentd-v1-and-roadmap/">Fluentd Meetup 新しい応用事例とv1に関する発表</a></li>
<li><a href="http://www.microsoft.com/ja-jp/ventures/events/meetup/default.aspx">Microsoft Ventures Meetup｜マイクロソフト ベンチャーズ</a>のTuning Maniaxセッション</li>
<li><a href="http://repeatedly.github.io/ja/2014/09/serverengine-at-rubykaigi-2014/">RubyKaigi 2014</a></li>
<li><a href="http://repeatedly.github.io/ja/2014/09/hadoopcon-2014-in-taiwan/">Hadoop Conference Taiwan</a></li>
<li><a href="http://rubyconf.org/program#prop_569">RubyConf 2014</a>: セッショントーク自体はkiyotoさん</li>
</ul>


<p>30分以上のトークが増えた年でもあった．HadoopCon Taiwanでは英語のみで基調講演というかなりレアな体験をした．
Fluentdを広めるのが仕事なので，来年も色々と発表はしていきたい．<br />
LTっぽいので話したのだと，<a href="http://www.zusaar.com/event/11447004">モニカジ</a>とか<a href="http://www.slideshare.net/repeatedly/sql-for-everything-at-cwt2014">Cloudera World Tokyo</a>でも喋った．多分他にもあるけどよく覚えていない．</p>

<p>2014年はPrestoのソースコードリーディングを4回くらい開催して，そのままの流れで来年は<a href="http://eventdots.jp/event/276987">Presto Meetup</a>をやる．
ユーザが増えつつあるPrestoの日本での普及に貢献出来ればという感じで活動している．</p>

<p>D言語関係のイベントは開催出来なかったのだけど，周りから少し要望があるので，2015年はmeetupっぽいのを開きたい．</p>

<h2>OSSなアレコレ</h2>

<p><img src="http://repeatedly.github.com/images/github_2014.png" title="&#34;github contribution 2014&#34;" alt="&#34;github contribution 2014&#34;"></p>

<p>Contributionがあんまり多くない感じもするので，来年はもっと色々とやる必要がありそう．</p>

<h3>Fluentd</h3>

<p>仕事でFluentd・td-agent関係をやっているので，開発の大半はそっちにリソースを割いた．以下がFluentdの2014年のまとめ的な記事．</p>

<p><a href="http://qiita.com/repeatedly/items/e4535709fe7d803d4b59">Fluentd update 2014</a></p>

<p>Fluentdもユーザが増えてきて色々と改善すべきところが見えているので，それらを来年は解決する．
v1に向けて，とりあえず年末に<a href="http://qiita.com/repeatedly/items/78fcd7e14e31b931f7eb">v0.12を出せた</a>のは良かった．</p>

<h3>D言語</h3>

<p>本体の破壊的変更の数が激減したので，ちょいちょいとしたメンテナンスが多めだった．</p>

<p><a href="http://qiita.com/repeatedly/items/68a70bc50bbd0383c57e">D言語 Language Update 2014</a></p>

<p>俺のライブラリにもユーザがいるらしく，俺が気づくより先にパッチが届くのもあったりして嬉しい．
個人的にはvibe.dがやっぱりイベント駆動ライブラリとして使うには少し自由度がアレな感じなので，
もう少し薄いライブラリでも書こうかなぁと考え中…</p>

<h2>まとめ</h2>

<p>すきやばし次郎，超美味かった</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[HadoopCon 2014 in Taiwan]]></title>
    <link href="http://repeatedly.github.com/ja/2014/09/hadoopcon-2014-in-taiwan/"/>
    <updated>2014-09-26T01:26:00+09:00</updated>
    <id>http://repeatedly.github.com/ja/2014/09/hadoopcon-2014-in-taiwan</id>
    <content type="html"><![CDATA[<p>記事にするの遅れたけど，9月12日から9月16日まで台北に行ってきた．
目的は台北で行われた<a href="http://2014.hadoopcon.org/wp/?page_id=21">HadoopCon 2014</a>で発表すること．</p>

<p>一緒に参加することになったモリスさんの感想記事は<a href="http://d.hatena.ne.jp/tagomoris/20140916/1410857871">こちら</a>.</p>

<h2>HadoopCon 2014</h2>

<p><img src="http://repeatedly.github.com/images/hadoopcon2014_taiwan.jpg" width="600" title="&#34;HadoopCon 2014&#34;" alt="&#34;HadoopCon 2014&#34;"></p>

<p>色々と紆余曲折？があり，なぜか俺がキーノートで発表することに．
初めての英語での発表が40分のキーノートということもあって，色々と疲れた．<br /></p>

<iframe src="http://repeatedly.github.com//www.slideshare.net/slideshow/embed_code/39130038" width="425" height="355" frameborder="0" marginwidth="0" marginheight="0" scrolling="no" style="border:1px solid #CCC; border-width:1px; margin-bottom:5px; max-width: 100%;" allowfullscreen> </iframe>


<p> <div style="margin-bottom:5px"> <strong> <a href="http://repeatedly.github.com//www.slideshare.net/treasure-data/sql-on-hadoop-in-taiwan-39130038" title="SQL on Hadoop in Taiwan" target="_blank">SQL on Hadoop in Taiwan</a> </strong> from <strong><a href="http://repeatedly.github.com//www.slideshare.net/treasure-data" target="_blank">Treasure Data, Inc.</a></strong> </div></p>

<p>発表内容はHadoop上で使えるSQLプロダクトについて，基本からTreasure Dataでの経験周りを含めてあれやこれや話した．
質問もあったので，俺のアレな英語でもそれなりに伝わっていたのかなという感じ．</p>

<p>他のセッションも聞きたかったのだけど，中国語で正直何を話しているか分からなかったので，外のスペースで他の人と話していた．<br />
海外から招待された人の気持ちが分かった一瞬だったｗ</p>

<p>カンファレンス会場だった中央研究院は，台北政府直属？の研究所らしくかなり大きかった．向こうの人曰く，大抵のイベントはここでやっているらしい．
その他，大規模ではないけどHBaseを使っている所が多かったりと，色々と情報交換も出来た感じで良かった．</p>

<h2>残りは観光</h2>

<p>HadoopCon 2014で知り合った人たちが観光案内をしてくれて，HadoopConの日と次の日に色々と回れた．</p>

<p>台北101含む観光地だったり，地元の人が集まる店だったり，夜市だったり，色々と解説もしてくれてかなり楽しめた．</p>

<p><img src="http://repeatedly.github.com/images/hadoopcon2014_temple.jpg" width="500" title="&#34;HadoopCon 2014: Temple&#34;" alt="&#34;HadoopCon 2014: Temple&#34;">
<img src="http://repeatedly.github.com/images/hadoopcon2014_chiang.jpg" width="500" title="&#34;HadoopCon 2014: Chiang&#34;" alt="&#34;HadoopCon 2014: Chiang&#34;">
<img src="http://repeatedly.github.com/images/hadoopcon2014_soup_dumpling.jpg" width="500" title="&#34;HadoopCon 2014: Soup dumplin&#34;" alt="&#34;HadoopCon 2014: Soup dumplin&#34;">
<img src="http://repeatedly.github.com/images/hadoopcon2014_yoichi.jpg" width="500" title="&#34;HadoopCon 2014: Night market&#34;" alt="&#34;HadoopCon 2014: Night market&#34;">
<img src="http://repeatedly.github.com/images/hadoopcon2014_yoichi_shop.jpg" width="500" title="&#34;HadoopCon 2014: Night market shop&#34;" alt="&#34;HadoopCon 2014: Night market shop&#34;"></p>

<p>写真あげまくるのもアレなので，残りはFBのアルバムで…</p>

<h2>感想</h2>

<p>色々と調整してくれた台北の人たちには本当に感謝というか，かなり台北中は楽できたので，こういう恩はいつか返したいなと．</p>

<p>台北，ココイチとかすき家とか大戸屋とかゆで太郎とか麺屋武蔵とかあるので，日本の人がいっても多分食には困らない．
ホテルとか，探せば普通に日本語が通じる所もかなりあるので，気軽にこれる所だなぁと．<br />
交通費もかなり安いので，気軽にタクシーとか乗れる．</p>

<p>RubyConfとかOSDCとか，大きめのイベントも毎年やってるっぽいので，近いし，英語の練習がてら皆さんも参加しましょう！と参加仲間を増やす作戦．</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[ServerEngine at RubyKaigi 2014]]></title>
    <link href="http://repeatedly.github.com/ja/2014/09/serverengine-at-rubykaigi-2014/"/>
    <updated>2014-09-22T00:03:00+09:00</updated>
    <id>http://repeatedly.github.com/ja/2014/09/serverengine-at-rubykaigi-2014</id>
    <content type="html"><![CDATA[<p><a href="http://rubykaigi.org/2014">RubyKaigi 2014</a>で<a href="http://rubykaigi.org/2014/presentation/S-MasahiroNakagawa">ServerEngineについて発表</a>してきました．</p>

<p>最初は<a href="http://www.fluentd.org/">Fluentd</a>で発表しようかと思ったんですが，別の有用なプロジェクトの話もそろそろした方がいいかな，ということでServerEngineにしました． <a href="http://blog.livedoor.jp/sonots/archives/40303560.html">@sonotsさんがFluentdの発表をしてくれた</a>ので，被らなくて良かった…</p>

<p><img src="http://repeatedly.github.com/images/rubykaigi2014_serverengine_pic.jpg" width="425" title="&#34;RubyKaigi 2014: ServerEngine&#34;" alt="&#34;RubyKaigi 2014: ServerEngine&#34;">
画像は<a href="https://twitter.com/gihyoreport/status/512867195504701440/photo/1">技評さんから</a>．</p>

<p>以下がスライドです．書いてないことも発表では色々と話したので，動画もセットで見た方が良いです．</p>

<iframe src="http://repeatedly.github.com//www.slideshare.net/slideshow/embed_code/39292931" width="425" height="355" frameborder="0" marginwidth="0" marginheight="0" scrolling="no" style="border:1px solid #CCC; border-width:1px; margin-bottom:5px; max-width: 100%;" allowfullscreen> </iframe>


<p> <div style="margin-bottom:5px"> <strong> <a href="http://repeatedly.github.com//www.slideshare.net/treasure-data/rubykaigi-2014-serverengine" title="RubyKaigi 2014: ServerEngine" target="_blank">RubyKaigi 2014: ServerEngine</a> </strong> from <strong><a href="http://repeatedly.github.com//www.slideshare.net/treasure-data" target="_blank">Treasure Data, Inc.</a></strong> </div></p>

<iframe width="560" height="315" src="http://repeatedly.github.com//www.youtube.com/embed/_f7XEDvnZIU?list=UUBSg5zH-VFJ42BGQFk4VH2A" frameborder="0" allowfullscreen></iframe>


<h2>ServerEngine</h2>

<p><a href="https://github.com/fluent/serverengine">fluent/serverengine</a></p>

<p>ServerEngineはTreasure Dataで開発・運用されている分散キューや分散スケジューラ，それとFluentdなどの経験を元に，汎用的な部分を抽出してフレームワークにしたプロダクトです．発表で言及した機能の他にもBlockingFlagなどのユーティリティがあるので，Rubyでデーモンやバッチワーカーを書くときには是非試して貰えればと思います．</p>

<p>また，FluentdもいずれはServerEngineベースになる予定です．今でもServerEngineと似たような機能を俺俺で実装しているのですが，ServerEngineにすることでよりコードは簡潔に，また新しい機能も実装出来るようになります．この辺は乞うご期待という感じです．</p>

<h2>発表に関して</h2>

<p>1週間前に台北で英語でのキーノートがあり，直前まで時間が取れませんでした．台北後にひたすらスライドを作り，前日にやっと完成という，かなり際どいスケジュール．</p>

<p>本番どうかなと思ったんですが，時間進行を見ながら一部詳細を飛ばしたり，メインホールだったけどそんなに詰まることなく発表出来たんじゃないかなと思います．ここ数年は色々と大きいイベントでの発表も増え，それらの経験のおかげか，日本語であればそれなりにこなせるようになってきたかなと実感してます．</p>

<p>また，Railsとか関係のない，どちらかというと地味というか泥臭い感じの話が多めだったんですが，何人かには受けたようで，良かったです．</p>

<blockquote class="twitter-tweet" lang="en"><p><a href="https://twitter.com/repeatedly">@repeatedly</a> 今年のセッションの中でトップクラスなぐらい良いセッションでした</p>&mdash; 複数DB (@ryopeko) <a href="https://twitter.com/ryopeko/status/512867029565460480">September 19, 2014</a></blockquote>


<script async src="http://repeatedly.github.com//platform.twitter.com/widgets.js" charset="utf-8"></script>




<blockquote class="twitter-tweet" data-conversation="none" lang="en"><p><a href="https://twitter.com/repeatedly">@repeatedly</a> よかったですよ！数年前にあれば、あの時苦労しなくてもよかったのに…と思ってしまいました</p>&mdash; Toshiwo (@toshiwo) <a href="https://twitter.com/toshiwo/status/512879201326596097">September 19, 2014</a></blockquote>


<script async src="http://repeatedly.github.com//platform.twitter.com/widgets.js" charset="utf-8"></script>




<blockquote class="twitter-tweet" data-conversation="none" lang="en"><p><a href="https://twitter.com/repeatedly">@repeatedly</a> BTW, your talk was great and ServerEngine is cool. Thanks!</p>&mdash; Hiroshi Nakamura (@nahi) <a href="https://twitter.com/nahi/status/513213969855565824">September 20, 2014</a></blockquote>


<script async src="http://repeatedly.github.com//platform.twitter.com/widgets.js" charset="utf-8"></script>


<p>聞きに来てくれた皆さん，手伝ってくれたスタッフ，そして同時通訳の方々，ありがとうございました！！</p>

<p>とりあえず8月9月のイベントラッシュが終わった感じなので，少しのんびりしたい…んだけど，11月のRubyConfで<a href="http://rubyconf.org/program#prop_569">kiyoto-sanがFluentdについて発表する</a>ようなので，俺も参加しているかもしれません．</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[YAPC::Asia 2014]]></title>
    <link href="http://repeatedly.github.com/ja/2014/08/yapc-asia-2014/"/>
    <updated>2014-08-31T11:59:00+09:00</updated>
    <id>http://repeatedly.github.com/ja/2014/08/yapc-asia-2014</id>
    <content type="html"><![CDATA[<p><a href="http://yapcasia.org/2014/">YAPC::Asia 2014</a>に初めて参加した．</p>

<p>Perl使ってないし最初は行く気なかったんだけど，登録中のセッション見るとPerlじゃないの多いし，
個人スポンサーになればTシャツやパーカーも貰えると言うことで，個人スポンサーでチケット入手．</p>

<p>0日目は参加せず，1日目は朝から，2日目は昼から参加．</p>

<h2>1日目</h2>

<h3>完成されたシステムなどない。完成された人間もいない。あるのは成長し続ける未完成なシステムと、それを支える未完成な人間だけだ</h3>

<p>YAPCでのTEDを目指したという発表．大ホールの暗い雰囲気と，宇宙に覆われたスライドによって，
宗教的な感じがしたプレゼン．</p>

<p>発表時間の半分で発表そのものは終わったのだけど，質疑応答をもっと盛り上げれば，完成度は上がったんじゃ無いかと思う．</p>

<h3>お待たせしました。Perl で BDD を簡単に実践する最高にクールなフレームワークができました</h3>

<p>一番Perlっぽい話かな，と思って参加．Perlのテストにおける歴史みたいなのとか，
エコシステムの話みたいなのが聞けたのは面白かった．</p>

<p>「Perl 6と同じくらい夢が詰まっている」という言葉，つらい．</p>

<h3>作られては消えていく、泡のように儚いクラスタの運用話</h3>

<p>TV番組用システムの裏側の話．あるある系もあったり，便利そうなコマンド作ってたり，
なかなかみんな苦労しているな，と．最近TV系の運用話はちょくちょく聞くので，どこも似ている感じ．</p>

<h3>ライブコーディング</h3>

<p>songmuさんともずにおんのコンビ漫才を休憩がてら見ていた．やっぱ本番では色々とミスが起きるｗ</p>

<p>ここで食べたDMMかき氷，普通に美味しかった</p>

<h3>O2O/IoT/Wearable時代におけるWeb以外のネットワーク技術入門</h3>

<p>IoT周辺の技術の用語とか仕組みの説明．いやー，しかしこの辺りは略語が多くてすぐ覚えるのがつらい．</p>

<p>その後はセッションには参加せず，休憩スペースで何人かでISUCONとかPHPとか色々とだべっていた．
MQTT Meetupに参加する予定があったので，懇親会には参加せず会場を去った．</p>

<h2>2日目</h2>

<p>naoyaさんの発表をにやにやしながら見ようかと思っていたのだけど，起きたらもう終わっていたのが心残り．</p>

<p>ついた時間も中途半端だったので，naoyaさんとHUBに行き，そこでmiyagawaさんとかけんじおじさん，shiba_yuさんとかとしゃべっていた．
時間が経つと色々と人が集まってきたのだけど，大ホールの席を取るため移動．</p>

<h3>そんなにビッグでもないデータ処理手法の話</h3>

<p>言うことはないというか，全部知っている話だったので内職をしていた．が，ベストトークで2位だったので，
やっぱ分野が違うと受けるトークも変わるんだなぁという．</p>

<p>ただ，最初にモリスさんがFluentdのユーザを聞いてくれたら半分くらい？は手をあげていたので，
ちゃんと浸透してるんだなと嬉しく思う反面，あと半数にどうやってリーチすべきかというのも考えないと行けない．</p>

<p>モリストリーム…じゃなくてNorikraの宣伝が少なかったな，という印象．</p>

<h3>Lightning Talks Day 2</h3>

<p>席を取っていて良かった，というくらい人がわらわらと集まってきていた．</p>

<p>FluentdがTwitterで非常にアクティブに議論・サポートされている話とか出てきて，Twiterの監視社会怖い!<br />
やっぱLTは短い中にネタを押し込んでくる人が多いので，それ故に面白いのだけど，すぐ終わるのがちょっと悲しい．</p>

<h3>キーノート</h3>

<p>typesterさんのエモい話．typesterさんのキャリアって他の人が真似するのはかなり難しいのだけど，
話の中でも出ていた「複数の人のロールモデルを参考にする」というのに結局落ち着く．</p>

<p>お子さんも一緒に来ていて，ほっこりする感じの発表だった．</p>

<p>あと，typesterさんはIngressは緑のLv8だったので，青のLv8の俺とどこかでやりあってたかも，
と思ったけど鎌倉だし全然関係なかった．</p>

<h3>HUB</h3>

<p>そうそうに一つのビールが無くなっていたけど，ジンジャーエール派の俺には関係なかった．
土曜日は夜に外せない用事があるので，色々な人に絡んでから，早めに帰った．</p>

<h2>改善点</h2>

<p>他の人も書いてると思うけど，意見が多いとそれだけ反映されるだろうということで書いておく．</p>

<h3>キャパシティプランニング</h3>

<p>今年の参加者は約1300人で，それに対して会場のキャパシティは約500人らしく，非常に狭かった．
特に多目的教室は毎度部屋から出るくらいまで立ち見とか出ていたので，ちゃんと聞けない人も多かったのではないかなと．</p>

<p>去年も同じ場所で約1100人だったらしいけど，去年は大丈夫だったのかな？参加してないのでよく分からない．
この辺のマネージは本当に難しいので，一発で解決のアイディアは提示できないのだけども…</p>

<h3>トーク間の移動時間</h3>

<p>2つのトークが続いて休憩がないのがいくつかあって，これは質疑応答と移動時間がかぶってしまうので勿体ないなと．</p>

<h2>まとめ</h2>

<p>トークの種類がPerlに限らず色々とあり，それに伴って参加者も結構多様な感じがしていて楽しかった．
ベストトーク賞のベスト3がどれもPerl関係ないのが，それを物語っていると思う．</p>

<p>ネットワークも快適だったし，休憩スペースも飲み物とかあって，セッション以外でぶらぶらするのも困らなかった．</p>

<p>1000人規模の運営超大変だし，運営チームの方達は本当にお疲れ様でした！来年も楽しみにしてます :)</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Fluentd v0.12でのFilterとLabel]]></title>
    <link href="http://repeatedly.github.com/ja/2014/08/fluentd-filter-and-label/"/>
    <updated>2014-08-25T17:30:00+09:00</updated>
    <id>http://repeatedly.github.com/ja/2014/08/fluentd-filter-and-label</id>
    <content type="html"><![CDATA[<p>Fluentd，最近だと海外でも露出が増えてきていて，軽量・柔軟・ロバストという所で，
新規の他，既存のログコレクタのリプレース含め，採用する所が増えてたりします．</p>

<p>より改善するため色々とユーザにヒアリングした結果，「フィルタ機能が欲しい」というのが一番多い意見でした．
Fluentdは元々Treasure Dataへロバストにデータを転送するためのミドルウェアで，「ETLとかはTreasure Dataで」
というのもあり，組み込みでフィルタ機能はありませんでした．</p>

<p>今現在のOutputプラグインによるフィルタ実装は，タグの書き換えが必要だったりして少し慣れが必要で，初心者にはちと難しい．
ということで，より簡単に効率よくデータストリームを扱えるフィルタ機能を入れることにしました！</p>

<p>前置きが長くなりましたが，次のバージョンであるv0.12ではFilterとLabelの導入が目玉機能になります．
これらは二つともデータストリームの処理をより楽にするための機能です．</p>

<p>後，<a href="http://www.fluentd.org/blog/fluentd-v0.10.53-is-released">Fluentd v0.10.53のリリースアナウンス</a>でも書きましたが，
今現在のmasterブランチはすでにv0.12用になっています．また，以下の機能はまだmasterにはマージされていません．今週中にはマージ予定ですが，
試して見たい方は，<a href="https://github.com/fluent/fluentd/pull/416">PR #416</a>をチェックしてください．</p>

<h2>Filter</h2>

<p>Outputプラグインで出力する前に，イベント群に処理を適用するための仕組みです．
<code>grep</code>や<code>record_refomer</code>や<code>geoip</code>プラグインなどは，Filterとして実装することでより効率良く処理出来るようになります．</p>

<p>最初に実装，その後に設定の例を見せます．</p>

<h3>実装</h3>

<p>FilterのAPIは以下のようになっています．</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
</pre></td><td class='code'><pre><code class='rb'><span class='line'><span class="k">module</span> <span class="nn">Fluent</span>
</span><span class='line'>  <span class="k">class</span> <span class="nc">SomeFilter</span> <span class="o">&lt;</span> <span class="no">Filter</span>
</span><span class='line'>    <span class="no">Plugin</span><span class="o">.</span><span class="n">register_filter</span><span class="p">(</span><span class="s1">&#39;some_filter&#39;</span><span class="p">,</span> <span class="nb">self</span><span class="p">)</span>
</span><span class='line'>
</span><span class='line'>    <span class="k">def</span> <span class="nf">filter</span><span class="p">(</span><span class="n">tag</span><span class="p">,</span> <span class="n">time</span><span class="p">,</span> <span class="n">record</span><span class="p">)</span>
</span><span class='line'>      <span class="c1"># レコードを弄るプラグインは，ここを実装すればOK</span>
</span><span class='line'>      <span class="c1"># レコードを返す必要がある</span>
</span><span class='line'>      <span class="n">modified_record</span>
</span><span class='line'>    <span class="k">end</span>
</span><span class='line'>
</span><span class='line'>    <span class="k">def</span> <span class="nf">filter_stream</span><span class="p">(</span><span class="n">tag</span><span class="p">,</span> <span class="n">es</span><span class="p">)</span>
</span><span class='line'>      <span class="c1"># 以下はFilterのデフォルト実装．grepなどはこちらを置き換えればOK</span>
</span><span class='line'>      <span class="n">new_es</span> <span class="o">=</span> <span class="no">MultiEventStream</span><span class="o">.</span><span class="n">new</span>
</span><span class='line'>      <span class="n">es</span><span class="o">.</span><span class="n">each</span> <span class="p">{</span> <span class="o">|</span><span class="n">time</span><span class="p">,</span> <span class="n">record</span><span class="o">|</span>
</span><span class='line'>        <span class="n">new_es</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">time</span><span class="p">,</span> <span class="n">filter</span><span class="p">(</span><span class="n">tag</span><span class="p">,</span> <span class="n">time</span><span class="p">,</span> <span class="n">record</span><span class="p">))</span>
</span><span class='line'>      <span class="p">}</span>
</span><span class='line'>      <span class="n">new_es</span>
</span><span class='line'>    <span class="k">end</span>
</span><span class='line'>  <span class="k">end</span> <span class="k">if</span> <span class="n">defined?</span><span class="p">(</span><span class="no">Filter</span><span class="p">)</span> <span class="c1"># v0.10とかでエラーにならないための回避策</span>
</span><span class='line'><span class="k">end</span>
</span></code></pre></td></tr></table></div></figure>


<h4>filter(tag, time, record)</h4>

<p><code>SetXXXMixin</code>を置き換える<a href="https://gist.github.com/repeatedly/cb16d5667350c8a0e2c9#file-filter_add_metadata-rb">add_metadata</a>フィルタを見て貰えればわかりやすいと思いますが，
引数で渡ってくるレコードを弄って，それを返り値にするだけです<br />
<code>filter</code>とは違い<code>filter_stream</code>は上記のデフォルト実装があるので，変更する必要はありません．</p>

<p>大抵のプラグインはこのAPIをオーバーライドして処理を実装すれば，その結果が次のフィルタに渡されるようになります．</p>

<h4>filter_stream(tag, es)</h4>

<p>EventStreamを直接処理するFilterを書くためのAPIです．例えば<code>grep</code>はレコードを弄らず，EventStream全体に対して処理を行うプラグインなので，
このAPIをオーバーライドします．<code>filter_stream</code>を変更する場合，<code>filter</code>を変更する必要はありません．<br />
<code>filter</code>とは違い，返り値としてEventStreamを返す必要があります．Fluentdは，この<code>filter_stream</code>の返り値を次のFilterに渡し，最終結果をOutputプラグインに渡します．</p>

<p>また，<code>record_reformer</code>の<code>renew_record</code>のように，新しくレコードを生成する系のプラグインもこちら側で処理を実装することになります．
<code>grep</code>と<code>record_reformer</code>のFilter例は以下にあります．</p>

<ul>
<li><a href="https://gist.github.com/repeatedly/0ed3e2b4016b4045640a#file-filter_grep-rb">filter_grep</a></li>
<li><a href="https://gist.github.com/repeatedly/5c9f89e14aace5cda195#file-filter_record_reformer-rb">filter_record_reformer</a></li>
</ul>


<h3>設定</h3>

<p><code>&lt;filter&gt;</code>セクションが追加されています．たとえば，<code>add_metadata</code>と<code>grep</code>を使う場合には以下のようになります．</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
</pre></td><td class='code'><pre><code class='aconf'><span class='line'><span class="nt">&lt;source&gt;</span>
</span><span class='line'>  <span class="nb">type</span> forward
</span><span class='line'><span class="nt">&lt;/source&gt;</span>
</span><span class='line'>
</span><span class='line'><span class="nt">&lt;filter&gt;</span> <span class="c"># &lt;filter&gt;と&lt;filter **&gt;は同じ</span>
</span><span class='line'>  <span class="nb">type</span> grep
</span><span class='line'>  <span class="err">input_</span><span class="nb">key</span> message
</span><span class='line'>  <span class="nb">regexp</span> <span class="k">WARN</span>
</span><span class='line'><span class="nt">&lt;/filter&gt;</span>
</span><span class='line'><span class="nt">&lt;filter&gt;</span>
</span><span class='line'>  <span class="nb">type</span> add_metadata
</span><span class='line'>  <span class="err">include_tag_</span><span class="nb">key</span>
</span><span class='line'>&lt;/filter&gt;
</span><span class='line'>
</span><span class='line'><span class="nt">&lt;match</span> <span class="s">**</span><span class="nt">&gt;</span>
</span><span class='line'>  <span class="nb">type</span> stdout
</span><span class='line'><span class="nt">&lt;/match&gt;</span>
</span></code></pre></td></tr></table></div></figure>


<p>Fluentdの設定ファイルの流儀にしたがって，上から順番に<code>match</code>にマッチしたところまでのFilterが適用されます．
この例では，まず<code>grep</code>が適用され，その次に<code>add_metadata</code>，そしてこれらの結果のEventStreamが<code>stdout</code>に渡されます．<br />
例えば以下のデータが入ってきたとして:</p>

<pre><code>{"message":"INFO"}
{"message":"WARN"}
</code></pre>

<p><code>stdout</code>には，<code>grep</code>で最初のレコードがフィルタリングされ，<code>add_metadata</code>でタグが追加された以下のデータが渡されます:</p>

<pre><code>{"message":"WARN", "tag":"filter.test"}
</code></pre>

<p>タグを書き換えて<code>match</code>の条件を調整して〜という煩わしさから解放されるようになります．</p>

<p>注意点としては，マッチした<code>match</code>の下にある<code>filter</code>は，たとえtagがマッチしようが適用されない所です．</p>

<h3>パフォーマンス</h3>

<p>タグの書き換えや再emitが発生しないため，速度やメモリ効率は多少よくなるはずです．</p>

<p>手元で約450MBのファイルを<code>in_tail</code>で読み込み，<code>record_reformer</code>でホスト名などを付加して転送する，
というのをv0.10とv0.12で測ってみた所，v0.10は181秒，v0.12は149秒で，約30秒短縮されました．</p>

<p>ユーザによってはもっとFilterがチェーンしている所もあるはずなので，そういう場合には恩恵が大きいと思います．</p>

<h2>Label</h2>

<p>これはFilterやOutputをまとめるための機能になります．制限として，InputはLabelの中に含めることは出来ません．
こちらは先に設定から見てみます．</p>

<h3>設定</h3>

<p>以下が簡単な例になります．</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
</pre></td><td class='code'><pre><code class='aconf'><span class='line'><span class="nt">&lt;source&gt;</span>
</span><span class='line'>  <span class="nb">type</span> forward
</span><span class='line'>  <span class="err">@</span><span class="nb">label</span> @forward
</span><span class='line'><span class="nt">&lt;/source&gt;</span>
</span><span class='line'>
</span><span class='line'><span class="nt">&lt;source&gt;</span>
</span><span class='line'>  <span class="nb">type</span> tail
</span><span class='line'>  <span class="nb">path</span> <span class="sx">/path/to/file</span>
</span><span class='line'>  <span class="nb">tag</span> tail
</span><span class='line'><span class="nt">&lt;/source&gt;</span>
</span><span class='line'>
</span><span class='line'><span class="nt">&lt;filter</span> <span class="s">**</span><span class="nt">&gt;</span>
</span><span class='line'>  <span class="nb">type</span> grep
</span><span class='line'>  <span class="c"># ...</span>
</span><span class='line'><span class="nt">&lt;/filter&gt;</span>
</span><span class='line'>
</span><span class='line'><span class="nt">&lt;match</span> <span class="s">**</span><span class="nt">&gt;</span>
</span><span class='line'>  <span class="nb">type</span> mongo
</span><span class='line'>  <span class="c"># ...</span>
</span><span class='line'><span class="nt">&lt;/match&gt;</span>
</span><span class='line'>
</span><span class='line'><span class="nt">&lt;label</span> <span class="s">@forward</span><span class="nt">&gt;</span>
</span><span class='line'>  <span class="nt">&lt;filter</span> <span class="s">**</span><span class="nt">&gt;</span>
</span><span class='line'>    <span class="nb">type</span> add_metadata
</span><span class='line'>    <span class="err">include_tag_</span><span class="nb">key</span>
</span><span class='line'>  &lt;/filter&gt;
</span><span class='line'>  <span class="nt">&lt;match</span> <span class="s">**</span><span class="nt">&gt;</span>
</span><span class='line'>    <span class="nb">type</span> file
</span><span class='line'>  <span class="nt">&lt;/match&gt;</span>
</span><span class='line'><span class="nt">&lt;/label&gt;</span>
</span></code></pre></td></tr></table></div></figure>


<p><code>forward</code>の中に<code>@label @forward</code>というパラメータがあります．これがLabelの指定になっていて，
<code>@label</code>があるとその指定されたLabelにイベント群が流れて行きます．なので，この例では<code>forward</code>で
受け付けたイベント群は，<code>add_metadata</code>フィルタを通り，その下の<code>file</code>に到達します．<br />
一方，<code>@label</code>のないInputは今までと同じ挙動となり，トップにイベント群を流します．
この例では，<code>grep</code>フィルタを通り，その下の<code>mongo</code>に到達します．</p>

<p>Labelの機能によって，各プラグイン間の関係がわかりやすくなり，またルーティングのためにタグを調整する必要もなくなります．
<code>out_relabel</code>プラグインを使えばデータを別のLabelに飛ばせるので，入力によって違うフィルタを適用したいが，書き込み先は一緒にしたい，
みたいな処理も簡単にできるようになります．</p>

<h3>実装</h3>

<p>v0.12から，<code>router</code>というのがInput/Outputに増えてます．今まで<code>Engine.emit</code>と書いていた所を，<code>router.emit</code>に書き換えるだけで，
Labelの機能が使えるようになります．<br />
言い換えれば，この書き換えをしていないInput/Outputプラグインは，<code>@label</code>が使えないということになります．</p>

<h2>まとめ</h2>

<p>v0.12の主要機能であるFilterとLabelについて簡単に説明しました．まだ実装としていくつか細かな改善はあるのですが，
基本機能は上記のままで行くと思います．<br />
何かフィードバックがあれば<code>@repeatedly</code>にmentionをするか，上記の該当PRにコメントをして貰えればと思います．</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Fluentd UI]]></title>
    <link href="http://repeatedly.github.com/ja/2014/08/fluentd-ui/"/>
    <updated>2014-08-04T04:10:00+09:00</updated>
    <id>http://repeatedly.github.com/ja/2014/08/fluentd-ui</id>
    <content type="html"><![CDATA[<p><a href="https://github.com/fluent/fluentd-ui">fluent/fluentd-ui</a></p>

<p><img src="http://repeatedly.github.com/images/fluentd_ui_ss.png" title="&#34;Fluentd UI image&#34;" alt="&#34;Fluentd UI image&#34;"></p>

<p>Fluentdのエコシステムの一つとして，Fluentd UIをリリースしました．
すでに試してくれたユーザもいるようなので，現在の使用感などは下記の記事を参考にしてください．</p>

<ul>
<li><a href="http://suzuken.hatenablog.jp/entry/2014/08/01/202334">Fluentd UIが出たので触ってみた</a></li>
<li><a href="http://qiita.com/inokappa/items/0a4a2db7abad22458bea">Touch the fluentd-ui(1)</a></li>
</ul>


<p>この記事ではFluentd UIそのものについてつらつらと書きたいと思います．英語でのアナウンスもいずれ公式ブログに載るはず．</p>

<h2>Fluentd UIの生い立ち</h2>

<p>Fluentd UIの背景として，Fluentdも最近は国を問わず色々な所でユーザが増えてきており，
「CLIとか楽勝！」以外のユーザの割合も増えつつあります．</p>

<p>ログコレクタでリッチな管理UIを持っているプロダクトってほとんどないと思うのですが，
新しく使い始めるユーザの嵌まり所とか見ていると，
GUIの方が始めるための敷居が下がりそうなポイントがいくつかありました．</p>

<p>なので，Fluentdを使いたい人がなるべく嵌まらずに始められるようにと，
万葉の方と開発したのがFluentd UIです．</p>

<h2>Fluentd UIのコンセプト</h2>

<p>生い立ちの所で書いた通り，Fluentdの敷居を下げるのが第一の目的なので，
すでにFluentdをバリバリ使っている人はユーザの対象ではありません．</p>

<p>バージョン0.1.0の段階で，以下の機能があります:</p>

<ul>
<li>Fluentdのプロセスの管理 (start/stop/restart)</li>
<li>Fluentdの設定ファイルの管理と編集</li>
<li>Fluentdのプラグインの管理 (install/uninstall/update)</li>
<li>ログやシステム情報のビューワー，などなど</li>
</ul>


<p>最初に色々機能を洗い出したのですが，全部入れるとリリースが遅れるし，
複雑なのを入れるとユーザが混乱するかもということで，ベーシックな機能セットに絞りました．<br />
それでも，プラグイン入れての挙動チェックなど，全部Webから出来るようになっています．また，
ユーザがテストしにくかったin_tailは，<a href="http://fluentular.herokuapp.com/">Fluentular</a>を参考にかなり使いやすいUIになったと思います．</p>

<p>実装的にもかなり依存を減らしていて，例えば，最初はSQLiteベースだったのですが，
「SQLiteだとFluentd UIそのもののセットアップに嵌まる人が出る可能性がある」とファイルベースに変更したりしました．</p>

<h2>Fluentd UIの今後の展望</h2>

<h3>機能追加</h3>

<p>バージョン0.1.0ということから分かる通り，まだまだ始まったばかりのプロダクトで，
今回は開発者側が「こういう機能があったら始めやすいだろう」というものを中心に入れました．<br />
今後はユーザからのフィードバックも受けつつ，更に使いやすさを改善して行けたらなと．</p>

<p>現状各プラグインの設定を削除する時は，自分でフリーフォームから消す必要があるので，
この辺もボタンで消せるようにとか，出来たらいいかなぁと考えてます．<br />
あと，今設定が組み込みで実装してあるので(インストールした3rd partyプラグイン用の設定ページがない)，
各プラグインから自動で設定ページが生成できるような仕組みも必要かなと，色々と模索中です．</p>

<h3>td-agent 2への同梱</h3>

<p>td-agentには同梱予定はないんですが，td-agent 2にはtd-agent-uiみたいな感じで同梱する予定です．すでに起動した人は知っていると思いますが，td-agentをセットアップする用のボタンがあります :)</p>

<h3>他の環境との連携</h3>

<p>Fluentd UIは，UI上で色々と試行錯誤しその結果出来た設定ファイルをChefとかで配布，
みたいなのを想定しているのですが，毎回コピペとか面倒ですし，
最近だと<a href="https://github.com/sonots/fluentd-server">fluentd-server</a>とかもあるので，この辺なんか上手くやりたいな，と．</p>

<h2>まとめ</h2>

<p>Fluentd UIについて背景含めつらつらと書きました．是非試して頂いて，問題があったら<a href="https://github.com/fluent/fluentd-ui/issues">issue</a>投げるなり<a href="https://github.com/fluent/fluentd-ui/pulls">PR</a>なりしてもらえると助かります！</p>

<p>あ，ちなみに最初のリリースは俺がやりましたが，開発はコミットを見れば分かる通り<a href="https://github.com/uu59">uu59</a>さんでちゃんとしたRailsコードになっているので，ご心配なく！</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Fluentdとログ収集のパターン]]></title>
    <link href="http://repeatedly.github.com/ja/2014/07/fluentd-and-log-forwarding-patterns/"/>
    <updated>2014-07-31T18:35:00+09:00</updated>
    <id>http://repeatedly.github.com/ja/2014/07/fluentd-and-log-forwarding-patterns</id>
    <content type="html"><![CDATA[<p>「ログを集めて保存する」と言うのは簡単だけど，ログ収集の構成にはいくつか方法があり，勉強会などでちょくちょく聞かれるので，いくつかのパターンについて書く．<br />
「俺はもうバリバリログ収集やってるぜ！」という人は多分すでに知っていることが書かれているので，タブを閉じて良い．</p>

<p>ここではログコレクタにFluentdを想定しているが，他のログ収集プロダクトにも適用出来るはず．
ただ，Fluentdはタグベースのルーティングを持ち，単体でもキューのように動作させることが可能で，既存のものより複雑な問題を解決しようとしているので，少し工夫が必要かもしれない．<br />
Fluentdそのものについては<a href="http://docs.fluentd.org/articles/quickstart">公式ドキュメント</a>や，<a href="http://tagomoris.hatenablog.com/entry/2013/12/03/150656">Fluentdとはどのようなソフトウェアなのか</a>を参考に．</p>

<h2>クライアントから直接保存する</h2>

<p><img src="http://repeatedly.github.com/images/fluentd_only_client_pattern.png" title="&#34;Only client pattern&#34;" alt="&#34;Only client pattern&#34;"></p>

<p>いきなりFluentdを使わないパターン．JavaScript SDKを提供している解析サービスやモバイル端末などでよく使われている．ログがユーザサイドで発生する場合にはログコレクタを仕込むことは出来ないので，基本このアプローチになる．<br />
これらはクライアントの出来によって精度が左右されるが，モバイルであれば繋がらなかったら一定量バッファリングをし，ネットワークが繋がった段階で非同期に転送などがよくある実装．</p>

<p>ログコレクタを用意出来るサーバサイドでこのアプローチを取っているシステムは最近だとあまり聞かない．もしやるならエラーハンドリングとして</p>

<ul>
<li>バッファリング</li>
<li>リトライ</li>
<li>ロードバランシング</li>
</ul>


<p>などの問題を解決する必要がある．Fluentdであればこれらの機能が最初からついているので，今から構築するシステムでやる必要はほとんど無いと思われる．</p>

<h2>末端ノードのログコレクタから直接保存する</h2>

<p><img src="http://repeatedly.github.com/images/fluentd_only_leaf_node_pattern.png" title="&#34;Only leaf node pattern&#34;" alt="&#34;Only leaf node pattern&#34;"></p>

<p>アプリケーションやノードからログを集め，ログコレクタから直接保存する．「クライアントから直接保存する」の例で，ローカルにログコレクタを置き，そこ経由でデータを投げつけるモデル．<br />
ネットワーク周りのややこしい問題をログコレクタに任せられ，Fluentdであればプラグインで容易にストリームを操作できるのがメリット．また，ApacheやNginxから直接外部にデータを投げるのは難しいので，Fluentdでファイルにはき出されたログを収集するときにはこの構成となる．</p>

<p>この構成だと，収集対象のサーバが多くなるだけアクセスが増えて保存先への負荷があがるので</p>

<ul>
<li>データのストリームがそれほど大きくない</li>
<li>保存先が書き込みに対して耐性がある (クラウドサービスなど)</li>
</ul>


<p>などの場合に有効になる．次で書く集約ノードが必要ないので，その分管理は楽になる．<br />
Fluentdは転送役と集約役に違いはないので，この段階でフィルター系プラグインを使って，データを加工することもある．</p>

<p><a href="http://www.treasuredata.com/">Treasure Data</a>の場合には，<a href="https://metrics.librato.com/">Librato Metrics</a>に投げる所などは集約ノードを経由せず，各Fluentd(Treasure Agent)から直接投げている．この場合は各ノードのメトリックスが取りたいので，集約ノードでデータストリームをまとめる必要もない．</p>

<p>これとは違いMongoDBの場合だと，細かいのをちまちま送るより大きめのバッチでガンと書き込んだ方が効率が良いので，このモデルよりも集約ノードを置いた方が良い．</p>

<h2>集約ノードのログコレクタを経由して保存する</h2>

<p><img src="http://repeatedly.github.com/images/fluentd_aggregation_node_pattern.png" title="&#34;Using aggregation node pattern&#34;" alt="&#34;Using aggregation node pattern&#34;"></p>

<p>ログコレクタでの多段構成モデル．集約ノードを置く利点は，データストリームをまとめてデータに対する処理をしやすくする点が大きい．また，各ノードから集めることでストリームが太くなり，マイクロバッチの効率も良くなる．</p>

<p>Fluentdでもアグリゲーションをしたり，<a href="http://norikra.github.io/">Norikra</a>と連携するプラグインがあったりするので，その手の処理はこの集約ノードでやるのがベター．</p>

<p>大抵のログコレクタと同じく，Fluentdのデフォルトの転送プロトコルはPush型になっていて，多段構成時には流れるように保存先にデータが集まるようになっている．<br />
多段構成時の注意点は，ある場所のノードが落ちた時にストリームが途切れてしまう所．Fluentdの場合は障害に対応するために，転送先を複数指定可能で，その中で負荷分散とノードが落ちた時の処理を指定出来るようになっていて，よほど一気にノードが落ちない限りストリームが途切れることはない．もし落ちてもバッファリングが行われるので，ノードを再度立ち上げればデータはまた流れ出す．</p>

<h3>PaaS上でのアプリケーション</h3>

<p>アプリケーションをホストするような環境だとローカルにFluentdを置けなかったりするので(HerokuだとFluentdは起動できるが，ファイルバッファが使えなかったりする．ユースケース次第)，その場合はいきなり集約ノードやキューにデータを投げることになる．</p>

<h2>キューを置く</h2>

<p><img src="http://repeatedly.github.com/images/fluentd_queue_pattern.png" title="&#34;Using queue pattern&#34;" alt="&#34;Using queue pattern&#34;"></p>

<p>データストリームの中でキューを間に挟むことの主な理由は，ログのreliabilityの向上と，処理の間にワンクッション置くこと．</p>

<p>そもそもキューはPush型ではなくPull型であり，Producer・Queue・Consumerと登場人物も増えるので，キューを置くことでログ収集そのものが効率化されることはあまりない．異なる粒度のシステム間で連携をする時に，間にキューを置くことが多い．</p>

<p>実際Fluentdとキューを連携させている例はいくつかあり，たとえば複雑なシステムを構築している<a href="http://engineering.viki.com/blog/2014/data-warehouse-and-analytics-infrastructure-at-viki/">Vikiの例</a>ではKestrelでFluentdからのデータストリームを分岐させているし，AWSは本家が<a href="https://github.com/awslabs/aws-fluent-plugin-kinesis">fluent-plugin-kinesis</a>を書いているので，いずれこの事例も増えるはず.</p>

<p>KafkaやKinesisなど信頼性のあるキューを間に置けば，ログをそれなりの期間保持しつつ，Consumerを複数用意することでストリームを分岐できる．<br />
Push型での分岐とは違い，キューからログを取る側の都合でデータを処理出来るので，各データストリームで処理粒度が違う時に有効．
ただ，キューそのものに信頼性があってもProducer/Consumerが駄目だと効率が良くならずログが欠損/重複するので，自分たちのシステム要件に合わせてちゃんと構築する必要がある．</p>

<h3>Pull型のログ収集</h3>

<p>キューを置かずにPull型でログを転送する方法もある．Kafkaほどの信頼性を期待するのは難しいが，Pull型の利点を享受できる．まだ完成していないが，Fluentdだとモリス=タゴという人が，<a href="https://github.com/tagomoris/fluent-plugin-pullforward">pullforward</a>というのを開発中らしい．</p>

<h2>Fluentdを使わない方が良いパターン</h2>

<p>プロダクションで使われているパターンをいくつか書いた．大抵のシステムは上のどれかの構成に当てはまる．FluentdはWebや広告のみならずIoTやPOS含め色々なところで使われていて，データのアーカイブ，簡単なストリーム処理，ノードやアプリケーションのモニタリング，などなど様々なユースケースの基盤になれる柔軟性がある．</p>

<p>また，LINE社で2年間問題なく動いているし，最近勉強会とかで話を聞くと「安定していて自分の仕事がない」と言われる位，よほど変なことしない限り安定性もある．ある会社で100億events/dayをFluentdクラスタで転送した実績もあるので，パフォーマンスもそれなりにある(フィルタ的な処理を重ねまくると，もちろん遅くなる)．</p>

<p>が，Fluentdを使わない方が良いケースもある．以下主に二つ．</p>

<h3>Exactly Onceが必要なケース</h3>

<p>一切ログの欠損も重複も許せない，しかも確実に書き込む必要がある，というケース．<br />
ストリーム処理でExactly Onceを保証するのはかなり難しく，俺が知っている限りOSSでは存在していない．商用でもほとんど知らない．</p>

<p>Exactly Onceを実現しようとすると，ログ発生時点から書き込むまでを完全に同期的にやるか，様々な箇所でトランザクションが必要になり，スケールアウトが難しくコストもものすごく掛かる．そして保存先にもそれなりの機能が求められる．</p>

<p>かつてOSSでマスターノードを使い到達保証を目指したプロダクトがあったが，結局パフォーマンスがボトルネックになり，そこまでしてもログの欠損が防げなかったため，新しいバージョンでは諦めることになった．</p>

<h4>Fluentdのモデル</h4>

<p>FluentdはデフォルトAt Most Onceであり，<a href="http://docs.fluentd.org/articles/high-availability">ドキュメントにもモデルの説明と対策が書いてある</a>，<br />
これはログが欠損/重複しまくるということではなく，At Most OnceもAt Least Onceも通常は問題は起きない．トポロジーに問題がある場合に，システム的に欠損/重複が起きうるという話．そして大抵のユーザはExactly Onceでなくても上手く行く．</p>

<p>Fluentdでも欠損/重複を防ぐための対策はいくつかあり</p>

<ul>
<li>ログにユニークIDを足して，HadoopなどのETLで重複を削除する</li>
<li>直近の生ログは保持しておき，保存先とのレコード数を比較する．おかしい所は再送</li>
<li>データストリームを複数作って冗長性を持たせる</li>
</ul>


<p>などなど．システム的にExactly Onceではなくても，それに低コストで近づけることは可能．</p>

<h5>追記(2014/11/14)</h5>

<p>v0.12からはAt Least Onceもサポートする．現在リリースされているv0.12.pre2から使えるが，v0.12の正式リリース後，ドキュメントにもちゃんと書く．</p>

<h3>データストリームが一本で密結合したサービスがある</h3>

<p>たとえばAWSのCloudWatch Logsがそう．Agentのセットアップが必要だったりして楽かと言われるとまだ微妙だが，今後最初からインストールされる可能性もある．<br />
そのような状況で，Agentから取れるログをCloudWatch Logsで直接見るので十分であれば，Fluentdを入れるメリットは少ない(<a href="https://github.com/ryotarai/fluent-plugin-cloudwatch-logs">CloudWatch Logs</a>用のプラグインがあるので，Fluentdから利用することは可能)．</p>

<p>Fluentdの利点は簡単にロバストで柔軟性のあるログ収集基盤が作れて，一度構築してしまえば，環境非依存でそのログ収集基盤を再利用出来るところなので，そのような必要性がないのであれば，環境と密結合したサービスを使う方が運用コストそのものは直近は削減できるはず．</p>

<h2>まとめ</h2>

<p>Fluentdが向いているケースと向いてないケース，そのPros/Consみたいなのを書いた．細かく書けばもっと色々と書けるのだけど，記事でそんなに長々と書いても疲れるだけなので大まかに．
何か質問があればTwitterで<a href="https://twitter.com/repeatedly">@repeatedly</a>にmentionするなり，この記事にコメントするなりしてください :)</p>

<p>もうすぐFluentd + Elasticsearch + Kibanaという有名な構成のムック本が出るようなので，この本とか読むと，解析のノウハウ含め色々とここには書いていない情報が手に入るのではないかと思います．<br />
<a href="http://www.amazon.co.jp/exec/obidos/ASIN/4774169838/repeatedly-22/ref=nosim/"><img src="http://ecx.images-amazon.com/images/I/61vwvFp6EEL._SL160_.jpg" /></a></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[MPP on Hadoop, Redshift, BigQuery]]></title>
    <link href="http://repeatedly.github.com/ja/2014/07/mpp-on-hadoop-redshift-bigquery/"/>
    <updated>2014-07-23T22:33:00+09:00</updated>
    <id>http://repeatedly.github.com/ja/2014/07/mpp-on-hadoop-redshift-bigquery</id>
    <content type="html"><![CDATA[<p>Twitterで「早く今流行のMPPの大まかな使い方の違い書けよ！」というプレッシャーが半端ないのでてきとうに書きます．この記事は俺の経験と勉強会などでユーザから聞いた話をもとに書いているので，すべてが俺の経験ではありません(特にBigQuery)．各社のSAの人とかに聞けば，もっと良いアプローチとか詳細を教えてくれるかもしれません．<br />
オンプレミスの商用MPPは使ったことないのでノーコメントです．</p>

<p>MPP on HadoopでPrestoがメインなのは今一番使っているからで，Impalaなど他のMPP on Hadoop的なものも似たような感じかなと思っています．
もちろん実装の違いなどがあるので，その辺は適宜自分で補間してください．</p>

<h2>前提</h2>

<p>アプリケーションを開発していて，そのための解析基盤を一から作る．</p>

<h2>簡単なまとめ</h2>

<ul>
<li>データを貯める所が作れるのであれば，そこに直接クエリを投げられるPrestoなどのMPPクエリエンジンを立てるのが楽

<ul>
<li>特にHadoopとかすでにある場合には，まずこれ</li>
</ul>
</li>
<li>データマートが必要であれば，RedshiftやBigQueryの方が向いている</li>
<li>ストレージもスキーマも運用も何も考えずにやりたいのであれば，BigQueryにFluentdとかでとりあえずJSONでぶち込むのが，多分この候補の中では一番初期コストが掛からない

<ul>
<li>もちろん要求によるので気をつける</li>
</ul>
</li>
<li>Presto + Redshiftというケースも有り(アドホックなクエリはPresto，BIからガリガリつなぐのにRedshiftなど)</li>
</ul>


<p>以下つらつらとリスト形式で書いてます．</p>

<h2>Presto/Impala/Drill</h2>

<p>PrestoやImpalaやApache Drillは，Redshift/BigQueryと違ってMPPデータベースではなくてMPPクエリエンジンなので，そこに違いがある．
Prestoそのものについては，@frsyuki が<a href="http://treasure-data.hateblo.jp/entry/2014/07/10/150250">HCJ 2014で発表したスライド</a>があるので，そっちも参考に．</p>

<ul>
<li>PrestoやImpalaはそもそもサービスじゃないので，自分ですべて運用する必要がある．

<ul>
<li>死活監視とか，もう少しワーカーが欲しかったら追加でデプロイみたいなのをする人が必要</li>
</ul>
</li>
<li>外部にストレージが必要

<ul>
<li>すでにある場合には，RedshiftやBigQueryじゃなくて，まずこれで十分かどうか試すという流れになりつつある</li>
<li>PrestoならS3とかにもクエリが投げられるので，FluentdでS3にJSONで貯めて，とかで構築コストはかなり軽減出来る</li>
</ul>
</li>
<li>ストレージ側にスキーマを要求せず，直接クエリが投げられる</li>
<li>MapReduceとかとデータソースを共有出来る

<ul>
<li>データ量が増えてくると，ストレージからMPPデータベースにimportするだけでコストになるので，アドホックにクエリが投げにくくなる</li>
<li>PrestoやApache Drillは一つのクエリで複数のデータソースにアクセス出来るので．マスターテーブルとのjoinとかが楽に出来る</li>
</ul>
</li>
<li>速さに関しては，やはりスキーマありでチューニングされたMPPにはまだ基本勝てない．状況によっては勝てる時もある

<ul>
<li>それでも数秒 - 数十秒で返ってきたりするので，どこまでパフォーマンスを求めるかによる</li>
</ul>
</li>
<li>クエリ同時実行制御に関しては，まだ商用のものに迫っているのはない印象

<ul>
<li>ここの改善に取り組んでいる人たちがいるので，いずれデータマート的にも使えるようになる可能性は高い</li>
</ul>
</li>
<li>オープンソースなので，問題があったら自分で修正可能，処理傾向も把握しやすい</li>
</ul>


<h2>Redshift</h2>

<ul>
<li>スキーマが必須なので，アドホックに解析するためのデータベースとしては少し不向き

<ul>
<li>やるならデータをJSON文字列で保存，クエリ時に分解する．効率は落ちる</li>
</ul>
</li>
<li>MPPデータベース(ParAccel)がAWSカスタマイズされて載っているので，その辺の知識がないと嵌まりやすい

<ul>
<li>AWS Casualで青木さんが話した<a href="http://www.slideshare.net/mineroaoki/20140419-aws-casualredshiftpublic">ふつうのRedshiftパフォーマンスチューニング</a>が参考になる</li>
<li>データ量がすくないとそれでもパワーでなんとかなる</li>
</ul>
</li>
<li>マネージドサービスとはいえ，リーダーノードの挙動がおかしい時など，面倒を見ないと行けないケースはある</li>
<li>カラムを弄る場合は基本テーブルを作り直すのがベター．クラスタ再配置中はREAD ONLYになるので，その辺含めて運用を考える必要がある

<ul>
<li>数時間READ ONLYの場合，貯めようとしていたログはどうするか，など</li>
<li>今時はMPPデータベース単体で運用している所は少ない．RedshiftでもEMRなどからデータを整形して一気にガツンと入れるのが多い</li>
</ul>
</li>
<li>クエリの同時実行制御周りはそれなりに頑張っている

<ul>
<li>データマートして使いやすい．<a href="https://twitter.com/mineroaoki/status/491995296671363073">バッチを投げると厳しい</a>とのこと．</li>
</ul>
</li>
<li>ストレージと演算パワーが分離してないので，ユースケースによってはコストが割に合わない

<ul>
<li>特に周りだとSSDインスタンスを使っている人は<del>いない</del>ほとんどいない(<a href="https://twitter.com/repeatedly/status/489635755979837441">この辺の話</a>)．</li>
<li>某ふっふはっほ社が「たべみる」でSSDをつかってました(<a href="http://www.slideshare.net/mineroaoki/at-aws-summit-tokyo-2014/9">AWS Summitでのスライド</a>)．が，これはかなり<a href="https://twitter.com/mirakui/status/491947294019690497">特殊な</a><a href="https://twitter.com/mirakui/status/491948100571758592">ケース</a>な気も．<a href="https://twitter.com/mineroaoki/status/49">横に並べることによるメリット</a>が大きいようです．</li>
</ul>
</li>
</ul>


<h2>BigQuery</h2>

<ul>
<li>Redshiftと同じく，アドホックに色々とデータをぶち込んで解析するには，JSON文字列(record型？)で保存する必要がある</li>
<li>既存のMPPデータベースとかで考えないと行けない問題(distkeyとか)を，Googleパワーで強引に解決</li>
<li>運用は完全Google任せ

<ul>
<li>Redshiftと違いGoogleの環境を共有するので，細かなことは出来ない</li>
</ul>
</li>
<li>Googleの制約を受ける

<ul>
<li>負荷が極端に上がるようなクエリとかは望み薄(FULL OUTER JOIN, 数億同士のjoin，count(distinct))</li>
<li>Redshift同様，でかいバッチ向けにHDFSとかオブジェクトストレージに生のデータを置いておくのがベター</li>
</ul>
</li>
<li>BigQueryもスキーマがあり，alter column的なものがないので，変更する時は適宜テーブルを作り直すのがベター</li>
<li>Redshiftと違いクエリ単位の課金なので，どれだけ掛かるか把握するのが難しい

<ul>
<li>小さい会社だとかなりマネージしやすい(<a href="https://twitter.com/repeatedly/status/491889139579506688">この辺の話</a>)．大きい会社や，マーケや営業の人がガンガン使う場合には，かなりバーストする可能性がある．Reservedがあるが，<a href="https://developers.google.com/bigquery/pricing?hl=ja#reserved_cap">月200万から</a>なので，判断が難しい</li>
</ul>
</li>
<li>Streaming Importが結構パフォーマンスが出るので，importして即クエリがやりやすい(<a href="http://qiita.com/kazunori279/items/10ac0066ac9b0b5aaaf3">参考記事</a>)

<ul>
<li>リミットがあるので，大量に入れる時には気をつける．2015年から有料．</li>
</ul>
</li>
<li>同時実行制御周りは基本よく動く

<ul>
<li>リソースはGoogle側が管理しているので，バッチ投げたら詰まるとかは起きにくい</li>
<li>リソースを占有しているわけではないので，勝手にクエリが死んだり，いきなり遅くなったりすることもある

<ul>
<li>日本時間の21時当たりで起きやすいらしい．でかいバッチを投げまくっているユーザが海外にいる？</li>
</ul>
</li>
</ul>
</li>
</ul>


<h2>まとめ</h2>

<p>基本的にこれらの裏にはHadoopなどの基盤が前提になりつつある(オブジェクトストレージ + 演算リソースでも可)．上のリストを眺めれば，なんとなく使い分けが分かるんじゃないでしょうか！
MPPと一纏めにするにはユースケースや得意なものが違うので，ちゃんと使い分けましょう．基本的にどれもBIツールと接続する方法があり，苦労はそんなにしないはず．</p>

<p>各プロダクトは常に改善されているので，ここに書いてある制約などは，いずれ緩和される可能性があります．常に最新情報をチェックしましょう．</p>

<p>今回はMPPクエリエンジンプロダクトの話なので上のリストでは省きましたが，Treasure Dataが提供しているTQAというMPPサービスは「Prestoで運用とかストレージを考えなくていい版」に近い感じになります．TDはさまざまな<a href="http://docs.treasuredata.com/categories/result">外部ストレージと連携出来る</a>ので，<a href="http://treasure-data.hateblo.jp/entry/2014/05/14/104632">Treasure Dataを中心に使い分ける感じになります</a>．<br />
最後に宣伝！</p>

<h2>P.S</h2>

<p>Twitterに流したさらに要約したtweet.</p>

<blockquote class="twitter-tweet" lang="en"><p>Presto on Storage/BigQuery/Redshiftはユースケースがバラバラなので，適宜使い分ければ良いという単純な話．ただ，HDFSやオブジェクトストレージみたいなのにデータが永続化されている前提なので，Prestoは入りには楽だよね，というのはあります．</p>&mdash; Mr. Fiber (@repeatedly) <a href="https://twitter.com/repeatedly/statuses/491883277829951488">July 23, 2014</a></blockquote>


<script async src="http://repeatedly.github.com//platform.twitter.com/widgets.js" charset="utf-8"></script>




<blockquote class="twitter-tweet" lang="en"><p>Redshiftは同時実行制御頑張っているし，distkeyとかをちゃんと設計してあげればかなりパフォーマンスが出るので，データマートとして優秀．特に8XLとかであれば，RDSとかでは頑張れない領域になる．ただ，スキーマの変更に弱いので，適宜ロードしてあげないと行けないのがネック</p>&mdash; Mr. Fiber (@repeatedly) <a href="https://twitter.com/repeatedly/statuses/491884516605038592">July 23, 2014</a></blockquote>


<script async src="http://repeatedly.github.com//platform.twitter.com/widgets.js" charset="utf-8"></script>




<blockquote class="twitter-tweet" lang="en"><p>BigQueryは逆に，その辺のMPPの知識ないけど楽に処理したい，という時には便利．ストレージと密結合しているRedshiftと違ってストレージとしては安価なので，ガンガンデータを入れられる．スキーマの変更に弱いのと，G社の都合でクエリに制限が掛かったり不安定になるのがネック</p>&mdash; Mr. Fiber (@repeatedly) <a href="https://twitter.com/repeatedly/statuses/491884911515533312">July 23, 2014</a></blockquote>


<script async src="http://repeatedly.github.com//platform.twitter.com/widgets.js" charset="utf-8"></script>




<blockquote class="twitter-tweet" lang="en"><p>Prestoは単体だとストレージがないので，裏側に何を使うかによってかなり左右される．ちゃんとしたHadoopクラスタやオブジェクトストレージがあれば，同時実行制御の部分に難はあるが，低レイテンシクエリーとしては十分優秀．データのインポートの手間がないのが大きい．</p>&mdash; Mr. Fiber (@repeatedly) <a href="https://twitter.com/repeatedly/statuses/491885404665049089">July 23, 2014</a></blockquote>


<script async src="http://repeatedly.github.com//platform.twitter.com/widgets.js" charset="utf-8"></script>




<blockquote class="twitter-tweet" lang="en"><p>まぁHadoopとかあるならとりあえずPresto入れとくか，という流れにはなりつつある気がする．それでも同時にたくさんのクエリが飛んでくるとか，ある程度スキーマ固まったのでガッツリ使いたい，になるとRedshiftとかBigQueryにバッチでinsert，がよくあるパターン</p>&mdash; Mr. Fiber (@repeatedly) <a href="https://twitter.com/repeatedly/statuses/491886467266789376">July 23, 2014</a></blockquote>


<script async src="http://repeatedly.github.com//platform.twitter.com/widgets.js" charset="utf-8"></script>




<blockquote class="twitter-tweet" lang="en"><p>やっぱり他のMPPデータベースにデータ入れるの面倒だからPrestoでがんばりたい，というユーザ結構いてその人たちが色々とPrestoをデータマート的に使えるようにと頑張っているようなので，いずれHadoop上ですべて完結する世界は来るかもしれない</p>&mdash; Mr. Fiber (@repeatedly) <a href="https://twitter.com/repeatedly/statuses/491887539267960833">July 23, 2014</a></blockquote>


<script async src="http://repeatedly.github.com//platform.twitter.com/widgets.js" charset="utf-8"></script>




<blockquote class="twitter-tweet" lang="en"><p>トレジャーデータというサービス，自分でインフラ管理する必要ないですし，Fluentd/JS/iOS/Androidなどからデータを入れるだけで，即バッチや低レイテンシクエリを投げられる，便利なサービスらしいですよ &gt; <a href="http://t.co/gSg9ZTNjKt">http://t.co/gSg9ZTNjKt</a></p>&mdash; Mr. Fiber (@repeatedly) <a href="https://twitter.com/repeatedly/statuses/491889631437144064">July 23, 2014</a></blockquote>


<script async src="http://repeatedly.github.com//platform.twitter.com/widgets.js" charset="utf-8"></script>




<blockquote class="twitter-tweet" lang="en"><p>社会人の勤めを果たした</p>&mdash; Mr. Fiber (@repeatedly) <a href="https://twitter.com/repeatedly/statuses/491889663787819008">July 23, 2014</a></blockquote>


<script async src="http://repeatedly.github.com//platform.twitter.com/widgets.js" charset="utf-8"></script>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Release fluent-plugin-http-puma]]></title>
    <link href="http://repeatedly.github.com/ja/2014/07/release-fluent-plugin-http-puma/"/>
    <updated>2014-07-20T18:42:00+09:00</updated>
    <id>http://repeatedly.github.com/ja/2014/07/release-fluent-plugin-http-puma</id>
    <content type="html"><![CDATA[<p><a href="https://github.com/repeatedly/fluent-plugin-http-puma">fluent-plugin-http-puma</a></p>

<p>標準で入っているin_httpとは違って，Pumaと呼ばれるWebサーバベースのHTTP(S)でのリクエストを受け付けるInputプラグイン書きました．</p>

<h2>使い方</h2>

<p>fluent-gemでインストール．</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>$ fluent-gem install fluent-plugin-http-puma</span></code></pre></td></tr></table></div></figure>


<p>in_httpとほぼ同じように動きますが，独自でHTTPリクエストをパースしてないので，keepaliveやボディサイズチェック用のオプションはありません．その代わりPuma関係のオプションが増えてます(<a href="https://github.com/repeatedly/fluent-plugin-http-puma#configuration">README参照</a>)．<br />
一番の違いは，HTTPSをサポートしている所です．<code>use_ssl</code>と<code>ssl_keys</code>を使うことで，HTTPSとして立ち上がります．</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
</pre></td><td class='code'><pre><code class='aconf'><span class='line'><span class="nt">&lt;source&gt;</span>
</span><span class='line'>  <span class="nb">type</span> http_puma
</span><span class='line'>
</span><span class='line'>  <span class="err">use_</span><span class="nb">ssl</span>
</span><span class='line'>  ssl_keys [<span class="s2">&quot;/path/to/key&quot;</span>, <span class="s2">&quot;/path/to/cert&quot;</span>]
</span><span class='line'><span class="nt">&lt;/source&gt;</span>
</span></code></pre></td></tr></table></div></figure>


<h2>パフォーマンス</h2>

<p>手元のMBPで試して見たら，HTTPはin_httpより少し速かった．HTTPSは当たり前ですがｶﾞｸｯと落ちます．</p>

<p>クライアントはRubyの<code>net/http</code>を使って，小さめのjsonを<code>application/json</code>で送ってます．</p>

<ul>
<li>in_http</li>
</ul>


<p>平均2400 events/secくらい．</p>

<pre><code>2014-07-20 19:02:30 +0900 [info]: plugin:out_flowcounter_simple count:2318      indicator:num   unit:second
2014-07-20 19:02:31 +0900 [info]: plugin:out_flowcounter_simple count:2420      indicator:num   unit:second
2014-07-20 19:02:32 +0900 [info]: plugin:out_flowcounter_simple count:2383      indicator:num   unit:second
2014-07-20 19:02:33 +0900 [info]: plugin:out_flowcounter_simple count:2399      indicator:num   unit:second
2014-07-20 19:02:34 +0900 [info]: plugin:out_flowcounter_simple count:2382      indicator:num   unit:second
</code></pre>

<ul>
<li>in_http_puma</li>
</ul>


<p>平均2500 events/secくらい．Ojを使ったらもっと速くなるかと思ったけど，ほぼ誤差の範囲だった．</p>

<pre><code>2014-07-20 19:01:12 +0900 [info]: plugin:out_flowcounter_simple count:2472      indicator:num   unit:second
2014-07-20 19:01:13 +0900 [info]: plugin:out_flowcounter_simple count:2550      indicator:num   unit:second
2014-07-20 19:01:14 +0900 [info]: plugin:out_flowcounter_simple count:2294      indicator:num   unit:second
2014-07-20 19:01:15 +0900 [info]: plugin:out_flowcounter_simple count:2537      indicator:num   unit:second
2014-07-20 19:01:16 +0900 [info]: plugin:out_flowcounter_simple count:2538      indicator:num   unit:second
</code></pre>

<ul>
<li>in_http_puma with VERIFY_NONE client</li>
</ul>


<p>平均400 events/secくらい．けどVERIFY_NONEはほとんど本番では使われないので参考程度．</p>

<pre><code>2014-07-20 19:04:06 +0900 [info]: plugin:out_flowcounter_simple count:406       indicator:num   unit:second
2014-07-20 19:04:07 +0900 [info]: plugin:out_flowcounter_simple count:365       indicator:num   unit:second
2014-07-20 19:04:08 +0900 [info]: plugin:out_flowcounter_simple count:400       indicator:num   unit:second
2014-07-20 19:04:09 +0900 [info]: plugin:out_flowcounter_simple count:399       indicator:num   unit:second
2014-07-20 19:04:10 +0900 [info]: plugin:out_flowcounter_simple count:400       indicator:num   unit:second
</code></pre>

<ul>
<li>in_http_puma with VERIFY_PEER client</li>
</ul>


<p>平均320 events/secくらい．高負荷環境で無ければ大丈夫かな…？</p>

<pre><code>2014-07-20 19:05:18 +0900 [info]: plugin:out_flowcounter_simple count:329       indicator:num   unit:second
2014-07-20 19:05:19 +0900 [info]: plugin:out_flowcounter_simple count:327       indicator:num   unit:second
2014-07-20 19:05:20 +0900 [info]: plugin:out_flowcounter_simple count:327       indicator:num   unit:second
2014-07-20 19:05:21 +0900 [info]: plugin:out_flowcounter_simple count:325       indicator:num   unit:second
2014-07-20 19:05:22 +0900 [info]: plugin:out_flowcounter_simple count:326       indicator:num   unit:second
</code></pre>

<h2>まとめ</h2>

<p>モダンと言われるPumaってどんなもんなんだろう？と調べてたら，HTTPSを標準でサポートしてるし，ライブラリとしても簡単に使えそうだったので試して見たら，それなりにパフォーマンスが出たので公開してみたという感じです．<br />
Pumaなので，今後FluentdがJRubyとかサポートしても普通にそのまま使えると思います．</p>

<p>実際HTTPSを処理するならFluentdの前にNginxとかを置いた方が良いのだけど，バックエンドでも通信はHTTPSでやってるとかなんか縛りがあるような環境では，手軽に使えるのではないかと思います．</p>

<p>何かあれば<a href="https://github.com/repeatedly/fluent-plugin-http-puma">issue/pull request</a>に投げてもらえれば対応します．</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Prestoソースコードリーディング #4]]></title>
    <link href="http://repeatedly.github.com/ja/2014/07/presto-scr-4/"/>
    <updated>2014-07-17T17:53:00+09:00</updated>
    <id>http://repeatedly.github.com/ja/2014/07/presto-scr-4</id>
    <content type="html"><![CDATA[<p><a href="http://atnd.org/events/53545">Presto ソースコードリーディング #4</a></p>

<p>いつものようにLINEでやりました！</p>

<p>@frsyukiが帰国する前に，という流れで開催決定・募集が1週間前というタイトなスケジュールでしたが，
無茶ぶりにつきあってくれた@ueshinさんに感謝．</p>

<h2>当日の内容</h2>

<p><a href="http://togetter.com/li/694128">togetterのまとめ</a>を見れば，なんとなく大まかな流れは把握できるはず…！</p>

<p>ueshinさんが第二回のashigeruさんの論理計画実行の後を継いで，
物理計画実行周りの話をしてくれました(<a href="https://gist.github.com/ueshin/5e38cfe915ce15f756b1">資料のgist</a>)．
バイトコード生成しての高速化の話とか，Presto以外でも有用な話が出てました．</p>

<p>frsyukiが現在のPrestoの開発体制の話，Treasure Dataでハックしている所の紹介，
CREATE VIEWなどの実装がなぜこうなっているのか(これはfrsyuki案が通ったらしい)，
今後Prestoチームがやろうとしていることなど含め，その場で色々と議論する感じになりました．</p>

<h2>まとめ</h2>

<p>少人数でソースコードレベルで興味のある人が集まっているのもあり，いつも通り濃い感じでした！
partitionedの話とか，現在の実行モデルにおけるオペレータの実装の話とか，
この辺を話すイベントはあんまりないんじゃないかなと思います．</p>

<p>次第5回をいつやるかは決まってませんが，いずれやる予定です．</p>

<p>またソースコードリーディングとは別に，Prestoのユースケースや，
プロダクションで動かしている人の運用の話などを共有する，
Presto meetupみたいなもう少し緩めのイベントもやる予定です．</p>

<p>お楽しみに :)</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Release fluent-plugin-multi-format-parser]]></title>
    <link href="http://repeatedly.github.com/ja/2014/07/release-fluent-plugin-multi-format-parser/"/>
    <updated>2014-07-13T21:00:00+09:00</updated>
    <id>http://repeatedly.github.com/ja/2014/07/release-fluent-plugin-multi-format-parser</id>
    <content type="html"><![CDATA[<p><a href="https://github.com/repeatedly/fluent-plugin-multi-format-parser">fluent-plugin-multi-format-parser</a></p>

<p>一つのログファイルの中に複数のフォーマットがある時に利用可能なパーサプラグイン書きました．</p>

<h2>使い方</h2>

<p>fluent-gemでインストール．</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>$ fluent-gem install fluent-plugin-multi-format-parser</span></code></pre></td></tr></table></div></figure>


<p>インストールすると，TextParserを利用している<code>in_tail</code>や<code>in_udp</code>などで<code>multi_format</code>が使えるようになります．
そこで<code>&lt;pattern&gt;</code>を複数並べてください．<code>&lt;pattern&gt;</code>内の各設定は，利用するパーサにそのまま渡されます．</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
</pre></td><td class='code'><pre><code class='aconf'><span class='line'><span class="nt">&lt;source&gt;</span>
</span><span class='line'>  <span class="nb">type</span> udp
</span><span class='line'>  <span class="nb">tag</span> logs.multi
</span><span class='line'>
</span><span class='line'>  <span class="nb">format</span> multi_format
</span><span class='line'>  <span class="nt">&lt;pattern&gt;</span>
</span><span class='line'>    <span class="nb">format</span> apache
</span><span class='line'>  <span class="nt">&lt;/pattern&gt;</span>
</span><span class='line'>  <span class="nt">&lt;pattern&gt;</span>
</span><span class='line'>    <span class="nb">format</span> json
</span><span class='line'>  <span class="nt">&lt;/pattern&gt;</span>
</span><span class='line'>  <span class="nt">&lt;pattern&gt;</span>
</span><span class='line'>    <span class="nb">format</span> <span class="k">none</span>
</span><span class='line'>  <span class="nt">&lt;/pattern&gt;</span>
</span><span class='line'><span class="nt">&lt;/match&gt;</span>
</span></code></pre></td></tr></table></div></figure>


<p><code>&lt;pattern&gt;</code>を上から順番に試し，パース出来たらその結果を返します．上の設定例だと，最初に<code>apache</code>，次に<code>json</code>，最後に<code>none</code>になります．
たとえば，以下のようなログ群を<code>in_udp</code>に流すと</p>

<pre><code>192.168.0.1 - - [28/Feb/2013:12:00:00 +0900] "GET / HTTP/1.1" 200 777
{"k1":"v", "k2":123456}
foobar
</code></pre>

<p>以下のように処理されます．</p>

<pre><code>2013-02-28 12:00:00 +0900 test.**: {"host":"192.168.0.1","user":"-","method":"GET","path":"/","code":"200","size":"777"}
2014-07-13 20:56:55 +0900 test.**: {"k":"v","k1":123456}
2014-07-13 20:56:55 +0900 test.**: {"message":"foobar"}
</code></pre>

<h2>まとめ</h2>

<p>ログファイルの中に複数のフォーマットが混じるのは望ましいことではないのですが，どうしてもそういう状況が起きるときには，使ってみてください．</p>

<p>あと，実装はかなり単純なので，パーサプラグインのサンプルにでもしてもらえればと思います．</p>

<p>何か要望があれば<a href="https://github.com/repeatedly/fluent-plugin-multi-format-parser">issue/pull request</a>に投げてもらえれば対応します．</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Release fluent-plugin-netflow]]></title>
    <link href="http://repeatedly.github.com/ja/2014/07/release-fluent-plugin-netflow/"/>
    <updated>2014-07-11T21:35:00+09:00</updated>
    <id>http://repeatedly.github.com/ja/2014/07/release-fluent-plugin-netflow</id>
    <content type="html"><![CDATA[<p><a href="https://github.com/repeatedly/fluent-plugin-netflow">fluent-plugin-netflow</a></p>

<p>CiscoのNetflowプロトコルを受け取るFluentdプラグインを書きました．
公開してみたら結構反応が良くて，地味にユーザが多そうですね…</p>

<h2>経緯</h2>

<p>Fluentdを調べていたユーザから「ログ収集基盤をFluentdベースにしたいんだけど，Netflowをパースするプラグインないの？」と言われたので，
さくっと作ってみました．<br />
「さくっと」と言ってもコアのパーサー部分はそのユーザが使っていたLogstashからポーティングしたやつなので，それなりにパース出来るはずです．
Pull Requestのおかげもあり，対応templateも少し増えてます．</p>

<h2>使い方</h2>

<p>fluent-gemでインストールするだけです．</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>$ fluent-gem install fluent-plugin-netflow</span></code></pre></td></tr></table></div></figure>


<p>その後，以下のように設定します．typeとtagは必須です．他のやつは適宜環境に合わせて設定してください．</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
</pre></td><td class='code'><pre><code class='aconf'><span class='line'><span class="nt">&lt;source&gt;</span>
</span><span class='line'>  <span class="nb">type</span> netflow
</span><span class='line'>  <span class="nb">tag</span> netflow.event
</span><span class='line'>
</span><span class='line'>  <span class="c"># optional parameters</span>
</span><span class='line'>  <span class="nb">bind</span> <span class="m">127.0.0.1</span>
</span><span class='line'>  <span class="nb">port</span> <span class="m">9555</span>
</span><span class='line'>
</span><span class='line'>  <span class="c"># optional parser parameters</span>
</span><span class='line'>  <span class="err">cache_</span><span class="nb">ttl</span> <span class="m">6000</span>
</span><span class='line'>  <span class="nb">versions</span> [5, <span class="m">9</span>]
</span><span class='line'>  <span class="nb">definitions</span> <span class="sx">/path/to/your_definitions.yml</span>
</span><span class='line'><span class="nt">&lt;/match&gt;</span>
</span></code></pre></td></tr></table></div></figure>


<p>今現在はin_syslogの影響もあってデフォルトポートが5140のままなのですが，0.1.0を出す時に変更する予定です．</p>

<h2>TODO</h2>

<ul>
<li>俺自身がNetflow関係のやつを持っていないので，使っている人，誰かメンテナになってください！実環境でのテストが出来ませんｗ</li>
<li>Fluentd v0.10.52が出たら，FluentdのSocketUtilベースで書き直して，0.1.0を出す</li>
</ul>


<p>他，何か要望があれば<a href="https://github.com/repeatedly/fluent-plugin-netflow">issue/pull request</a>をしてもらえれば対応します．</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Fluentd v1 and Roadmapというプレゼンをしてきた]]></title>
    <link href="http://repeatedly.github.com/ja/2014/05/fluentd-v1-and-roadmap/"/>
    <updated>2014-05-15T18:55:00+09:00</updated>
    <id>http://repeatedly.github.com/ja/2014/05/fluentd-v1-and-roadmap</id>
    <content type="html"><![CDATA[<p><a href="http://eventdots.jp/event/49560">Fluentd Meetup 新しい応用事例とv1に関する発表</a></p>

<p>フリークアウトさんのオフィスでFluentd Meetupがあり，Fluentdのv1について話してきました．</p>

<iframe src="http://www.slideshare.net/slideshow/embed_code/34652297?rel=0" width="427" height="356" frameborder="0" marginwidth="0" marginheight="0" scrolling="no" style="border:1px solid #CCC; border-width:1px 1px 0; margin-bottom:5px; max-width: 100%;" allowfullscreen> </iframe>


<p> <div style="margin-bottom:5px"> <strong> <a href="https://www.slideshare.net/treasure-data/fluentd-v1-and-roadmap" title="Fluentd v1 and Roadmap" target="_blank">Fluentd v1 and Roadmap</a> </strong> from <strong><a href="http://www.slideshare.net/treasure-data" target="_blank">Treasure Data, Inc.</a></strong> </div></p>

<p>今回の発表は，今までのv11やv1に関してのまとめ的な発表になっています．<br />
以下のリンク集を見れば，発表内容の大抵はカバー出来ると思います．
また，他の方もまとめ記事とかを書かれているので，そちらも参照してください．</p>

<ul>
<li><a href="http://repeatedly.github.io/ja/2014/03/about-fluentd-v11/">そろそろFluentd v11についてひとこと言っておくか</a></li>
<li><a href="https://github.com/fluent/fluentd/issues/251">Plan for v1 release #251</a></li>
<li><a href="https://github.com/fluent/fluentd/issues/317">Support JRuby #317</a></li>
<li><a href="https://github.com/fluent/fluentd/tree/windows">FluentdのWindowsブランチ</a></li>
<li><a href="https://github.com/fluent/fluentd/pull/293">Add &#8211;use-v1-config option to enable new configuration format #293</a></li>
<li><a href="https://github.com/repeatedly/omnibus-td-agent">td-agent2のパッケージリポジトリ</a></li>
</ul>


<p>俺の方から言えることは，Fluentd v0.10.46以降を使っている方は，
積極的に<code>--use-v1-config</code>オプションを使ってくださいということです．<br />
既存のフォーマットとの違いは<a href="http://docs.fluentd.org/articles/config-file#v1-format">ドキュメントを参照</a>してください．</p>

<p>td-agent2は今ビルド中で，今週末あたりにリリースしたいと思ってます(パッケージングツールをアップデートしたら色々と壊れて無駄に時間が…)．
それ以降はv1にリソースを割けるはずなので，フィルタやラベルなどを実装していく予定です．ご期待ください！</p>

<p>また，Treasure DataはFluentdの開発者含め<a href="http://www.treasuredata.com/jp/about/careers.php">人材を募集している</a>ので，
興味のある方はぜひぜひコンタクトをしてもらえればと思います！</p>

<p>P.S.</p>

<p>フリークアウトさんのオフィスにある，バスケのゴールにダンク出来なかったのが悔しいので，足腰鍛え直す．</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[MultiOS testing for Fluentd repository on Travis CI]]></title>
    <link href="http://repeatedly.github.com/2014/05/multios-testing-for-fluentd-repository-on-travis-ci/"/>
    <updated>2014-05-15T14:22:00+09:00</updated>
    <id>http://repeatedly.github.com/2014/05/multios-testing-for-fluentd-repository-on-travis-ci</id>
    <content type="html"><![CDATA[<p>Recently, Travis CI announces &#8220;Multi-OS feature&#8221; on their blog.</p>

<p><a href="http://blog.travis-ci.com/2014-05-13-multi-os-feature-available/">Multi-OS Feature Available</a></p>

<p>If this feature is enabled, our project can be tested on both Linux and Mac OS X. <br />
Multi OS feature has been enabled for <a href="https://github.com/fluent/fluentd/commit/e4bb4f61e91c70a95690d19b07414b485e7a3542">Fluentd repository</a>. See following build:</p>

<p><a href="https://travis-ci.org/fluent/fluentd/builds/25147077">fluent/fluentd on Travis CI</a></p>

<p>This is very useful for checking commit and PR. Thanks Travis CI and Facebook team!</p>
]]></content>
  </entry>
  
</feed>
