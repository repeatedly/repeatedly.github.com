
<!DOCTYPE html>
<!--[if IEMobile 7 ]><html class="no-js iem7"><![endif]-->
<!--[if lt IE 9]><html class="no-js lte-ie8"><![endif]-->
<!--[if (gt IE 8)|(gt IEMobile 7)|!(IEMobile)|!(IE)]><!--><html class="no-js" lang="en"><!--<![endif]-->
<head>
  <meta charset="utf-8">
  <title>Go ahead!</title>
  <meta name="author" content="Masahiro Nakagawa">

  
  <meta name="description" content="Fluentd，最近だと海外でも露出が増えてきていて，軽量・柔軟・ロバストという所で，
新規の他，既存のログコレクタのリプレース含め，採用する所が増えてたりします． より改善するため色々とユーザにヒアリングした結果，「フィルタ機能が欲しい」というのが一番多い意見でした． &hellip;">
  

  <!-- http://t.co/dKP3o1e -->
  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  
  <link rel="canonical" href="http://repeatedly.github.com/ja">
  <link href="/favicon.png" rel="icon">
  <link href="/stylesheets/screen.css" media="screen, projection" rel="stylesheet" type="text/css">
  <script src="/javascripts/modernizr-2.0.js"></script>
  <script src="/javascripts/ender.js"></script>
  <script src="/javascripts/octopress.js" type="text/javascript"></script>
  <link href="/atom.xml" rel="alternate" title="Go ahead!" type="application/atom+xml">
  <!--Fonts from Google"s Web font directory at http://google.com/webfonts -->
<link href="http://fonts.googleapis.com/css?family=PT+Serif:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css">
<link href="http://fonts.googleapis.com/css?family=PT+Sans:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css">

  

</head>

<body   >
  <header role="banner"><hgroup>
  <h1><a href="/">Go ahead!</a></h1>
  
    <h2>Memoization for Everything</h2>
  
</hgroup>

</header>
  <nav role="navigation"><ul class="subscription" data-subscription="rss">
  <li><a href="/atom.xml" rel="subscribe-rss" title="subscribe via RSS">RSS</a></li>
  
</ul>
  
<form action="http://google.com/search" method="get">
  <fieldset role="search">
    <input type="hidden" name="q" value="site:repeatedly.github.com" />
    <input class="search" type="text" name="q" results="0" placeholder="Search"/>
  </fieldset>
</form>
  


  
<ul class="main-navigation">
  <li><a href="/ja/archives">Archives</a></li>
  <li><a href="/">English</a></li>
</ul>

  

</nav>
  <div id="main">
    <div id="content">
      <div class="blog-index">
  
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/ja/2014/08/fluentd-filter-and-label/">Fluentd v0.12でのFilterとLabel</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2014-08-25T17:30:00+09:00" pubdate data-updated="true">Aug 25<span>th</span>, 2014</time>
        
         | <a href="/ja/2014/08/fluentd-filter-and-label/#disqus_thread">Comments</a>
        
      </p>
    
  </header>


  <div class="entry-content"><p>Fluentd，最近だと海外でも露出が増えてきていて，軽量・柔軟・ロバストという所で，
新規の他，既存のログコレクタのリプレース含め，採用する所が増えてたりします．</p>

<p>より改善するため色々とユーザにヒアリングした結果，「フィルタ機能が欲しい」というのが一番多い意見でした．
Fluentdは元々Treasure Dataへロバストにデータを転送するためのミドルウェアで，「ETLとかはTreasure Dataで」
というのもあり，組み込みでフィルタ機能はありませんでした．</p>

<p>今現在のOutputプラグインによるフィルタ実装は，タグの書き換えが必要だったりして少し慣れが必要で，初心者にはちと難しい．
ということで，より簡単に効率よくデータストリームを扱えるフィルタ機能を入れることにしました！</p>

<p>前置きが長くなりましたが，次のバージョンであるv0.12ではFilterとLabelの導入が目玉機能になります．
これらは二つともデータストリームの処理をより楽にするための機能です．</p>

<p>後，<a href="http://www.fluentd.org/blog/fluentd-v0.10.53-is-released">Fluentd v0.10.53のリリースアナウンス</a>でも書きましたが，
今現在のmasterブランチはすでにv0.12用になっています．また，以下の機能はまだmasterにはマージされていません．今週中にはマージ予定ですが，
試して見たい方は，<a href="https://github.com/fluent/fluentd/pull/416">PR #416</a>をチェックしてください．</p>

<h2>Filter</h2>

<p>Outputプラグインで出力する前に，イベント群に処理を適用するための仕組みです．
<code>grep</code>や<code>record_refomer</code>や<code>geoip</code>プラグインなどは，Filterとして実装することでより効率良く処理出来るようになります．</p>

<p>最初に実装，その後に設定の例を見せます．</p>

<h3>実装</h3>

<p>FilterのAPIは以下のようになっています．</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
</pre></td><td class='code'><pre><code class='rb'><span class='line'><span class="k">module</span> <span class="nn">Fluent</span>
</span><span class='line'>  <span class="k">class</span> <span class="nc">SomeFilter</span> <span class="o">&lt;</span> <span class="no">Filter</span>
</span><span class='line'>    <span class="no">Plugin</span><span class="o">.</span><span class="n">register_filter</span><span class="p">(</span><span class="s1">&#39;some_filter&#39;</span><span class="p">,</span> <span class="nb">self</span><span class="p">)</span>
</span><span class='line'>
</span><span class='line'>    <span class="k">def</span> <span class="nf">filter</span><span class="p">(</span><span class="n">tag</span><span class="p">,</span> <span class="n">time</span><span class="p">,</span> <span class="n">record</span><span class="p">)</span>
</span><span class='line'>      <span class="c1"># レコードを弄るプラグインは，ここを実装すればOK</span>
</span><span class='line'>      <span class="c1"># レコードを返す必要がある</span>
</span><span class='line'>      <span class="n">modified_record</span>
</span><span class='line'>    <span class="k">end</span>
</span><span class='line'>
</span><span class='line'>    <span class="k">def</span> <span class="nf">filter_stream</span><span class="p">(</span><span class="n">tag</span><span class="p">,</span> <span class="n">es</span><span class="p">)</span>
</span><span class='line'>      <span class="c1"># 以下はFilterのデフォルト実装．grepなどはこちらを置き換えればOK</span>
</span><span class='line'>      <span class="n">new_es</span> <span class="o">=</span> <span class="no">MultiEventStream</span><span class="o">.</span><span class="n">new</span>
</span><span class='line'>      <span class="n">es</span><span class="o">.</span><span class="n">each</span> <span class="p">{</span> <span class="o">|</span><span class="n">time</span><span class="p">,</span> <span class="n">record</span><span class="o">|</span>
</span><span class='line'>        <span class="n">new_es</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">time</span><span class="p">,</span> <span class="n">filter</span><span class="p">(</span><span class="n">tag</span><span class="p">,</span> <span class="n">time</span><span class="p">,</span> <span class="n">record</span><span class="p">))</span>
</span><span class='line'>      <span class="p">}</span>
</span><span class='line'>      <span class="n">new_es</span>
</span><span class='line'>    <span class="k">end</span>
</span><span class='line'>  <span class="k">end</span> <span class="k">if</span> <span class="n">defined?</span><span class="p">(</span><span class="no">Filter</span><span class="p">)</span> <span class="c1"># v0.10とかでエラーにならないための回避策</span>
</span><span class='line'><span class="k">end</span>
</span></code></pre></td></tr></table></div></figure>


<h4>filter(tag, time, record)</h4>

<p><code>SetXXXMixin</code>を置き換える<a href="https://gist.github.com/repeatedly/cb16d5667350c8a0e2c9#file-filter_add_metadata-rb">add_metadata</a>フィルタを見て貰えればわかりやすいと思いますが，
引数で渡ってくるレコードを弄って，それを返り値にするだけです<br />
<code>filter</code>とは違い<code>filter_stream</code>は上記のデフォルト実装があるので，変更する必要はありません．</p>

<p>大抵のプラグインはこのAPIをオーバーライドして処理を実装すれば，その結果が次のフィルタに渡されるようになります．</p>

<h4>filter_stream(tag, es)</h4>

<p>EventStreamを直接処理するFilterを書くためのAPIです．例えば<code>grep</code>はレコードを弄らず，EventStream全体に対して処理を行うプラグインなので，
このAPIをオーバーライドします．<code>filter_stream</code>を変更する場合，<code>filter</code>を変更する必要はありません．<br />
<code>filter</code>とは違い，返り値としてEventStreamを返す必要があります．Fluentdは，この<code>filter_stream</code>の返り値を次のFilterに渡し，最終結果をOutputプラグインに渡します．</p>

<p>また，<code>record_reformer</code>の<code>renew_record</code>のように，新しくレコードを生成する系のプラグインもこちら側で処理を実装することになります．
<code>grep</code>と<code>record_reformer</code>のFilter例は以下にあります．</p>

<ul>
<li><a href="https://gist.github.com/repeatedly/0ed3e2b4016b4045640a#file-filter_grep-rb">filter_grep</a></li>
<li><a href="https://gist.github.com/repeatedly/5c9f89e14aace5cda195#file-filter_record_reformer-rb">filter_record_reformer</a></li>
</ul>


<h3>設定</h3>

<p><code>&lt;filter&gt;</code>セクションが追加されています．たとえば，<code>add_metadata</code>と<code>grep</code>を使う場合には以下のようになります．</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
</pre></td><td class='code'><pre><code class='aconf'><span class='line'><span class="nt">&lt;source&gt;</span>
</span><span class='line'>  <span class="nb">type</span> forward
</span><span class='line'><span class="nt">&lt;/source&gt;</span>
</span><span class='line'>
</span><span class='line'><span class="nt">&lt;filter&gt;</span> <span class="c"># &lt;filter&gt;と&lt;filter **&gt;は同じ</span>
</span><span class='line'>  <span class="nb">type</span> grep
</span><span class='line'>  <span class="err">input_</span><span class="nb">key</span> message
</span><span class='line'>  <span class="nb">regexp</span> <span class="k">WARN</span>
</span><span class='line'><span class="nt">&lt;/filter&gt;</span>
</span><span class='line'><span class="nt">&lt;filter&gt;</span>
</span><span class='line'>  <span class="nb">type</span> add_metadata
</span><span class='line'>  <span class="err">include_tag_</span><span class="nb">key</span>
</span><span class='line'>&lt;/filter&gt;
</span><span class='line'>
</span><span class='line'><span class="nt">&lt;match</span> <span class="s">**</span><span class="nt">&gt;</span>
</span><span class='line'>  <span class="nb">type</span> stdout
</span><span class='line'><span class="nt">&lt;/match&gt;</span>
</span></code></pre></td></tr></table></div></figure>


<p>Fluentdの設定ファイルの流儀にしたがって，上から順番に<code>match</code>にマッチしたところまでのFilterが適用されます．
この例では，まず<code>grep</code>が適用され，その次に<code>add_metadata</code>，そしてこれらの結果のEventStreamが<code>stdout</code>に渡されます．<br />
例えば以下のデータが入ってきたとして:</p>

<pre><code>{"message":"INFO"}
{"message":"WARN"}
</code></pre>

<p><code>stdout</code>には，<code>grep</code>で最初のレコードがフィルタリングされ，<code>add_metadata</code>でタグが追加された以下のデータが渡されます:</p>

<pre><code>{"message":"WARN", "tag":"filter.test"}
</code></pre>

<p>タグを書き換えて<code>match</code>の条件を調整して〜という煩わしさから解放されるようになります．</p>

<p>注意点としては，マッチした<code>match</code>の下にある<code>filter</code>は，たとえtagがマッチしようが適用されない所です．</p>

<h3>パフォーマンス</h3>

<p>タグの書き換えや再emitが発生しないため，速度やメモリ効率は多少よくなるはずです．</p>

<p>手元で約450MBのファイルを<code>in_tail</code>で読み込み，<code>record_reformer</code>でホスト名などを付加して転送する，
というのをv0.10とv0.12で測ってみた所，v0.10は181秒，v0.12は149秒で，約30秒短縮されました．</p>

<p>ユーザによってはもっとFilterがチェーンしている所もあるはずなので，そういう場合には恩恵が大きいと思います．</p>

<h2>Label</h2>

<p>これはFilterやOutputをまとめるための機能になります．制限として，InputはLabelの中に含めることは出来ません．
こちらは先に設定から見てみます．</p>

<h3>設定</h3>

<p>以下が簡単な例になります．</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
</pre></td><td class='code'><pre><code class='aconf'><span class='line'><span class="nt">&lt;source&gt;</span>
</span><span class='line'>  <span class="nb">type</span> forward
</span><span class='line'>  <span class="err">@</span><span class="nb">label</span> @forward
</span><span class='line'><span class="nt">&lt;/source&gt;</span>
</span><span class='line'>
</span><span class='line'><span class="nt">&lt;source&gt;</span>
</span><span class='line'>  <span class="nb">type</span> tail
</span><span class='line'>  <span class="nb">path</span> <span class="sx">/path/to/file</span>
</span><span class='line'>  <span class="nb">tag</span> tail
</span><span class='line'><span class="nt">&lt;/source&gt;</span>
</span><span class='line'>
</span><span class='line'><span class="nt">&lt;filter</span> <span class="s">**</span><span class="nt">&gt;</span>
</span><span class='line'>  <span class="nb">type</span> grep
</span><span class='line'>  <span class="c"># ...</span>
</span><span class='line'><span class="nt">&lt;/filter&gt;</span>
</span><span class='line'>
</span><span class='line'><span class="nt">&lt;match</span> <span class="s">**</span><span class="nt">&gt;</span>
</span><span class='line'>  <span class="nb">type</span> mongo
</span><span class='line'>  <span class="c"># ...</span>
</span><span class='line'><span class="nt">&lt;/match&gt;</span>
</span><span class='line'>
</span><span class='line'><span class="nt">&lt;label</span> <span class="s">@forward</span><span class="nt">&gt;</span>
</span><span class='line'>  <span class="nt">&lt;filter</span> <span class="s">**</span><span class="nt">&gt;</span>
</span><span class='line'>    <span class="nb">type</span> add_metadata
</span><span class='line'>    <span class="err">include_tag_</span><span class="nb">key</span>
</span><span class='line'>  &lt;/filter&gt;
</span><span class='line'>  <span class="nt">&lt;match</span> <span class="s">**</span><span class="nt">&gt;</span>
</span><span class='line'>    <span class="nb">type</span> file
</span><span class='line'>  <span class="nt">&lt;/match&gt;</span>
</span><span class='line'><span class="nt">&lt;/label&gt;</span>
</span></code></pre></td></tr></table></div></figure>


<p><code>forward</code>の中に<code>@label @forward</code>というパラメータがあります．これがLabelの指定になっていて，
<code>@label</code>があるとその指定されたLabelにイベント群が流れて行きます．なので，この例では<code>forward</code>で
受け付けたイベント群は，<code>add_metadata</code>フィルタを通り，その下の<code>file</code>に到達します．<br />
一方，<code>@label</code>のないInputは今までと同じ挙動となり，トップにイベント群を流します．
この例では，<code>grep</code>フィルタを通り，その下の<code>mongo</code>に到達します．</p>

<p>Labelの機能によって，各プラグイン間の関係がわかりやすくなり，またルーティングのためにタグを調整する必要もなくなります．
<code>out_relabel</code>プラグインを使えばデータを別のLabelに飛ばせるので，入力によって違うフィルタを適用したいが，書き込み先は一緒にしたい，
みたいな処理も簡単にできるようになります．</p>

<h3>実装</h3>

<p>v0.12から，<code>router</code>というのがInput/Outputに増えてます．今まで<code>Engine.emit</code>と書いていた所を，<code>router.emit</code>に書き換えるだけで，
Labelの機能が使えるようになります．<br />
言い換えれば，この書き換えをしていないInput/Outputプラグインは，<code>@label</code>が使えないということになります．</p>

<h2>まとめ</h2>

<p>v0.12の主要機能であるFilterとLabelについて簡単に説明しました．まだ実装としていくつか細かな改善はあるのですが，
基本機能は上記のままで行くと思います．<br />
何かフィードバックがあれば<code>@repeatedly</code>にmentionをするか，上記の該当PRにコメントをして貰えればと思います．</p>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/ja/2014/08/fluentd-ui/">Fluentd UI</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2014-08-04T04:10:00+09:00" pubdate data-updated="true">Aug 4<span>th</span>, 2014</time>
        
         | <a href="/ja/2014/08/fluentd-ui/#disqus_thread">Comments</a>
        
      </p>
    
  </header>


  <div class="entry-content"><p><a href="https://github.com/fluent/fluentd-ui">fluent/fluentd-ui</a></p>

<p><img src="/images/fluentd_ui_ss.png" title="&#34;Fluentd UI image&#34;" alt="&#34;Fluentd UI image&#34;"></p>

<p>Fluentdのエコシステムの一つとして，Fluentd UIをリリースしました．
すでに試してくれたユーザもいるようなので，現在の使用感などは下記の記事を参考にしてください．</p>

<ul>
<li><a href="http://suzuken.hatenablog.jp/entry/2014/08/01/202334">Fluentd UIが出たので触ってみた</a></li>
<li><a href="http://qiita.com/inokappa/items/0a4a2db7abad22458bea">Touch the fluentd-ui(1)</a></li>
</ul>


<p>この記事ではFluentd UIそのものについてつらつらと書きたいと思います．英語でのアナウンスもいずれ公式ブログに載るはず．</p>

<h2>Fluentd UIの生い立ち</h2>

<p>Fluentd UIの背景として，Fluentdも最近は国を問わず色々な所でユーザが増えてきており，
「CLIとか楽勝！」以外のユーザの割合も増えつつあります．</p>

<p>ログコレクタでリッチな管理UIを持っているプロダクトってほとんどないと思うのですが，
新しく使い始めるユーザの嵌まり所とか見ていると，
GUIの方が始めるための敷居が下がりそうなポイントがいくつかありました．</p>

<p>なので，Fluentdを使いたい人がなるべく嵌まらずに始められるようにと，
万葉の方と開発したのがFluentd UIです．</p>

<h2>Fluentd UIのコンセプト</h2>

<p>生い立ちの所で書いた通り，Fluentdの敷居を下げるのが第一の目的なので，
すでにFluentdをバリバリ使っている人はユーザの対象ではありません．</p>

<p>バージョン0.1.0の段階で，以下の機能があります:</p>

<ul>
<li>Fluentdのプロセスの管理 (start/stop/restart)</li>
<li>Fluentdの設定ファイルの管理と編集</li>
<li>Fluentdのプラグインの管理 (install/uninstall/update)</li>
<li>ログやシステム情報のビューワー，などなど</li>
</ul>


<p>最初に色々機能を洗い出したのですが，全部入れるとリリースが遅れるし，
複雑なのを入れるとユーザが混乱するかもということで，ベーシックな機能セットに絞りました．<br />
それでも，プラグイン入れての挙動チェックなど，全部Webから出来るようになっています．また，
ユーザがテストしにくかったin_tailは，<a href="http://fluentular.herokuapp.com/">Fluentular</a>を参考にかなり使いやすいUIになったと思います．</p>

<p>実装的にもかなり依存を減らしていて，例えば，最初はSQLiteベースだったのですが，
「SQLiteだとFluentd UIそのもののセットアップに嵌まる人が出る可能性がある」とファイルベースに変更したりしました．</p>

<h2>Fluentd UIの今後の展望</h2>

<h3>機能追加</h3>

<p>バージョン0.1.0ということから分かる通り，まだまだ始まったばかりのプロダクトで，
今回は開発者側が「こういう機能があったら始めやすいだろう」というものを中心に入れました．<br />
今後はユーザからのフィードバックも受けつつ，更に使いやすさを改善して行けたらなと．</p>

<p>現状各プラグインの設定を削除する時は，自分でフリーフォームから消す必要があるので，
この辺もボタンで消せるようにとか，出来たらいいかなぁと考えてます．<br />
あと，今設定が組み込みで実装してあるので(インストールした3rd partyプラグイン用の設定ページがない)，
各プラグインから自動で設定ページが生成できるような仕組みも必要かなと，色々と模索中です．</p>

<h3>td-agent 2への同梱</h3>

<p>td-agentには同梱予定はないんですが，td-agent 2にはtd-agent-uiみたいな感じで同梱する予定です．すでに起動した人は知っていると思いますが，td-agentをセットアップする用のボタンがあります :)</p>

<h3>他の環境との連携</h3>

<p>Fluentd UIは，UI上で色々と試行錯誤しその結果出来た設定ファイルをChefとかで配布，
みたいなのを想定しているのですが，毎回コピペとか面倒ですし，
最近だと<a href="https://github.com/sonots/fluentd-server">fluentd-server</a>とかもあるので，この辺なんか上手くやりたいな，と．</p>

<h2>まとめ</h2>

<p>Fluentd UIについて背景含めつらつらと書きました．是非試して頂いて，問題があったら<a href="https://github.com/fluent/fluentd-ui/issues">issue</a>投げるなり<a href="https://github.com/fluent/fluentd-ui/pulls">PR</a>なりしてもらえると助かります！</p>

<p>あ，ちなみに最初のリリースは俺がやりましたが，開発はコミットを見れば分かる通り<a href="https://github.com/uu59">uu59</a>さんでちゃんとしたRailsコードになっているので，ご心配なく！</p>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/ja/2014/07/fluentd-and-log-forwarding-patterns/">Fluentdとログ収集のパターン</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2014-07-31T18:35:00+09:00" pubdate data-updated="true">Jul 31<span>st</span>, 2014</time>
        
         | <a href="/ja/2014/07/fluentd-and-log-forwarding-patterns/#disqus_thread">Comments</a>
        
      </p>
    
  </header>


  <div class="entry-content"><p>「ログを集めて保存する」と言うのは簡単だけど，ログ収集の構成にはいくつか方法があり，勉強会などでちょくちょく聞かれるので，いくつかのパターンについて書く．<br />
「俺はもうバリバリログ収集やってるぜ！」という人は多分すでに知っていることが書かれているので，タブを閉じて良い．</p>

<p>ここではログコレクタにFluentdを想定しているが，他のログ収集プロダクトにも適用出来るはず．
ただ，Fluentdはタグベースのルーティングを持ち，単体でもキューのように動作させることが可能で，既存のものより複雑な問題を解決しようとしているので，少し工夫が必要かもしれない．<br />
Fluentdそのものについては<a href="http://docs.fluentd.org/articles/quickstart">公式ドキュメント</a>や，<a href="http://tagomoris.hatenablog.com/entry/2013/12/03/150656">Fluentdとはどのようなソフトウェアなのか</a>を参考に．</p>

<h2>クライアントから直接保存する</h2>

<p><img src="/images/fluentd_only_client_pattern.png" title="&#34;Only client pattern&#34;" alt="&#34;Only client pattern&#34;"></p>

<p>いきなりFluentdを使わないパターン．JavaScript SDKを提供している解析サービスやモバイル端末などでよく使われている．ログがユーザサイドで発生する場合にはログコレクタを仕込むことは出来ないので，基本このアプローチになる．<br />
これらはクライアントの出来によって精度が左右されるが，モバイルであれば繋がらなかったら一定量バッファリングをし，ネットワークが繋がった段階で非同期に転送などがよくある実装．</p>

<p>ログコレクタを用意出来るサーバサイドでこのアプローチを取っているシステムは最近だとあまり聞かない．もしやるならエラーハンドリングとして</p>

<ul>
<li>バッファリング</li>
<li>リトライ</li>
<li>ロードバランシング</li>
</ul>


<p>などの問題を解決する必要がある．Fluentdであればこれらの機能が最初からついているので，今から構築するシステムでやる必要はほとんど無いと思われる．</p>

<h2>末端ノードのログコレクタから直接保存する</h2>

<p><img src="/images/fluentd_only_leaf_node_pattern.png" title="&#34;Only leaf node pattern&#34;" alt="&#34;Only leaf node pattern&#34;"></p>

<p>アプリケーションやノードからログを集め，ログコレクタから直接保存する．「クライアントから直接保存する」の例で，ローカルにログコレクタを置き，そこ経由でデータを投げつけるモデル．<br />
ネットワーク周りのややこしい問題をログコレクタに任せられ，Fluentdであればプラグインで容易にストリームを操作できるのがメリット．また，ApacheやNginxから直接外部にデータを投げるのは難しいので，Fluentdでファイルにはき出されたログを収集するときにはこの構成となる．</p>

<p>この構成だと，収集対象のサーバが多くなるだけアクセスが増えて保存先への負荷があがるので</p>

<ul>
<li>データのストリームがそれほど大きくない</li>
<li>保存先が書き込みに対して耐性がある (クラウドサービスなど)</li>
</ul>


<p>などの場合に有効になる．次で書く集約ノードが必要ないので，その分管理は楽になる．<br />
Fluentdは転送役と集約役に違いはないので，この段階でフィルター系プラグインを使って，データを加工することもある．</p>

<p><a href="http://www.treasuredata.com/">Treasure Data</a>の場合には，<a href="https://metrics.librato.com/">Librato Metrics</a>に投げる所などは集約ノードを経由せず，各Fluentd(Treasure Agent)から直接投げている．この場合は各ノードのメトリックスが取りたいので，集約ノードでデータストリームをまとめる必要もない．</p>

<p>これとは違いMongoDBの場合だと，細かいのをちまちま送るより大きめのバッチでガンと書き込んだ方が効率が良いので，このモデルよりも集約ノードを置いた方が良い．</p>

<h2>集約ノードのログコレクタを経由して保存する</h2>

<p><img src="/images/fluentd_aggregation_node_pattern.png" title="&#34;Using aggregation node pattern&#34;" alt="&#34;Using aggregation node pattern&#34;"></p>

<p>ログコレクタでの多段構成モデル．集約ノードを置く利点は，データストリームをまとめてデータに対する処理をしやすくする点が大きい．また，各ノードから集めることでストリームが太くなり，マイクロバッチの効率も良くなる．</p>

<p>Fluentdでもアグリゲーションをしたり，<a href="http://norikra.github.io/">Norikra</a>と連携するプラグインがあったりするので，その手の処理はこの集約ノードでやるのがベター．</p>

<p>大抵のログコレクタと同じく，Fluentdのデフォルトの転送プロトコルはPush型になっていて，多段構成時には流れるように保存先にデータが集まるようになっている．<br />
多段構成時の注意点は，ある場所のノードが落ちた時にストリームが途切れてしまう所．Fluentdの場合は障害に対応するために，転送先を複数指定可能で，その中で負荷分散とノードが落ちた時の処理を指定出来るようになっていて，よほど一気にノードが落ちない限りストリームが途切れることはない．もし落ちてもバッファリングが行われるので，ノードを再度立ち上げればデータはまた流れ出す．</p>

<h3>PaaS上でのアプリケーション</h3>

<p>アプリケーションをホストするような環境だとローカルにFluentdを置けなかったりするので(HerokuだとFluentdは起動できるが，ファイルバッファが使えなかったりする．ユースケース次第)，その場合はいきなり集約ノードやキューにデータを投げることになる．</p>

<h2>キューを置く</h2>

<p><img src="/images/fluentd_queue_pattern.png" title="&#34;Using queue pattern&#34;" alt="&#34;Using queue pattern&#34;"></p>

<p>データストリームの中でキューを間に挟むことの主な理由は，ログのreliabilityの向上と，処理の間にワンクッション置くこと．</p>

<p>そもそもキューはPush型ではなくPull型であり，Producer・Queue・Consumerと登場人物も増えるので，キューを置くことでログ収集そのものが効率化されることはあまりない．異なる粒度のシステム間で連携をする時に，間にキューを置くことが多い．</p>

<p>実際Fluentdとキューを連携させている例はいくつかあり，たとえば複雑なシステムを構築している<a href="http://engineering.viki.com/blog/2014/data-warehouse-and-analytics-infrastructure-at-viki/">Vikiの例</a>ではKestrelでFluentdからのデータストリームを分岐させているし，AWSは本家が<a href="https://github.com/awslabs/aws-fluent-plugin-kinesis">fluent-plugin-kinesis</a>を書いているので，いずれこの事例も増えるはず.</p>

<p>KafkaやKinesisなど信頼性のあるキューを間に置けば，ログをそれなりの期間保持しつつ，Consumerを複数用意することでストリームを分岐できる．<br />
Push型での分岐とは違い，キューからログを取る側の都合でデータを処理出来るので，各データストリームで処理粒度が違う時に有効．
ただ，キューそのものに信頼性があってもProducer/Consumerが駄目だと効率が良くならずログが欠損/重複するので，自分たちのシステム要件に合わせてちゃんと構築する必要がある．</p>

<h3>Pull型のログ収集</h3>

<p>キューを置かずにPull型でログを転送する方法もある．Kafkaほどの信頼性を期待するのは難しいが，Pull型の利点を享受できる．まだ完成していないが，Fluentdだとモリス=タゴという人が，<a href="https://github.com/tagomoris/fluent-plugin-pullforward">pullforward</a>というのを開発中らしい．</p>

<h2>Fluentdを使わない方が良いパターン</h2>

<p>プロダクションで使われているパターンをいくつか書いた．大抵のシステムは上のどれかの構成に当てはまる．FluentdはWebや広告のみならずIoTやPOS含め色々なところで使われていて，データのアーカイブ，簡単なストリーム処理，ノードやアプリケーションのモニタリング，などなど様々なユースケースの基盤になれる柔軟性がある．</p>

<p>また，LINE社で2年間問題なく動いているし，最近勉強会とかで話を聞くと「安定していて自分の仕事がない」と言われる位，よほど変なことしない限り安定性もある．ある会社で100億events/dayをFluentdクラスタで転送した実績もあるので，パフォーマンスもそれなりにある(フィルタ的な処理を重ねまくると，もちろん遅くなる)．</p>

<p>が，Fluentdを使わない方が良いケースもある．以下主に二つ．</p>

<h3>Exactly Onceが必要なケース</h3>

<p>一切ログの欠損も重複も許せない，しかも確実に書き込む必要がある，というケース．<br />
ストリーム処理でExactly Onceを保証するのはかなり難しく，俺が知っている限りOSSでは存在していない．商用でもほとんど知らない．</p>

<p>Exactly Onceを実現しようとすると，ログ発生時点から書き込むまでを完全に同期的にやるか，様々な箇所でトランザクションが必要になり，スケールアウトが難しくコストもものすごく掛かる．そして保存先にもそれなりの機能が求められる．</p>

<p>かつてOSSでマスターノードを使い到達保証を目指したプロダクトがあったが，結局パフォーマンスがボトルネックになり，そこまでしてもログの欠損が防げなかったため，新しいバージョンでは諦めることになった．</p>

<h4>Fluentdのモデル</h4>

<p>FluentdはAt Most Onceであり，<a href="http://docs.fluentd.org/articles/high-availability">ドキュメントにもモデルの説明と対策が書いてある</a>，<br />
これはログが欠損/重複しまくるということではなく，At Most OnceもAt Least Onceも通常は問題は起きない．トポロジーに問題がある場合に，システム的に欠損/重複が起きうるという話．そして大抵のユーザはExactly Onceでなくても上手く行く．</p>

<p>Fluentdでも欠損/重複を防ぐための対策はいくつかあり</p>

<ul>
<li>ログにユニークIDを足して，HadoopなどのETLで重複を削除する</li>
<li>直近の生ログは保持しておき，保存先とのレコード数を比較する．おかしい所は再送</li>
<li>データストリームを複数作って冗長性を持たせる</li>
</ul>


<p>などなど．システム的にExactly Onceではなくても，それに低コストで近づけることは可能．</p>

<h3>データストリームが一本で密結合したサービスがある</h3>

<p>たとえばAWSのCloudWatch Logsがそう．Agentのセットアップが必要だったりして楽かと言われるとまだ微妙だが，今後最初からインストールされる可能性もある．<br />
そのような状況で，Agentから取れるログをCloudWatch Logsで直接見るので十分であれば，Fluentdを入れるメリットは少ない(<a href="https://github.com/ryotarai/fluent-plugin-cloudwatch-logs">CloudWatch Logs</a>用のプラグインがあるので，Fluentdから利用することは可能)．</p>

<p>Fluentdの利点は簡単にロバストで柔軟性のあるログ収集基盤が作れて，一度構築してしまえば，環境非依存でそのログ収集基盤を再利用出来るところなので，そのような必要性がないのであれば，環境と密結合したサービスを使う方が運用コストそのものは直近は削減できるはず．</p>

<h2>まとめ</h2>

<p>Fluentdが向いているケースと向いてないケース，そのPros/Consみたいなのを書いた．細かく書けばもっと色々と書けるのだけど，記事でそんなに長々と書いても疲れるだけなので大まかに．
何か質問があればTwitterで<a href="https://twitter.com/repeatedly">@repeatedly</a>にmentionするなり，この記事にコメントするなりしてください :)</p>

<p>もうすぐFluentd + Elasticsearch + Kibanaという有名な構成のムック本が出るようなので，この本とか読むと，解析のノウハウ含め色々とここには書いていない情報が手に入るのではないかと思います．<br />
<a href="http://www.amazon.co.jp/exec/obidos/ASIN/4774169838/repeatedly-22/ref=nosim/"><img src="http://ecx.images-amazon.com/images/I/61vwvFp6EEL._SL160_.jpg" /></a></p>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/ja/2014/07/mpp-on-hadoop-redshift-bigquery/">MPP on Hadoop, Redshift, BigQuery</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2014-07-23T22:33:00+09:00" pubdate data-updated="true">Jul 23<span>rd</span>, 2014</time>
        
         | <a href="/ja/2014/07/mpp-on-hadoop-redshift-bigquery/#disqus_thread">Comments</a>
        
      </p>
    
  </header>


  <div class="entry-content"><p>Twitterで「早く今流行のMPPの大まかな使い方の違い書けよ！」というプレッシャーが半端ないのでてきとうに書きます．この記事は俺の経験と勉強会などでユーザから聞いた話をもとに書いているので，すべてが俺の経験ではありません(特にBigQuery)．各社のSAの人とかに聞けば，もっと良いアプローチとか詳細を教えてくれるかもしれません．<br />
オンプレミスの商用MPPは使ったことないのでノーコメントです．</p>

<p>MPP on HadoopでPrestoがメインなのは今一番使っているからで，Impalaなど他のMPP on Hadoop的なものも似たような感じかなと思っています．
もちろん実装の違いなどがあるので，その辺は適宜自分で補間してください．</p>

<h2>前提</h2>

<p>アプリケーションを開発していて，そのための解析基盤を一から作る．</p>

<h2>簡単なまとめ</h2>

<ul>
<li>データを貯める所が作れるのであれば，そこに直接クエリを投げられるPrestoなどのMPPクエリエンジンを立てるのが楽

<ul>
<li>特にHadoopとかすでにある場合には，まずこれ</li>
</ul>
</li>
<li>データマートが必要であれば，RedshiftやBigQueryの方が向いている</li>
<li>ストレージもスキーマも運用も何も考えずにやりたいのであれば，BigQueryにFluentdとかでとりあえずJSONでぶち込むのが，多分この候補の中では一番初期コストが掛からない

<ul>
<li>もちろん要求によるので気をつける</li>
</ul>
</li>
<li>Presto + Redshiftというケースも有り(アドホックなクエリはPresto，BIからガリガリつなぐのにRedshiftなど)</li>
</ul>


<p>以下つらつらとリスト形式で書いてます．</p>

<h2>Presto/Impala/Drill</h2>

<p>PrestoやImpalaやApache Drillは，Redshift/BigQueryと違ってMPPデータベースではなくてMPPクエリエンジンなので，そこに違いがある．
Prestoそのものについては，@frsyuki が<a href="http://treasure-data.hateblo.jp/entry/2014/07/10/150250">HCJ 2014で発表したスライド</a>があるので，そっちも参考に．</p>

<ul>
<li>PrestoやImpalaはそもそもサービスじゃないので，自分ですべて運用する必要がある．

<ul>
<li>死活監視とか，もう少しワーカーが欲しかったら追加でデプロイみたいなのをする人が必要</li>
</ul>
</li>
<li>外部にストレージが必要

<ul>
<li>すでにある場合には，RedshiftやBigQueryじゃなくて，まずこれで十分かどうか試すという流れになりつつある</li>
<li>PrestoならS3とかにもクエリが投げられるので，FluentdでS3にJSONで貯めて，とかで構築コストはかなり軽減出来る</li>
</ul>
</li>
<li>ストレージ側にスキーマを要求せず，直接クエリが投げられる</li>
<li>MapReduceとかとデータソースを共有出来る

<ul>
<li>データ量が増えてくると，ストレージからMPPデータベースにimportするだけでコストになるので，アドホックにクエリが投げにくくなる</li>
<li>PrestoやApache Drillは一つのクエリで複数のデータソースにアクセス出来るので．マスターテーブルとのjoinとかが楽に出来る</li>
</ul>
</li>
<li>速さに関しては，やはりスキーマありでチューニングされたMPPにはまだ基本勝てない．状況によっては勝てる時もある

<ul>
<li>それでも数秒 - 数十秒で返ってきたりするので，どこまでパフォーマンスを求めるかによる</li>
</ul>
</li>
<li>クエリ同時実行制御に関しては，まだ商用のものに迫っているのはない印象

<ul>
<li>ここの改善に取り組んでいる人たちがいるので，いずれデータマート的にも使えるようになる可能性は高い</li>
</ul>
</li>
<li>オープンソースなので，問題があったら自分で修正可能，処理傾向も把握しやすい</li>
</ul>


<h2>Redshift</h2>

<ul>
<li>スキーマが必須なので，アドホックに解析するためのデータベースとしては少し不向き

<ul>
<li>やるならデータをJSON文字列で保存，クエリ時に分解する．効率は落ちる</li>
</ul>
</li>
<li>MPPデータベース(ParAccel)がAWSカスタマイズされて載っているので，その辺の知識がないと嵌まりやすい

<ul>
<li>AWS Casualで青木さんが話した<a href="http://www.slideshare.net/mineroaoki/20140419-aws-casualredshiftpublic">ふつうのRedshiftパフォーマンスチューニング</a>が参考になる</li>
<li>データ量がすくないとそれでもパワーでなんとかなる</li>
</ul>
</li>
<li>マネージドサービスとはいえ，リーダーノードの挙動がおかしい時など，面倒を見ないと行けないケースはある</li>
<li>カラムを弄る場合は基本テーブルを作り直すのがベター．クラスタ再配置中はREAD ONLYになるので，その辺含めて運用を考える必要がある

<ul>
<li>数時間READ ONLYの場合，貯めようとしていたログはどうするか，など</li>
<li>今時はMPPデータベース単体で運用している所は少ない．RedshiftでもEMRなどからデータを整形して一気にガツンと入れるのが多い</li>
</ul>
</li>
<li>クエリの同時実行制御周りはそれなりに頑張っている

<ul>
<li>データマートして使いやすい．<a href="https://twitter.com/mineroaoki/status/491995296671363073">バッチを投げると厳しい</a>とのこと．</li>
</ul>
</li>
<li>ストレージと演算パワーが分離してないので，ユースケースによってはコストが割に合わない

<ul>
<li>特に周りだとSSDインスタンスを使っている人は<del>いない</del>ほとんどいない(<a href="https://twitter.com/repeatedly/status/489635755979837441">この辺の話</a>)．</li>
<li>某ふっふはっほ社が「たべみる」でSSDをつかってました(<a href="http://www.slideshare.net/mineroaoki/at-aws-summit-tokyo-2014/9">AWS Summitでのスライド</a>)．が，これはかなり<a href="https://twitter.com/mirakui/status/491947294019690497">特殊な</a><a href="https://twitter.com/mirakui/status/491948100571758592">ケース</a>な気も．<a href="https://twitter.com/mineroaoki/status/49">横に並べることによるメリット</a>が大きいようです．</li>
</ul>
</li>
</ul>


<h2>BigQuery</h2>

<ul>
<li>Redshiftと同じく，アドホックに色々とデータをぶち込んで解析するには，JSON文字列(record型？)で保存する必要がある</li>
<li>既存のMPPデータベースとかで考えないと行けない問題(distkeyとか)を，Googleパワーで強引に解決</li>
<li>運用は完全Google任せ

<ul>
<li>Redshiftと違いGoogleの環境を共有するので，細かなことは出来ない</li>
</ul>
</li>
<li>Googleの制約を受ける

<ul>
<li>負荷が極端に上がるようなクエリとかは望み薄(FULL OUTER JOIN, 数億同士のjoin，count(distinct))</li>
<li>Redshift同様，でかいバッチ向けにHDFSとかオブジェクトストレージに生のデータを置いておくのがベター</li>
</ul>
</li>
<li>BigQueryもスキーマがあり，alter column的なものがないので，変更する時は適宜テーブルを作り直すのがベター</li>
<li>Redshiftと違いクエリ単位の課金なので，どれだけ掛かるか把握するのが難しい

<ul>
<li>小さい会社だとかなりマネージしやすい(<a href="https://twitter.com/repeatedly/status/491889139579506688">この辺の話</a>)．大きい会社や，マーケや営業の人がガンガン使う場合には，かなりバーストする可能性がある．Reservedがあるが，<a href="https://developers.google.com/bigquery/pricing?hl=ja#reserved_cap">月200万から</a>なので，判断が難しい</li>
</ul>
</li>
<li>Streaming Importが結構パフォーマンスが出るので，importして即クエリがやりやすい(<a href="http://qiita.com/kazunori279/items/10ac0066ac9b0b5aaaf3">参考記事</a>)</li>
<li>同時実行制御周りは基本よく動く

<ul>
<li>リソースはGoogle側が管理しているので，バッチ投げたら詰まるとかは起きにくい</li>
<li>リソースを占有しているわけではないので，勝手にクエリが死んだり，いきなり遅くなったりすることもある

<ul>
<li>日本時間の21時当たりで起きやすいらしい．でかいバッチを投げまくっているユーザが海外にいる？</li>
</ul>
</li>
</ul>
</li>
</ul>


<h2>まとめ</h2>

<p>基本的にこれらの裏にはHadoopなどの基盤が前提になりつつある(オブジェクトストレージ + 演算リソースでも可)．上のリストを眺めれば，なんとなく使い分けが分かるんじゃないでしょうか！
MPPと一纏めにするにはユースケースや得意なものが違うので，ちゃんと使い分けましょう．基本的にどれもBIツールと接続する方法があり，苦労はそんなにしないはず．</p>

<p>各プロダクトは常に改善されているので，ここに書いてある制約などは，いずれ緩和される可能性があります．常に最新情報をチェックしましょう．</p>

<p>今回はMPPクエリエンジンプロダクトの話なので上のリストでは省きましたが，Treasure Dataが提供しているTQAというMPPサービスは「Prestoで運用とかストレージを考えなくていい版」に近い感じになります．TDはさまざまな<a href="http://docs.treasuredata.com/categories/result">外部ストレージと連携出来る</a>ので，<a href="http://treasure-data.hateblo.jp/entry/2014/05/14/104632">Treasure Dataを中心に使い分ける感じになります</a>．<br />
最後に宣伝！</p>

<h2>P.S</h2>

<p>Twitterに流したさらに要約したtweet.</p>

<blockquote class="twitter-tweet" lang="en"><p>Presto on Storage/BigQuery/Redshiftはユースケースがバラバラなので，適宜使い分ければ良いという単純な話．ただ，HDFSやオブジェクトストレージみたいなのにデータが永続化されている前提なので，Prestoは入りには楽だよね，というのはあります．</p>&mdash; Mr. Fiber (@repeatedly) <a href="https://twitter.com/repeatedly/statuses/491883277829951488">July 23, 2014</a></blockquote>


<script async src="//platform.twitter.com/widgets.js" charset="utf-8"></script>




<blockquote class="twitter-tweet" lang="en"><p>Redshiftは同時実行制御頑張っているし，distkeyとかをちゃんと設計してあげればかなりパフォーマンスが出るので，データマートとして優秀．特に8XLとかであれば，RDSとかでは頑張れない領域になる．ただ，スキーマの変更に弱いので，適宜ロードしてあげないと行けないのがネック</p>&mdash; Mr. Fiber (@repeatedly) <a href="https://twitter.com/repeatedly/statuses/491884516605038592">July 23, 2014</a></blockquote>


<script async src="//platform.twitter.com/widgets.js" charset="utf-8"></script>




<blockquote class="twitter-tweet" lang="en"><p>BigQueryは逆に，その辺のMPPの知識ないけど楽に処理したい，という時には便利．ストレージと密結合しているRedshiftと違ってストレージとしては安価なので，ガンガンデータを入れられる．スキーマの変更に弱いのと，G社の都合でクエリに制限が掛かったり不安定になるのがネック</p>&mdash; Mr. Fiber (@repeatedly) <a href="https://twitter.com/repeatedly/statuses/491884911515533312">July 23, 2014</a></blockquote>


<script async src="//platform.twitter.com/widgets.js" charset="utf-8"></script>




<blockquote class="twitter-tweet" lang="en"><p>Prestoは単体だとストレージがないので，裏側に何を使うかによってかなり左右される．ちゃんとしたHadoopクラスタやオブジェクトストレージがあれば，同時実行制御の部分に難はあるが，低レイテンシクエリーとしては十分優秀．データのインポートの手間がないのが大きい．</p>&mdash; Mr. Fiber (@repeatedly) <a href="https://twitter.com/repeatedly/statuses/491885404665049089">July 23, 2014</a></blockquote>


<script async src="//platform.twitter.com/widgets.js" charset="utf-8"></script>




<blockquote class="twitter-tweet" lang="en"><p>まぁHadoopとかあるならとりあえずPresto入れとくか，という流れにはなりつつある気がする．それでも同時にたくさんのクエリが飛んでくるとか，ある程度スキーマ固まったのでガッツリ使いたい，になるとRedshiftとかBigQueryにバッチでinsert，がよくあるパターン</p>&mdash; Mr. Fiber (@repeatedly) <a href="https://twitter.com/repeatedly/statuses/491886467266789376">July 23, 2014</a></blockquote>


<script async src="//platform.twitter.com/widgets.js" charset="utf-8"></script>




<blockquote class="twitter-tweet" lang="en"><p>やっぱり他のMPPデータベースにデータ入れるの面倒だからPrestoでがんばりたい，というユーザ結構いてその人たちが色々とPrestoをデータマート的に使えるようにと頑張っているようなので，いずれHadoop上ですべて完結する世界は来るかもしれない</p>&mdash; Mr. Fiber (@repeatedly) <a href="https://twitter.com/repeatedly/statuses/491887539267960833">July 23, 2014</a></blockquote>


<script async src="//platform.twitter.com/widgets.js" charset="utf-8"></script>




<blockquote class="twitter-tweet" lang="en"><p>トレジャーデータというサービス，自分でインフラ管理する必要ないですし，Fluentd/JS/iOS/Androidなどからデータを入れるだけで，即バッチや低レイテンシクエリを投げられる，便利なサービスらしいですよ &gt; <a href="http://t.co/gSg9ZTNjKt">http://t.co/gSg9ZTNjKt</a></p>&mdash; Mr. Fiber (@repeatedly) <a href="https://twitter.com/repeatedly/statuses/491889631437144064">July 23, 2014</a></blockquote>


<script async src="//platform.twitter.com/widgets.js" charset="utf-8"></script>




<blockquote class="twitter-tweet" lang="en"><p>社会人の勤めを果たした</p>&mdash; Mr. Fiber (@repeatedly) <a href="https://twitter.com/repeatedly/statuses/491889663787819008">July 23, 2014</a></blockquote>


<script async src="//platform.twitter.com/widgets.js" charset="utf-8"></script>

</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/ja/2014/07/release-fluent-plugin-http-puma/">Release fluent-plugin-http-puma</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2014-07-20T18:42:00+09:00" pubdate data-updated="true">Jul 20<span>th</span>, 2014</time>
        
         | <a href="/ja/2014/07/release-fluent-plugin-http-puma/#disqus_thread">Comments</a>
        
      </p>
    
  </header>


  <div class="entry-content"><p><a href="https://github.com/repeatedly/fluent-plugin-http-puma">fluent-plugin-http-puma</a></p>

<p>標準で入っているin_httpとは違って，Pumaと呼ばれるWebサーバベースのHTTP(S)でのリクエストを受け付けるInputプラグイン書きました．</p>

<h2>使い方</h2>

<p>fluent-gemでインストール．</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>$ fluent-gem install fluent-plugin-http-puma</span></code></pre></td></tr></table></div></figure>


<p>in_httpとほぼ同じように動きますが，独自でHTTPリクエストをパースしてないので，keepaliveやボディサイズチェック用のオプションはありません．その代わりPuma関係のオプションが増えてます(<a href="https://github.com/repeatedly/fluent-plugin-http-puma#configuration">README参照</a>)．<br />
一番の違いは，HTTPSをサポートしている所です．<code>use_ssl</code>と<code>ssl_keys</code>を使うことで，HTTPSとして立ち上がります．</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
</pre></td><td class='code'><pre><code class='aconf'><span class='line'><span class="nt">&lt;source&gt;</span>
</span><span class='line'>  <span class="nb">type</span> http_puma
</span><span class='line'>
</span><span class='line'>  <span class="err">use_</span><span class="nb">ssl</span>
</span><span class='line'>  ssl_keys [<span class="s2">&quot;/path/to/key&quot;</span>, <span class="s2">&quot;/path/to/cert&quot;</span>]
</span><span class='line'><span class="nt">&lt;/source&gt;</span>
</span></code></pre></td></tr></table></div></figure>


<h2>パフォーマンス</h2>

<p>手元のMBPで試して見たら，HTTPはin_httpより少し速かった．HTTPSは当たり前ですがｶﾞｸｯと落ちます．</p>

<p>クライアントはRubyの<code>net/http</code>を使って，小さめのjsonを<code>application/json</code>で送ってます．</p>

<ul>
<li>in_http</li>
</ul>


<p>平均2400 events/secくらい．</p>

<pre><code>2014-07-20 19:02:30 +0900 [info]: plugin:out_flowcounter_simple count:2318      indicator:num   unit:second
2014-07-20 19:02:31 +0900 [info]: plugin:out_flowcounter_simple count:2420      indicator:num   unit:second
2014-07-20 19:02:32 +0900 [info]: plugin:out_flowcounter_simple count:2383      indicator:num   unit:second
2014-07-20 19:02:33 +0900 [info]: plugin:out_flowcounter_simple count:2399      indicator:num   unit:second
2014-07-20 19:02:34 +0900 [info]: plugin:out_flowcounter_simple count:2382      indicator:num   unit:second
</code></pre>

<ul>
<li>in_http_puma</li>
</ul>


<p>平均2500 events/secくらい．Ojを使ったらもっと速くなるかと思ったけど，ほぼ誤差の範囲だった．</p>

<pre><code>2014-07-20 19:01:12 +0900 [info]: plugin:out_flowcounter_simple count:2472      indicator:num   unit:second
2014-07-20 19:01:13 +0900 [info]: plugin:out_flowcounter_simple count:2550      indicator:num   unit:second
2014-07-20 19:01:14 +0900 [info]: plugin:out_flowcounter_simple count:2294      indicator:num   unit:second
2014-07-20 19:01:15 +0900 [info]: plugin:out_flowcounter_simple count:2537      indicator:num   unit:second
2014-07-20 19:01:16 +0900 [info]: plugin:out_flowcounter_simple count:2538      indicator:num   unit:second
</code></pre>

<ul>
<li>in_http_puma with VERIFY_NONE client</li>
</ul>


<p>平均400 events/secくらい．けどVERIFY_NONEはほとんど本番では使われないので参考程度．</p>

<pre><code>2014-07-20 19:04:06 +0900 [info]: plugin:out_flowcounter_simple count:406       indicator:num   unit:second
2014-07-20 19:04:07 +0900 [info]: plugin:out_flowcounter_simple count:365       indicator:num   unit:second
2014-07-20 19:04:08 +0900 [info]: plugin:out_flowcounter_simple count:400       indicator:num   unit:second
2014-07-20 19:04:09 +0900 [info]: plugin:out_flowcounter_simple count:399       indicator:num   unit:second
2014-07-20 19:04:10 +0900 [info]: plugin:out_flowcounter_simple count:400       indicator:num   unit:second
</code></pre>

<ul>
<li>in_http_puma with VERIFY_PEER client</li>
</ul>


<p>平均320 events/secくらい．高負荷環境で無ければ大丈夫かな…？</p>

<pre><code>2014-07-20 19:05:18 +0900 [info]: plugin:out_flowcounter_simple count:329       indicator:num   unit:second
2014-07-20 19:05:19 +0900 [info]: plugin:out_flowcounter_simple count:327       indicator:num   unit:second
2014-07-20 19:05:20 +0900 [info]: plugin:out_flowcounter_simple count:327       indicator:num   unit:second
2014-07-20 19:05:21 +0900 [info]: plugin:out_flowcounter_simple count:325       indicator:num   unit:second
2014-07-20 19:05:22 +0900 [info]: plugin:out_flowcounter_simple count:326       indicator:num   unit:second
</code></pre>

<h2>まとめ</h2>

<p>モダンと言われるPumaってどんなもんなんだろう？と調べてたら，HTTPSを標準でサポートしてるし，ライブラリとしても簡単に使えそうだったので試して見たら，それなりにパフォーマンスが出たので公開してみたという感じです．<br />
Pumaなので，今後FluentdがJRubyとかサポートしても普通にそのまま使えると思います．</p>

<p>実際HTTPSを処理するならFluentdの前にNginxとかを置いた方が良いのだけど，バックエンドでも通信はHTTPSでやってるとかなんか縛りがあるような環境では，手軽に使えるのではないかと思います．</p>

<p>何かあれば<a href="https://github.com/repeatedly/fluent-plugin-http-puma">issue/pull request</a>に投げてもらえれば対応します．</p>
</div>
  
  


    </article>
  
  <div class="pagination">
    
      <a class="prev" href="/ja/page/2/">&larr; Older</a>
    
    <a href="/archives">Archives</a>
    
  </div>
</div>
<aside class="sidebar">
  
    <section>
  <h1>Recent Posts</h1>
  <ul id="recent_posts">
    
      <li class="post">
        <a href="/ja/2014/08/fluentd-filter-and-label/">Fluentd v0.12でのFilterとLabel</a>
      </li>
    
      <li class="post">
        <a href="/ja/2014/08/fluentd-ui/">Fluentd UI</a>
      </li>
    
      <li class="post">
        <a href="/ja/2014/07/fluentd-and-log-forwarding-patterns/">Fluentdとログ収集のパターン</a>
      </li>
    
      <li class="post">
        <a href="/ja/2014/07/mpp-on-hadoop-redshift-bigquery/">MPP on Hadoop, Redshift, BigQuery</a>
      </li>
    
      <li class="post">
        <a href="/ja/2014/07/release-fluent-plugin-http-puma/">Release fluent-plugin-http-puma</a>
      </li>
    
  </ul>
</section>

<section>
  <h1>Github Repos</h1>
  <ul id="gh_repos">
    <li class="loading">Status updating&#8230;</li>
  </ul>
  
  <a href="https://github.com/repeatedly">@repeatedly</a> on Github
  
  <script type="text/javascript">
    $.domReady(function(){
        if (!window.jXHR){
            var jxhr = document.createElement('script');
            jxhr.type = 'text/javascript';
            jxhr.src = '/javascripts/libs/jXHR.js';
            var s = document.getElementsByTagName('script')[0];
            s.parentNode.insertBefore(jxhr, s);
        }

        github.showRepos({
            user: 'repeatedly',
            count: 4,
            skip_forks: true,
            target: '#gh_repos'
        });
    });
  </script>
  <script src="/javascripts/github.js" type="text/javascript"> </script>
</section>


<section>
  <h1>Latest Tweets</h1>
  <ul id="tweets">
    <li class="loading">Status updating&#8230;</li>
  </ul>
  <script type="text/javascript">
    $.domReady(function(){
      getTwitterFeed("repeatedly", 4, false);
    });
  </script>
  <script src="/javascripts/twitter.js" type="text/javascript"> </script>
  
    <a href="http://twitter.com/repeatedly" class="twitter-follow-button" data-show-count="false">Follow @repeatedly</a>
  
</section>





  
</aside>

    </div>
  </div>
  <footer role="contentinfo"><p>
  Copyright &copy; 2014 - Masahiro Nakagawa -
  <span class="credit">Powered by <a href="http://octopress.org">Octopress</a></span>
</p>

</footer>
  

<script type="text/javascript">
      var disqus_shortname = 'repeatedly';
      
        
        var disqus_script = 'count.js';
      
    (function () {
      var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
      dsq.src = 'http://' + disqus_shortname + '.disqus.com/' + disqus_script;
      (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    }());
</script>



<div id="fb-root"></div>
<script>(function(d, s, id) {
  var js, fjs = d.getElementsByTagName(s)[0];
  if (d.getElementById(id)) {return;}
  js = d.createElement(s); js.id = id;
  js.src = "//connect.facebook.net/en_US/all.js#appId=212934732101925&xfbml=1";
  fjs.parentNode.insertBefore(js, fjs);
}(document, 'script', 'facebook-jssdk'));</script>





  <script type="text/javascript">
    (function(){
      var twitterWidgets = document.createElement('script');
      twitterWidgets.type = 'text/javascript';
      twitterWidgets.async = true;
      twitterWidgets.src = 'http://platform.twitter.com/widgets.js';
      document.getElementsByTagName('head')[0].appendChild(twitterWidgets);
    })();
  </script>





</body>
</html>
